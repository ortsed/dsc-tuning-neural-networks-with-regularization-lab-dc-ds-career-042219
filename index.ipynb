{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recall from the last lab that you had a training accuracy close to 90% and a test set accuracy close to 76%.\n",
    "\n",
    "As with your previous machine learning work, you should be asking a couple of questions:\n",
    "- Is there a high bias? yes/no\n",
    "- Is there a high variance? yes/no \n",
    "\n",
    "In this lab, you'll use the a train-validate-test partition to get better insights of how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. Then, just before you go on to train the model, you'll see how to include a validation set. From there, you'll define and compile the model like before. However, this time, when you are presented with the `history` dictionary of the model, you will have additional data entries for not only the train and test set but also the validation set.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Construct and run a basic model in Keras\n",
    "* Construct a validation set and explain potential benefits\n",
    "* Apply L1 and L2 regularization\n",
    "* Apply dropout regularization\n",
    "* Observe and comment on the effect of using more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "As usual, start by importing some of the packages and modules that you intend to use. The first thing you'll be doing is importing the data and taking a random sample, so that should clue you in to what tools to import. If you need more tools down the line, you can always import additional packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "As with the previous lab, the data is stored in a file **Bank_complaints.csv**. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Bank_complaints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools regarding regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels\n",
    "* Train - test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your models performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "Generate the random sample using seed 123 for consistency of results. Make your new sample have 10,000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(random_state=123, n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding of the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing and data manipulationg before building the neural network. \n",
    "\n",
    "Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Yyour code here; use one-hot encoding to reformat the complaints into a matrix of vectors.\n",
    "#Only keep the 2000 most common words.\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(sample[\"Consumer complaint narrative\"])\n",
    "\n",
    "one_hot_results= tokenizer.texts_to_matrix(sample[\"Consumer complaint narrative\"], mode='binary')\n",
    "word_index = tokenizer.word_index\n",
    "np.shape(one_hot_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29561</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>I want to file a \" Bait and Switch '' Complain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26640</th>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>I am an account holder for my personal, busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24498</th>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>they took my whole social security check i had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24594</th>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>This is in dispute of my Case number : XXXX. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24249</th>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>My Bluebird card that i used for bill pay was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Product  \\\n",
       "29561            Consumer Loan   \n",
       "26640  Bank account or service   \n",
       "24498  Bank account or service   \n",
       "24594  Bank account or service   \n",
       "24249  Bank account or service   \n",
       "\n",
       "                            Consumer complaint narrative  \n",
       "29561  I want to file a \" Bait and Switch '' Complain...  \n",
       "26640  I am an account holder for my personal, busine...  \n",
       "24498  they took my whole social security check i had...  \n",
       "24594  This is in dispute of my Case number : XXXX. I...  \n",
       "24249  My Bluebird card that i used for bill pay was ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Your code here; transform the product labels to numerical values\n",
    "#Then transform these integer values into a matrix of binary flags\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "le = LabelEncoder()\n",
    "le.fit(sample.Product)\n",
    "product_cat = le.transform(sample.Product) \n",
    "\n",
    "product_onehot = to_categorical(product_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "\n",
    "Now onto the ever familiar train-test split! \n",
    "Below, perform an appropriate train test split.\n",
    "> Be sure to split both the complaint data (now transformed into word vectors) as well as their associated labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(one_hot_results, product_onehot, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yyour code here\n",
    "X_train = \n",
    "X_test = \n",
    "y_train = \n",
    "y_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model using a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, you saw that in deep learning, you generally set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test can then be used to define the final model perforance. \n",
    "\n",
    "In this example, take the first 1000 cases out of the training set to create a validation set. You should do this for both `train` and `label_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just run this block of code \n",
    "np.random.seed(123)\n",
    "val = X_train[:1000]\n",
    "train_final = X_train[1000:]\n",
    "label_val = y_train[:1000]\n",
    "label_train_final = y_train[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a fully connected (Dense) layer network with relu activations in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you used 2 hidden with 50 units in the first layer and 25 in the second, both with a `relu` activation function. Because you are dealing with a multiclass problem (classifying the complaints into 7 classes), use a softmax classifyer in order to output 7 class probabilities per case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; build a neural network using Keras as described above.\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "In the compiler, you'll be passing the optimizer, loss function, and metrics. Train the model for 120 epochs in mini-batches of 256 samples. This time, include the argument `validation_data` and assign it `(val, label_val)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"SGD\", metrics=['accuracy'], validation_data=(val, label_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Ok, now for the resource intensive part: time to train your model! Note that this is where you also introduce the validation data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7000/7000 [==============================] - 0s 67us/step - loss: 2.1745 - acc: 0.1721 - val_loss: 1.8687 - val_acc: 0.2150\n",
      "Epoch 2/120\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.8544 - acc: 0.2329 - val_loss: 1.8269 - val_acc: 0.2780\n",
      "Epoch 3/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.7945 - acc: 0.2984 - val_loss: 1.7748 - val_acc: 0.3130\n",
      "Epoch 4/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.7216 - acc: 0.3580 - val_loss: 1.7557 - val_acc: 0.3580\n",
      "Epoch 5/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 2.2691 - acc: 0.1687 - val_loss: 2.3151 - val_acc: 0.1220\n",
      "Epoch 6/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 2.2468 - acc: 0.1399 - val_loss: 2.2425 - val_acc: 0.1220\n",
      "Epoch 7/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 2.1902 - acc: 0.1399 - val_loss: 2.1963 - val_acc: 0.1220\n",
      "Epoch 8/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 2.1521 - acc: 0.1399 - val_loss: 2.1625 - val_acc: 0.1220\n",
      "Epoch 9/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 2.1236 - acc: 0.1399 - val_loss: 2.1364 - val_acc: 0.1220\n",
      "Epoch 10/120\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 2.1012 - acc: 0.1399 - val_loss: 2.1152 - val_acc: 0.1220\n",
      "Epoch 11/120\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 2.0827 - acc: 0.1399 - val_loss: 2.0972 - val_acc: 0.1220\n",
      "Epoch 12/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 2.0669 - acc: 0.1399 - val_loss: 2.0819 - val_acc: 0.1220\n",
      "Epoch 13/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 2.0535 - acc: 0.1399 - val_loss: 2.0684 - val_acc: 0.1220\n",
      "Epoch 14/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 2.0417 - acc: 0.1399 - val_loss: 2.0567 - val_acc: 0.1220\n",
      "Epoch 15/120\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 2.0314 - acc: 0.1399 - val_loss: 2.0462 - val_acc: 0.1220\n",
      "Epoch 16/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 2.0221 - acc: 0.1399 - val_loss: 2.0367 - val_acc: 0.1220\n",
      "Epoch 17/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 2.0138 - acc: 0.1399 - val_loss: 2.0282 - val_acc: 0.1220\n",
      "Epoch 18/120\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 2.0063 - acc: 0.1399 - val_loss: 2.0203 - val_acc: 0.1220\n",
      "Epoch 19/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.9994 - acc: 0.1399 - val_loss: 2.0131 - val_acc: 0.1220\n",
      "Epoch 20/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.9931 - acc: 0.1399 - val_loss: 2.0065 - val_acc: 0.1220\n",
      "Epoch 21/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.9872 - acc: 0.1399 - val_loss: 2.0003 - val_acc: 0.1220\n",
      "Epoch 22/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.9818 - acc: 0.1399 - val_loss: 1.9946 - val_acc: 0.1220\n",
      "Epoch 23/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.9768 - acc: 0.1399 - val_loss: 1.9893 - val_acc: 0.1220\n",
      "Epoch 24/120\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.9722 - acc: 0.1399 - val_loss: 1.9843 - val_acc: 0.1220\n",
      "Epoch 25/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.9679 - acc: 0.1399 - val_loss: 1.9797 - val_acc: 0.1220\n",
      "Epoch 26/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.9638 - acc: 0.1399 - val_loss: 1.9754 - val_acc: 0.1220\n",
      "Epoch 27/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.9601 - acc: 0.1399 - val_loss: 1.9713 - val_acc: 0.1220\n",
      "Epoch 28/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.9565 - acc: 0.1399 - val_loss: 1.9673 - val_acc: 0.1220\n",
      "Epoch 29/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.9532 - acc: 0.1399 - val_loss: 1.9637 - val_acc: 0.1220\n",
      "Epoch 30/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.9500 - acc: 0.1399 - val_loss: 1.9602 - val_acc: 0.1220\n",
      "Epoch 31/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.9471 - acc: 0.1399 - val_loss: 1.9569 - val_acc: 0.1220\n",
      "Epoch 32/120\n",
      "7000/7000 [==============================] - 0s 38us/step - loss: 1.9442 - acc: 0.1399 - val_loss: 1.9537 - val_acc: 0.1220\n",
      "Epoch 33/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.9415 - acc: 0.1399 - val_loss: 1.9507 - val_acc: 0.1220\n",
      "Epoch 34/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.9390 - acc: 0.1399 - val_loss: 1.9480 - val_acc: 0.1220\n",
      "Epoch 35/120\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.9367 - acc: 0.1399 - val_loss: 1.9452 - val_acc: 0.1220\n",
      "Epoch 36/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.9344 - acc: 0.1399 - val_loss: 1.9427 - val_acc: 0.1220\n",
      "Epoch 37/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.9323 - acc: 0.1399 - val_loss: 1.9403 - val_acc: 0.1220\n",
      "Epoch 38/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.9303 - acc: 0.1399 - val_loss: 1.9379 - val_acc: 0.1220\n",
      "Epoch 39/120\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 1.9283 - acc: 0.1399 - val_loss: 1.9357 - val_acc: 0.1220\n",
      "Epoch 40/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.9265 - acc: 0.1399 - val_loss: 1.9336 - val_acc: 0.1220\n",
      "Epoch 41/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.9247 - acc: 0.1399 - val_loss: 1.9316 - val_acc: 0.1220\n",
      "Epoch 42/120\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.9231 - acc: 0.1399 - val_loss: 1.9296 - val_acc: 0.1220\n",
      "Epoch 43/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.9215 - acc: 0.1399 - val_loss: 1.9277 - val_acc: 0.1220\n",
      "Epoch 44/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.9200 - acc: 0.1399 - val_loss: 1.9259 - val_acc: 0.1220\n",
      "Epoch 45/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.9185 - acc: 0.1399 - val_loss: 1.9242 - val_acc: 0.1220\n",
      "Epoch 46/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.9171 - acc: 0.1399 - val_loss: 1.9226 - val_acc: 0.1220\n",
      "Epoch 47/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.9158 - acc: 0.1399 - val_loss: 1.9210 - val_acc: 0.1220\n",
      "Epoch 48/120\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 1.9145 - acc: 0.1399 - val_loss: 1.9195 - val_acc: 0.1220\n",
      "Epoch 49/120\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.9133 - acc: 0.1399 - val_loss: 1.9180 - val_acc: 0.1220\n",
      "Epoch 50/120\n",
      "7000/7000 [==============================] - 0s 30us/step - loss: 1.9121 - acc: 0.1400 - val_loss: 1.9166 - val_acc: 0.1220\n",
      "Epoch 51/120\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 1.9109 - acc: 0.140 - 0s 37us/step - loss: 1.9109 - acc: 0.1404 - val_loss: 1.9152 - val_acc: 0.1240\n",
      "Epoch 52/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.9098 - acc: 0.1411 - val_loss: 1.9139 - val_acc: 0.1270\n",
      "Epoch 53/120\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.9088 - acc: 0.1439 - val_loss: 1.9127 - val_acc: 0.1310\n",
      "Epoch 54/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.9078 - acc: 0.1513 - val_loss: 1.9115 - val_acc: 0.1380\n",
      "Epoch 55/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.9068 - acc: 0.1609 - val_loss: 1.9103 - val_acc: 0.1540\n",
      "Epoch 56/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.9059 - acc: 0.1757 - val_loss: 1.9092 - val_acc: 0.1770\n",
      "Epoch 57/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.9050 - acc: 0.1946 - val_loss: 1.9081 - val_acc: 0.1890\n",
      "Epoch 58/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.9041 - acc: 0.2090 - val_loss: 1.9070 - val_acc: 0.2070\n",
      "Epoch 59/120\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.9032 - acc: 0.2140 - val_loss: 1.9060 - val_acc: 0.2100\n",
      "Epoch 60/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.9024 - acc: 0.2123 - val_loss: 1.9050 - val_acc: 0.2090\n",
      "Epoch 61/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.9016 - acc: 0.2097 - val_loss: 1.9041 - val_acc: 0.2120\n",
      "Epoch 62/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.9008 - acc: 0.2053 - val_loss: 1.9031 - val_acc: 0.2110\n",
      "Epoch 63/120\n",
      "7000/7000 [==============================] - 0s 30us/step - loss: 1.9000 - acc: 0.1993 - val_loss: 1.9022 - val_acc: 0.2130\n",
      "Epoch 64/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.8993 - acc: 0.1956 - val_loss: 1.9012 - val_acc: 0.2110\n",
      "Epoch 65/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.8985 - acc: 0.1939 - val_loss: 1.9003 - val_acc: 0.2080\n",
      "Epoch 66/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.8978 - acc: 0.1921 - val_loss: 1.8995 - val_acc: 0.2060\n",
      "Epoch 67/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 1.8971 - acc: 0.1899 - val_loss: 1.8986 - val_acc: 0.2070\n",
      "Epoch 68/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.8964 - acc: 0.1887 - val_loss: 1.8977 - val_acc: 0.2060\n",
      "Epoch 69/120\n",
      "7000/7000 [==============================] - 0s 30us/step - loss: 1.8956 - acc: 0.1876 - val_loss: 1.8969 - val_acc: 0.2050\n",
      "Epoch 70/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.8949 - acc: 0.1869 - val_loss: 1.8961 - val_acc: 0.2050\n",
      "Epoch 71/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8942 - acc: 0.1867 - val_loss: 1.8952 - val_acc: 0.2050\n",
      "Epoch 72/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.8935 - acc: 0.1861 - val_loss: 1.8944 - val_acc: 0.2040\n",
      "Epoch 73/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.8929 - acc: 0.1860 - val_loss: 1.8936 - val_acc: 0.2040\n",
      "Epoch 74/120\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.8922 - acc: 0.1864 - val_loss: 1.8928 - val_acc: 0.2040\n",
      "Epoch 75/120\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.8915 - acc: 0.1860 - val_loss: 1.8920 - val_acc: 0.2030\n",
      "Epoch 76/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.8908 - acc: 0.1857 - val_loss: 1.8913 - val_acc: 0.2030\n",
      "Epoch 77/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8901 - acc: 0.1856 - val_loss: 1.8905 - val_acc: 0.2030\n",
      "Epoch 78/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.8894 - acc: 0.1857 - val_loss: 1.8897 - val_acc: 0.2040\n",
      "Epoch 79/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.8887 - acc: 0.1860 - val_loss: 1.8889 - val_acc: 0.2040\n",
      "Epoch 80/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.8880 - acc: 0.1860 - val_loss: 1.8881 - val_acc: 0.2040\n",
      "Epoch 81/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.8873 - acc: 0.1859 - val_loss: 1.8873 - val_acc: 0.2040\n",
      "Epoch 82/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.8866 - acc: 0.1860 - val_loss: 1.8866 - val_acc: 0.2040\n",
      "Epoch 83/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.8859 - acc: 0.1859 - val_loss: 1.8858 - val_acc: 0.2040\n",
      "Epoch 84/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8852 - acc: 0.1860 - val_loss: 1.8850 - val_acc: 0.2040\n",
      "Epoch 85/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8844 - acc: 0.1860 - val_loss: 1.8842 - val_acc: 0.2040\n",
      "Epoch 86/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.8837 - acc: 0.1864 - val_loss: 1.8834 - val_acc: 0.2040\n",
      "Epoch 87/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.8830 - acc: 0.1866 - val_loss: 1.8826 - val_acc: 0.2040\n",
      "Epoch 88/120\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 1.8822 - acc: 0.1867 - val_loss: 1.8818 - val_acc: 0.2040\n",
      "Epoch 89/120\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 1.8814 - acc: 0.1866 - val_loss: 1.8810 - val_acc: 0.2050\n",
      "Epoch 90/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8806 - acc: 0.1866 - val_loss: 1.8801 - val_acc: 0.2050\n",
      "Epoch 91/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.8799 - acc: 0.1867 - val_loss: 1.8793 - val_acc: 0.2060\n",
      "Epoch 92/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.8790 - acc: 0.1867 - val_loss: 1.8784 - val_acc: 0.2060\n",
      "Epoch 93/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.8782 - acc: 0.1869 - val_loss: 1.8776 - val_acc: 0.2060\n",
      "Epoch 94/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.8774 - acc: 0.1869 - val_loss: 1.8767 - val_acc: 0.2050\n",
      "Epoch 95/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.8765 - acc: 0.1867 - val_loss: 1.8758 - val_acc: 0.2050\n",
      "Epoch 96/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8757 - acc: 0.1869 - val_loss: 1.8749 - val_acc: 0.2060\n",
      "Epoch 97/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.8748 - acc: 0.1869 - val_loss: 1.8740 - val_acc: 0.2060\n",
      "Epoch 98/120\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.8739 - acc: 0.1870 - val_loss: 1.8731 - val_acc: 0.2060\n",
      "Epoch 99/120\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.8730 - acc: 0.1873 - val_loss: 1.8721 - val_acc: 0.2060\n",
      "Epoch 100/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.8720 - acc: 0.1876 - val_loss: 1.8712 - val_acc: 0.2070\n",
      "Epoch 101/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.8711 - acc: 0.1876 - val_loss: 1.8702 - val_acc: 0.2070\n",
      "Epoch 102/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.8701 - acc: 0.1877 - val_loss: 1.8692 - val_acc: 0.2070\n",
      "Epoch 103/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.8691 - acc: 0.1879 - val_loss: 1.8681 - val_acc: 0.2070\n",
      "Epoch 104/120\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.8681 - acc: 0.1886 - val_loss: 1.8671 - val_acc: 0.2090\n",
      "Epoch 105/120\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.8670 - acc: 0.1887 - val_loss: 1.8660 - val_acc: 0.2090\n",
      "Epoch 106/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.8659 - acc: 0.1890 - val_loss: 1.8649 - val_acc: 0.2090\n",
      "Epoch 107/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.8648 - acc: 0.1890 - val_loss: 1.8638 - val_acc: 0.2090\n",
      "Epoch 108/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8637 - acc: 0.1893 - val_loss: 1.8627 - val_acc: 0.2110\n",
      "Epoch 109/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.8625 - acc: 0.1901 - val_loss: 1.8615 - val_acc: 0.2130\n",
      "Epoch 110/120\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 1.8614 - acc: 0.1906 - val_loss: 1.8603 - val_acc: 0.2140\n",
      "Epoch 111/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.8601 - acc: 0.1913 - val_loss: 1.8591 - val_acc: 0.2140\n",
      "Epoch 112/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.8589 - acc: 0.1927 - val_loss: 1.8578 - val_acc: 0.2140\n",
      "Epoch 113/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8576 - acc: 0.1941 - val_loss: 1.8565 - val_acc: 0.2140\n",
      "Epoch 114/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8562 - acc: 0.1951 - val_loss: 1.8552 - val_acc: 0.2150\n",
      "Epoch 115/120\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.8549 - acc: 0.1967 - val_loss: 1.8538 - val_acc: 0.2160\n",
      "Epoch 116/120\n",
      "7000/7000 [==============================] - 0s 29us/step - loss: 1.8535 - acc: 0.1986 - val_loss: 1.8524 - val_acc: 0.2170\n",
      "Epoch 117/120\n",
      "7000/7000 [==============================] - 0s 30us/step - loss: 1.8520 - acc: 0.1987 - val_loss: 1.8509 - val_acc: 0.2170\n",
      "Epoch 118/120\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.8505 - acc: 0.2007 - val_loss: 1.8494 - val_acc: 0.2180\n",
      "Epoch 119/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.8490 - acc: 0.2024 - val_loss: 1.8479 - val_acc: 0.2190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/120\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.8474 - acc: 0.2034 - val_loss: 1.8463 - val_acc: 0.2210\n"
     ]
    }
   ],
   "source": [
    "#Code provided; note the extra validation parameter passed.\n",
    "model_val = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Performance Results: the `history` dictionary\n",
    "\n",
    "The dictionary `history` contains four entries this time: one per metric that was being monitored during training and during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_dict = model_val.history\n",
    "model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 56us/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 72us/step\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.846470379965646, 0.2047142857142857]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8545295238494872, 0.2]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result isn't exactly the same as before. Note that this because the training set is slightly different! you remove 1000 instances for validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function versus the number of epochs. Be sure to include the training and the validation loss in the same plot. Then, create a second plot comparing training and validation accuracy to the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4FFXW+PHv6c4GCZAQ9gSSsK8hxIgoyOK+76PiNm7w4jjuvqPv/HTGdUZHRxEdddQRHcUd9w0dZUREUEB2ZA8QEiAEQsKadOf8/qhKCCEbIZ1O0ufzPP3Y3VVddaob6+Tce+uWqCrGGGMMgCfYARhjjGk8LCkYY4wpY0nBGGNMGUsKxhhjylhSMMYYU8aSgjHGmDKWFEyDERGviOwSkW71uW5jJyKvi8h97vPRIrK0NuvWYT8B+85EJEtERtf3dk3jY0nBVMk9wZQ+SkRkb7nXlx/u9lTVr6oxqrqhPtetCxE5WkTmi0ihiPwqIicFYj8Vqep/VXVAfWxLRGaKyNXlth3Q78yEBksKpkruCSZGVWOADcDZ5d6bUnF9EQlr+Cjr7FngY6A1cAawKbjhGNM4WFIwdSYiD4nI2yLypogUAleIyLEiMltE8kUkR0QmiUi4u36YiKiIJLuvX3eXf+H+xf6jiKQc7rru8tNFZKWI7BSRp0Xkh/J/RVfCB6xXx1pVXV7Dsa4SkdPKvY4Qke0ikioiHhF5T0Q2u8f9XxHpV8V2ThKRzHKvjxKRBe4xvQlEllsWLyKfi0iuiOwQkU9EJMFd9ihwLPC8W7lNrOQ7i3W/t1wRyRSR/xMRcZddLyLficiTbsxrReSU6r6DcnFFub9FjohsEpEnRCTCXdbBjTnf/X5mlPvcH0UkW0QK3OpsdG32ZxqWJQVzpM4H3gDaAG/jnGxvAdoBw4HTgP+p5vOXAfcCbXGqkQcPd10R6QC8A/yvu991wNAa4v4J+LuIDK5hvVJvAmPLvT4dyFbVRe7rT4FeQCdgCfBaTRsUkUjgI+BlnGP6CDiv3Coe4EWgG5AEFANPAajqXcCPwAS3cru1kl08C7QEugMnANcBV5VbfhywGIgHngT+VVPMrj8BGUAqMATnd/4/d9n/AmuB9jjfxb3usQ7A+XeQrqqtcb4/a+ZqhCwpmCM1U1U/UdUSVd2rqj+r6hxV9anqWuAFYFQ1n39PVeeqajEwBUirw7pnAQtU9SN32ZPAtqo2IiJX4JzIrgA+E5FU9/3TRWROFR97AzhPRKLc15e57+Ee+yuqWqiq+4D7gKNEJLqaY8GNQYGnVbVYVd8CfildqKq5qvqB+70WAH+h+u+y/DGGAxcDd7txrcX5Xq4st9oaVX1ZVf3Aq0CiiLSrxeYvB+5z49sKPFBuu8VAF6Cbqhap6nfu+z4gChggImGqus6NyTQylhTMkdpY/oWI9BWRz9ymlAKcE0Z1J5rN5Z7vAWLqsG6X8nGoM8tjVjXbuQWYpKqfAzcCX7mJ4TjgP5V9QFV/BdYAZ4pIDE4iegPKRv38zW2CKQBWux+r6QTbBcjSg2elXF/6RESiReQlEdngbvfbWmyzVAfAW3577vOEcq8rfp9Q/fdfqnM1233Eff2NiKwRkf8FUNUVwB04/x62uk2OnWp5LKYBWVIwR6riNLv/xGk+6ek2E/wJkADHkAMklr5w280Tql6dMJy/XFHVj4C7cJLBFcDEaj5X2oR0Pk5lkum+fxVOZ/UJOM1oPUtDOZy4XeWHk/4BSAGGut/lCRXWrW6K462AH6fZqfy266NDPaeq7apqgarepqrJOE1hd4nIKHfZ66o6HOeYvMBf6yEWU88sKZj61grYCex2O1ur60+oL58C6SJytjgjoG7BadOuyrvAfSIySEQ8wK9AEdACp4mjKm/itIWPx60SXK2A/UAeThv+w7WMeybgEZHfu53EvwHSK2x3D7BDROJxEmx5W3D6Cw7hNqO9B/xFRGLcTvnbgNdrGVt13gT+JCLtRKQ9Tr/B6wDub9DDTcw7cRKTX0T6icgYtx9lr/vw10Mspp5ZUjD17Q7gt0AhTtXwdqB3qKpbgEuAJ3BOzD1w2ub3V/GRR4F/4wxJ3Y5THVyPc7L7TERaV7GfLGAuMAynY7vUZCDbfSwFZtUy7v04Vcc4YAdwAfBhuVWewKk88txtflFhExOBse5Inycq2cXvcJLdOuA7nH6Df9cmthrcDyzE6aReBMzhwF/9fXCauXYBPwBPqepMnFFVf8Pp69kMxAH31EMspp6J3WTHNDci4sU5QV+kqt8HOx5jmhKrFEyzICKniUgbt3niXpw+g5+CHJYxTY4lBdNcjMAZH78N59qI89zmGWPMYbDmI2OMMWWsUjDGGFOmKU1gBkC7du00OTk52GEYY0yTMm/evG2qWt1QbaAJJoXk5GTmzp0b7DCMMaZJEZH1Na9lzUfGGGPKsaRgjDGmjCUFY4wxZZpcn4IxpmEVFxeTlZXFvn37gh2KqYWoqCgSExMJDw+v0+ctKRhjqpWVlUWrVq1ITk7GvXGbaaRUlby8PLKyskhJSan5A5Ww5iNjTLX27dtHfHy8JYQmQESIj48/oqrOkoIxpkaWEJqOI/2tLClU4o03YOfOYEdhjDENz5JCBZs3w+WXw2s13nbdGNMQ8vLySEtLIy0tjU6dOpGQkFD2uqioqFbbuOaaa1ixYkW16/zjH/9gypQp9REyI0aMYMGCBfWyrYZmHc0V7Hfn1dy4sfr1jDENIz4+vuwEe9999xETE8Odd9550Dqqiqri8VT+d+7kyZNr3M+NN9545ME2AwGrFESkq4hMF5HlIrJURG6pZJ1zRWSRiCwQkbkiMiJQ8dSWz+f8d1N93MnWGBMwq1evZuDAgUyYMIH09HRycnIYP348GRkZDBgwgAceeKBs3dK/3H0+H7Gxsdx9990MHjyYY489lq1btwJwzz33MHHixLL17777boYOHUqfPn2YNcu5md7u3bu58MILGTx4MGPHjiUjI6PGiuD1119n0KBBDBw4kD/+8Y8A+Hw+rrzyyrL3J02aBMCTTz5J//79GTx4MFdccUW9f2e1EchKwQfcoarzRaQVME9EvlbVZeXW+Qb4WFVVRFJxbnHYN4Ax1cjv3jXWkoIxh7r1y1tZsLl+m0XSOqUx8bSJdfrssmXLmDx5Ms8//zwAjzzyCG3btsXn8zFmzBguuugi+vfvf9Bndu7cyahRo3jkkUe4/fbbefnll7n77rsP2baq8tNPP/Hxxx/zwAMP8OWXX/L000/TqVMnpk6dysKFC0lPTz/kc+VlZWVxzz33MHfuXNq0acNJJ53Ep59+Svv27dm2bRuLFy8GID8/H4C//e1vrF+/noiIiLL3GlrAKgVVzVHV+e7zQmA5kFBhnV164IYO0UDQb+5glYIxTUePHj04+uijy16/+eabpKenk56ezvLly1m2bNkhn2nRogWnn346AEcddRSZmZmVbvuCCy44ZJ2ZM2dy6aWXAjB48GAGDBhQbXxz5szhhBNOoF27doSHh3PZZZcxY8YMevbsyYoVK7jllluYNm0abdq0AWDAgAFcccUVTJkypc4Xnx2pBulTEJFkYAjODb4rLjsf56bfHYAzq/j8eGA8QLdu3QIVJnBwpaAKNhLPmAPq+hd9oERHR5c9X7VqFU899RQ//fQTsbGxXHHFFZWO14+IiCh77vV68ZX+JVhBZGTkIesc7k3Jqlo/Pj6eRYsW8cUXXzBp0iSmTp3KCy+8wLRp0/juu+/46KOPeOihh1iyZAler/ew9nmkAj76SERigKnArapaUHG5qn6gqn2B84AHK9uGqr6gqhmqmtG+fY3TgR+R0n8fe/ZAkKo3Y0wdFBQU0KpVK1q3bk1OTg7Tpk2r932MGDGCd955B4DFixdXWomUN2zYMKZPn05eXh4+n4+33nqLUaNGkZubi6rym9/8hvvvv5/58+fj9/vJysrihBNO4LHHHiM3N5c9e/bU+zHUJKCVgoiE4ySEKar6fnXrquoMEekhIu1UdVsg46pOaaUATrUQFxesSIwxhyM9PZ3+/fszcOBAunfvzvDhw+t9HzfddBNXXXUVqamppKenM3DgwLKmn8okJibywAMPMHr0aFSVs88+mzPPPJP58+dz3XXXoaqICI8++ig+n4/LLruMwsJCSkpKuOuuu2jVqlW9H0NNAnaPZnEuq3sV2K6qt1axTk9gjdvRnA58AiRqNUFlZGRoIG+yM3s2HHus8/zLL+HUUwO2K2OahOXLl9OvX79gh9Eo+Hw+fD4fUVFRrFq1ilNOOYVVq1YRFta4RvdX9puJyDxVzajps4E8kuHAlcBiESkdrvBHoBuAqj4PXAhcJSLFwF7gkuoSQkOoWCkYY0ypXbt2ceKJJ+Lz+VBV/vnPfza6hHCkAnY0qjoTqLabVlUfBR4NVAx1Ub7PyZKCMaa82NhY5s2bF+wwAsqmuajAKgVjTCizpFCBVQrGmFBmSaGC0kohPt6SgjEm9FhSqKC0UkhKUksKxpiQY0mhgoK9uwHQNpls3Qq1nJnXGBMgo0ePPuRCtIkTJ/K73/2u2s/FxMQAkJ2dzUUXXVTltmsa4j5x4sSDLiI744wz6mVeovvuu4/HH3/8iLdT3ywpVFCwz/nxN4f9BEBOTjCjMcaMHTuWt95666D33nrrLcaOHVurz3fp0oX33nuvzvuvmBQ+//xzYmNj67y9xs6SQgXFxSUA5HhmA5CVFcxojDEXXXQRn376Kfvdm51kZmaSnZ3NiBEjyq4bSE9PZ9CgQXz00UeHfD4zM5OBAwcCsHfvXi699FJSU1O55JJL2Lt3b9l6N9xwQ9m023/+858BmDRpEtnZ2YwZM4YxY8YAkJyczLZtzqQLTzzxBAMHDmTgwIFl025nZmbSr18/xo0bx4ABAzjllFMO2k9lFixYwLBhw0hNTeX8889nx44dZfvv378/qampZRPxfffdd2U3GRoyZAiFhYV1/m4r07yuuqgHxcXutXNt1gPW2WxMebfeCvV9Q7G0NJhYzTx78fHxDB06lC+//JJzzz2Xt956i0suuQQRISoqig8++IDWrVuzbds2hg0bxjnnnFPlfYqfe+45WrZsyaJFi1i0aNFBU18//PDDtG3bFr/fz4knnsiiRYu4+eabeeKJJ5g+fTrt2rU7aFvz5s1j8uTJzJkzB1XlmGOOYdSoUcTFxbFq1SrefPNNXnzxRS6++GKmTp1a7f0RrrrqKp5++mlGjRrFn/70J+6//34mTpzII488wrp164iMjCxrsnr88cf5xz/+wfDhw9m1axdRUVGH8W3XzCqFCop9TqVAmw2AJQVjGoPyTUjlm45UlT/+8Y+kpqZy0kknsWnTJrZs2VLldmbMmFF2ck5NTSU1NbVs2TvvvEN6ejpDhgxh6dKlNU52N3PmTM4//3yio6OJiYnhggsu4PvvvwcgJSWFtLQ0oPrpucG5v0N+fj6jRo0C4Le//S0zZswoi/Hyyy/n9ddfL7tyevjw4dx+++1MmjSJ/Pz8er+i2iqFCorc5qP0nt2YH7aXJav3Am2DG5QxjUR1f9EH0nnnncftt9/O/Pnz2bt3b9lf+FOmTCE3N5d58+YRHh5OcnJypdNll1dZFbFu3Toef/xxfv75Z+Li4rj66qtr3E51M/KUTrsNztTbNTUfVeWzzz5jxowZfPzxxzz44IMsXbqUu+++mzPPPJPPP/+cYcOG8Z///Ie+fevv3mRWKVTg8ztJ4fz+Z0OrTfz8a3aQIzLGxMTEMHr0aK699tqDOph37txJhw4dCA8PZ/r06axfv77a7YwcOZIpU6YAsGTJEhYtWgQ4025HR0fTpk0btmzZwhdffFH2mVatWlXabj9y5Eg+/PBD9uzZw+7du/nggw84/vjjD/vY2rRpQ1xcXFmV8dprrzFq1ChKSkrYuHEjY8aM4W9/+xv5+fns2rWLNWvWMGjQIO666y4yMjL49ddfD3uf1bFKoYIit0+hW2wCbToUsma9v4ZPGGMawtixY7ngggsOGol0+eWXc/bZZ5ORkUFaWlqNfzHfcMMNXHPNNaSmppKWlsbQoUMB5y5qQ4YMYcCAAYdMuz1+/HhOP/10OnfuzPTp08veT09P5+qrry7bxvXXX8+QIUOqbSqqyquvvsqECRPYs2cP3bt3Z/Lkyfj9fq644gp27tyJqnLbbbcRGxvLvffey/Tp0/F6vfTv37/sLnL1JWBTZwdKoKfOvvOhTP5+bzJvzP6aR+7pzKJ5Ldi9pTMtw1sGbJ/GNGY2dXbTcyRTZ1vzUQWlQ1Ijwr0kdfNAQSKrctcFOSpjjGkYlhQq8Pmdyiky3EvawCjwR/Lj4s1BjsoYYxqGJYUKSvsUwsM8HJ/hjDr66ZfdwQzJmKBras3MoexIfytLChX4fAcqhWFpzr1Xly+v9l5BxjRrUVFR5OXlWWJoAlSVvLy8I7qgzUYfVVA6S2p4uIdWrYSIttmsXx0T3KCMCaLExESysrLIzc0NdiimFqKiokhMTKzz5y0pVOBzr2iOcK8SjOu2me0bOgYzJGOCKjw8nJSUlGCHYRqINR9VUOwHxEe410kK3XoWsn9zCkXFdr2CMab5s6RQga8Y8PjwiheAfv0VfC2YvaTq+VSMMaa5sKRQgc+v4PET5nEqhaMHRwMw4+e8YIZljDENwpJCBT4fTqXgcSqFURntAZi/qPrJsYwxpjmwpFCBz6cgByqFfomJ0GYDK3+1PnljTPMXsKQgIl1FZLqILBeRpSJySyXrXC4ii9zHLBEZHKh4asvvBzy+sqQQ5gmjZZd1bFrbfG+/Z4wxpQJZKfiAO1S1HzAMuFFE+ldYZx0wSlVTgQeBFwIYT6343KRQ2tEM0D55GzuzOjsJwxhjmrGAJQVVzVHV+e7zQmA5kFBhnVmqusN9ORuo+xUX9cTv46COZoCUXnvQ4ijqMCOuMcY0KQ3SpyAiycAQYE41q10HfFHN8gZR2nxU2tEMMGiA83zO/F1BisoYYxpGwJOCiMQAU4FbVbWginXG4CSFu6pYPl5E5orI3EBfau/zcVBHM8Cw9NYA/DAvP6D7NsaYYAtoUhCRcJyEMEVV369inVTgJeBcVa30YgBVfUFVM1Q1o3379oELGPD75ZA+hYFdu0Hblfz0U0B3bYwxQRfI0UcC/AtYrqpPVLFON+B94EpVXRmoWA5HZX0K3eO6Q9dZLP8lDpso0hjTnAVy8P1w4EpgsYgscN/7I9ANQFWfB/4ExAPPOjkEX21uFxdIpZVC+aQQExFDfJ+V5C2MZs0a6NkziAEaY0wABSwpqOpMoNobEajq9cD1gYqhLvx+QPwHdTQDpB+zl6/fgR9+sKRgjGm+7IrmCkorBY8c/NWMzugIkflMn2HTXRhjmi9LChU4SaHkkPeHJmZA1x/5bqYvCFEZY0zDCJmk8MOGHzjnzXPYuHNjteuV+EG8h166nN45Hbr+wPpV0eTbyFRjTDMVMklhy+4tfLLyE/L3VX9G9/s9SCWVQtsWbencPxNVYfbsQEVpjDHBFTJJIcIbAUCRv6ja9Ur8gngqn+Ro2DEe8PiYNavewzPGmEbBkkIFJX7BU0mlADCs+0DouJDvvq9+G8YY01RZUqigxC+V9ikAZHTJgK6z+OknjzMdhjHGNDMhlxT2+/dXu57Tp1D5ZcvpndMh6Tv27QmzfgVjTLMUckmhpkpBSwSPt/Lmo9ioWFIy1iBeH599Vu8hGmNM0FlSqKCkitFHpY7p0ZeIlJ/49NN6Dc8YYxqFkEkKkd5IoBZJoZpKASCjcwb7u09lyRLYsKFeQzTGmKALmaRwOJVCdUlhTMoY6O2UCdaEZIxpbiwpVKB+Dx5v1fNjp3VKo21iHq06bbEmJGNMs2NJoYKSEg+eKkYfAXjEw0k9TsTf8xO+/VbZs6dewzTGmKAKuaSw31f9kFQtqb75CODk7iezJ+Vt9u0Tpk+vtxCNMSboQi4p1K5Pofrbq53c/WRImkFkyyI+/rjeQjTGmKCzpFBBbSqFpNgkenVIou3gWbz3HhTZrBfGmGYiZJKC1+PFK95adDR78dZQKYBTLWzv9RTbt8MXX9RXlMYYE1whkxTAqRZqUynUKin0OJn9SZ8QG1/Ea6/VV4TGGBNclhQq0BJvtaOPSo1JHoM3DHqOnMsnn2A33jHGNAshlxRqmhBPSzx4w2reVpuoNozoNoLcnk9QVATvvltPQRpjTBCFXFKorlJQBUrCahx9VOqSAZewvuVUknvu4/XX6ylIY4wJIksK5ZS4g45q06cAcGH/C/F4PHQb8T0zZsC6dfURpTHGBI8lhXJKb5wTFla7pNAhugMnppxIZvL9eL3Kc8/VR5TGGBM8lhTK8bs3XPN4a7/NSwdeygZ+YNSpO3jpJWzaC2NMkxawpCAiXUVkuogsF5GlInJLJev0FZEfRWS/iNwZqFhKRYZF1q5SOIykcH7f8wn3hNNuzFvs2AFvvHGEQRpjTBAFslLwAXeoaj9gGHCjiPSvsM524Gbg8QDGUaa2lUJt+xQA4lrEcWrPU/nB81cGDVKeftrtsDbGmCYoYElBVXNUdb77vBBYDiRUWGerqv4MFAcqjvJqGpJaWinUZkhqeZcOuJRNhVmcctkKFi2C778/giCNMSaIGqRPQUSSgSHAnDp+fryIzBWRubm5uXWOo/aVwuFt94J+FxAXFceaxAeJi4OJE+scojHGBFXAk4KIxABTgVtVtaAu21DVF1Q1Q1Uz2rdvX+dYaj/66PC22yK8BdcOuZZP1r7NVdcX8sEHsHhxncM0xpigCWhSEJFwnIQwRVXfD+S+aqO2lUKYVw572zdk3IBf/USOeJbWreH+++sapTHGBE8gRx8J8C9guao+Eaj9HI5AVQoAPdr24LSep/H66kn8/iY/U6fCwoV1DNQYY4IkkJXCcOBK4AQRWeA+zhCRCSIyAUBEOolIFnA7cI+IZIlI60AFFOmtfkjqgUqhbtv/XcbvyC7MpteZn9K6NTzwQN22Y4wxwVKHv4lrR1VnAtW2w6jqZiAxUDFUVNtKwRtet+2f0esMktok8fKvf+fWW8/lgQfgl19gyJC6bc8YYxpayF3RXN09mksrhfA69CmAcyOf24+9ne83fM/QC38gPh5uv92uWzDGNB0hlxSqqxSKi52zd1hY3ZICwLj0cXSM7sjEhffxwAPw3//Chx/WeXPGGNOgLCmUs7/YKRXqMvqoVIvwFtx53J38Z+1/SD1jNv37w513wv7qb+NgjDGNQkgmBa2iPae42Jk7Ozy87kkBYELGBOJbxPPXWQ/y5JOwdi1MmnREmzTGmAYRcklBUfzqr3R5aaVwuNNcVBQTEcPtx97O56s+J27Az5x1lnPdQmbmkW3XGGMCLaSSQqQ3EqDKJqRin1MpRIQd+dfy+6G/p0N0B27/6naefloRgfHjrdPZGNO4hVRSiPBGAFQ5AqmsT+EIOppLtY5szUNjHmLmhpn8tPtdHn0Uvv4aJk8+4k0bY0zAhGRSqKlSCK+HpABw7ZBrGdxxMH/4+g/89rq9jBzpDFHdtKleNm+MMfXOkkI5RUWlSaF+vhavx8uTpz7J+p3rmTjnCf71Lygqgt/+9sD9oI0xpjGxpFBOkc9pPgqv4xXNlRmTMoYL+l3Aw98/jCd+LU8/Dd98A48+Wn/7MMaY+mJJoZxin9MLHF7XyY+q8NRpTxHmCWPcJ+O45hrlkkvg3nth1qx63Y0xxhwxSwrllFUK9dSnUCqxdSKPnfwY3677lskLXuaf/4Ru3WDsWNi2rV53ZYwxRySkkkJkWPVDUouK67dPobxxR41jVNIo7vjqDnbJJt55B7ZsgYsvhuIGuRmpMcbUrFZnPxHpISKR7vPRInKziMQGNrT6VzYktYr7NPvcuY8iwus/KXjEw0vnvESRv4irPryKIel+XnwRpk+HO+6o990ZY0yd1PbsNxXwi0hPnBvnpABvBCyqAKm5+cipFOrjOoXK9Gzbk2fOeIZv133Lw98/zJVXwm23wdNPw4svBmSXxhhzWGqbFEpU1QecD0xU1duAzoELKzBqSgo+t6M5Mrx+O5rLuybtGq5IvYL7v7uf/2b+l7/9DU47DSZMgE8+CdhujTGmVmqbFIpFZCzwW+BT9716HLjZMGqsFALYp1BKRHj2jGfp2bYnY6eOZcueTbz7LqSnO/0LNiLJGBNMtT37XQMcCzysqutEJAV4PXBhBUaNlYLfnfsoAH0K5bWKbMXUi6eyq2gX5751Lp7IPXz2GSQmwlln2b2djTHBU6uzn6ouU9WbVfVNEYkDWqnqIwGOrd7VeJ2COwooop6vU6jMwA4DeeOCN5ifM59rPrqG9u2Vr76C6Gg46SRYujTgIRhjzCFqO/rovyLSWkTaAguBySLyRGBDq3+1nfsoIqJhRuqe3edsHj3pUd5Z+g73fHsPKSnw7bfOFdUnngi//togYRhjTJnanv3aqGoBcAEwWVWPAk4KXFiBUTp1dlWzpJZ2NAe6+ai8O4+7k3Hp4/jLzL8wcfZEevVyEoMqjBoFixY1WCjGGFPrpBAmIp2BiznQ0dzk1Haai4ZoPiolIjx35nNc0O8Cbpt2G68tfI2+feG77yAiwkkMP/7YYOEYY0JcbZPCA8A0YI2q/iwi3YFVgQsrMGoekur8N5BDUivj9Xh544I3ODHlRK756BreXvI2ffvCzJnQrp3Tx/DZZw0akjEmRNW2o/ldVU1V1Rvc12tV9cLAhlb/ak4KpaOPGjYpgDMFx4eXfsjwbsO57P3LeH3R6yQlwfffQ9++cM458OyzDR6WMSbE1LajOVFEPhCRrSKyRUSmikhiDZ/pKiLTRWS5iCwVkVsqWUdEZJKIrBaRRSKSXtcDqY1wr3NpRdXNRwAl9T5Lam3FRMTw+WWfMzp5NFd9cBUvzX+JTp2cpqQzz4Qbb3SugC6taIwxpr7VtvloMvAx0AVIAD5x36uOD7hDVfsBw4AbRaR/hXVOB3q5j/HAc7WMp0484iHME1ZlUvD7FTx+wjxhgQyjWtER0Xw69lNO7Xkq4z4Zx0MzHiI6WvngA7j5Zpg40bkCOi8vaCEaY5qx2iaF9qo6WVV97uMVoH11H1DVHFWd7z4vBJZmVK+bAAAfy0lEQVTjJJTyzgX+rY7ZQKzboR0wEd6I6isFjy+oSQGgRXgLPrr0I65MvZJ7p9/LjZ/fiIqPp56Cl192mpQyMmD+/KCGaYxphmqbFLaJyBUi4nUfVwC1/ltVRJKBIcCcCosSgI3lXmdxaOJARMaLyFwRmZubm1vb3VYq0htZ5Sypfr+C+PFKcJqPyovwRvDqea/yh+P+wHNzn+OsN84if18+11zjJAWfD449Fp55xhm+aowx9aG2SeFanOGom4Ec4CKcqS9qJCIxOLOs3upe63DQ4ko+csgpTlVfUNUMVc1o377aAqVG1VYKxTSKSqGUiPDoyY/ywlkv8M26bxj20jBW5q1k6FBYsABOPhluugkuusiak4wx9aO2o482qOo5qtpeVTuo6nk4F7JVS0TCcRLCFFV9v5JVsoCu5V4nAtm1iamuqksKfj/g8eP1BL9SKG/cUeP45qpvyNubx9EvHs37y98nPh4+/hgee8yZXXXgQPjii2BHaoxp6o7k0t3bq1soIoJz74XlqlrVlBgfA1e5o5CGATtVNecIYqpRdUnB56dRVQrljUwaydxxc+nbri8XvnMht315Gz4t4s474aefnOsZzjgDrrsOduwIdrTGmKbqSJJCTXeiGQ5cCZwgIgvcxxkiMkFEJrjrfA6sBVYDLwK/O4J4aqXaSsFHo+lTqExSbBLfX/M9Nw29iYlzJjLspWEsz11OWhr8/DPcdRe8+ir07w/vv299DcaYw3ckSaHaU46qzlRVcS96S3Mfn6vq86r6vLuOquqNqtpDVQep6twjiKdWqq0UGsnoo+pEeCOYdPokPrzkQzYWbCT9hXSenvM0EZElPPKIUzV06gQXXuhMw71mTbAjNsY0JdUmBREpFJGCSh6FONcsNDkR3ohqRh8R9OsUauvcvuey+IbFjEkew81f3syoV0axMm8l6elOYnjiCZgxAwYMgHvvhV27gh2xMaYpqDYpqGorVW1dyaOVqjb+M2clIsMia+ho9jW6juaqdIrpxGeXfcbkcyezZOsSUp9L5aEZD1Ei+7ntNlixwqkYHnoIevWCl16yq6GNMdVruDmiG4nqRx8JSNOoFEqJCFenXc2y3y3j7D5nc+/0exn03CCmrZ5Gly4wZQrMng3du8O4cZCaCh98YP0NxpjKWVIox+/2KTTWjubqdG7VmXd/8y7TrpgGwGlTTuPMN85kee5yjjnGmXG1tPP5ggvgmGPgq68sORhjDmZJoRy/X8DjxyNN92s5pccpLL5hMY+d/BgzN8xk0HODuOHTG8jZlc3558PixfCvf8GWLXDqqc79Giw5GGNKNd2zXx3VJik4l1g0XZFhkdx53J2svmk1EzIm8NIvL9FjUg/+8PUf2L5/K9deCytXOlNkrFnjJIejj4Z333X7VYwxIcuSQjklfhBP8zkrto9uzzNnPMOK36/gN/1/w+OzHid5YjK3T7udvKJsbrwR1q6FF1+EggK4+GKnQ/qZZ2y0kjGhKiSTQlX3aPb7BfE2n6RQqntcd/59/r9ZfuNyfjPgN0yaM4nkiclc99F1rC1YzvXXw/LlMHWqc43DTTdBYiLccQesWxfs6I0xDSnkkkKkt7ohqYJ4Sho4oobTp10fXj3vVVbetJLxR43nzSVv0v/Z/pz5xpl8m/k155+vzJoFs2Y592x46ino0cO5CO7zz61pyZhQEHJJofrmI2lWzUdV6R7XnWfOeIb1t67nvlH3MTd7Lqe8fgoDnxvI03Oept+QfN56CzIz4Z57YO5c585vKSnw5z9b9WBMc2ZJoRwnKYTOMJz20e358+g/s+HWDUw+dzIxETHc/OXNdPl7F67+8GrW+b/n/vuVDRvg7behXz948EHnmodRo5yL4fLzg30Uxpj6ZEmhnBK/B08z7FOoSWRYJFenXc2c6+cwb/w8rky9kveXv8/IV0bS9x99eWz2wxxzynqmTXOqhIcecoa0jht3YJ6lqVNhz55gH4kx5kiFZFIoLilGKxmYX1LSvPsUaiO9czr/PPuf5NyRw+RzJ9M5pjP3TL+H5KeSGfXKKL7IfZ7/uW0by5c7cyxNmAA//ODc6Kd9e2cE09tvQ2FhsI/EGFMXIZkUAIpLig9Z5vd7EG9oJ4VS0RHRXJ12Nf+9+r+su2UdD455kNzdudzw2Q10erwTp7x+MvPln9z90GaysuDrr+Gqq+C77+DSS537O5x5pjPcNSegd8gwxtSnkE0KlQ1LVb/gCaE+hdpKjk3mnpH3sPR3S1nwPwv4w/A/sD5/PRM+m0CXv3fh+FeP5efIv3LDfYvYtEmZMQN+/3tnmOv48dClCwwdCvfd51QXJZZ3jWm0QjYpVNavEKp9CrUlIgzuNJi/nPgXVvx+BYsmLOKBMQ/gK/Hxx2//yODnB9P96SRez/8fhl//PvOX7mTxYqcPIiwMHnjAmXOpQwenmnj5ZdiwIdhHZYwpr+lMB1pPIr2RQBVJocRjlUItiQiDOg5iUMdB3DPyHrILs/l81ed8uvJT3ljyBi/MfwGveBmaMJSTjjuJv15+Ij2jhvHdt5FMm+bMt/T22862evaEE06AMWOcR8eOwT02Y0KZVNbh2phlZGTo3Ll1v0Hb5F8mc+3H15J5SyZJsUkHLYvuuJnI5Llsn3PWkYYZ0or8RczOms201dP4Zt03/Jz9MyVaQlRYFMcmHsvIpJGM6Ho8rQuOZdZ3LfnmG6cvorRzuk8fZ8jryJEwYgR06wZNfDoqY4JOROapakZN64VcpVBd85FaR3O9iPBGMDJpJCOTRvIwD5O/L5/v13/P9MzpTM+czgPfPYCieMVLWqc0hv9uOJc+eBzRecezYm5nZswQ3noLXnjB2V5CAhx3nPMYNgyGDIHIyOAeozHNlSWFckpKPHi9Tatyagpio2I5u8/ZnN3nbAB27tvJrI2z+GHjD/yw8Qde+uUlJv00CYAO0R0YesVQbrtjKPGFoylcPZhFP7fmxx+dWVwBwsMhLc2Z2TUjw3n06+f0WxhjjkzI/W9UNvqokvs0a4kHjyWFgGsT1YbTe53O6b1OB6DYX8ySrUuYnTWb2Ztm8/Omn/ls5Wcozm/R+ejODDlnCOd6RxK5+Xjy1/Rl1eI4XntNePZZZ5tRUTB4MKSnO5VEWhoMHAgtWgTrKI1pmkI2KVTafGQdzUER7g1nSOchDOk8hBuOvgGAwv2FLNi8gHk585ifM59fNv/CtNz/h1/9EA8tT25Jv0sH0K34ZFrkjmDvxn5kr+jElCmRPPec0wHh8UDv3s4tSFNTYdAgGDDAmcPJE3Lj7oypHUsK5ajfizfM+hQag1aRrTg+6XiOTzq+7L29xXtZlruMRVsWsWjLIhZvXcwPhS+x1fMXSAKSIPrMGAZxIm13noBn6xB2bejBrDnteOediLLttGgBfftC//7Oo29fp/mpRw+IiKgkGGNCSMglhciwqoekWqXQuLUIb8FRXY7iqC5HHfR+7u5cluUuY2nuUn7d9ivLty1nedTf2NRyEyQDI4H9rei45wTaFo4gLC+NPVt6MO3bjkyZ0rJsO16vU0X06eNUGL16OY+ePaFrV2e5Mc1dwJKCiLwMnAVsVdWBlSyPA14GegD7gGtVdUmg4ilVffORF2+YJYWmpn10e0ZFj2JU8qiD3t9VtIsV21awavsqVuatZGXeSlZvf49V2//K9r3bnZX2x8C2PsQUHE2rwgz2be/HT8uS+eo/7SneH162rfBwJ2H07Ok8UlKc2WJLHy1bYkyzEMhK4RXgGeDfVSz/I7BAVc8Xkb7AP4ATAxgPUIs+BftrsNmIiYiptLIAyN+Xz9oda1mzfQ3r8texdsdaMvPfJTM/k9z8TIqLi6CwC2zvCdt7IjsHsrmwPzlLe/D19ASK90YdtL2OnUpITvKQlATJyQceSUnOIzq6QQ7ZmCMWsKSgqjNEJLmaVfoDf3XX/VVEkkWko6puCVRMUIs+BRt9FBJio2JJ75xOeuf0Q5aVaAlbd28lMz+T9fnr2bBzA+t3rmZjwXQ27tzIhp0bydumsKMH7EiBHT3YsqM727b1YP7aFHw7OqO+gzsn2sQV07VbCd1TwkhJ8pKU5FyUl5joNE116mSd36ZxCGafwkLgAmCmiAzF6SpMBA5JCiIyHhgP0K1btyPaaVUT4qkC6rV2Y4NHPHSK6USnmE4MSxxW6Tp7i/eSVZDFpsJNZBVkkVWQRXbhQjYVbmLTzhw2ZBWzdVNL/DsSYGcSO/OT2LkziSUzk+DzblAUc/A+vX7adtxL5wQfXbsKPZIj6JkURbduQmKikzw6dLDEYQIvmEnhEeApEVkALAZ+AXyVraiqLwAvgDPNxZHstKpKofT+w9anYGqjRXgLesX3old8ryrXKdEStu3ZRnZhNjmFOeTsyiG7cB7ZBTls2FLIhg2wJTuC7Ztb4svvzLaCRLZt7cri1V2hIBH8B8/tIV4freILadtxHx07++iaKKR0i6B3cjS9kluSmCgkJDjXbBhTV0FLCqpaAFwDICICrHMfAVVjUrBKwdQTj3joEN2BDtEdSOuUVuV6qsrO/TvZvGszOYU5bNn9M9kFn5C5aTfrNhSTtVHI3RJB/tYYCvJiKSjoQua8BOb8NwGKWh2yvfCYAmLidxLXYQ/tOxbTuTN0TQine7cW9E1pTb/urenS2UN4eCXBmJAXtKQgIrHAHlUtAq4HZriJIqCqmiXV59Yo1qdgGpqIEBsVS2xULH3b9a12XX+Jn7y9eWzZtYUtu+ewbnMeq9fvJXO9j03ZsHVzODu2tGBXXht2bIpn7fIusLsj6KF/7YS12k6LuB20breL+I776diphMQuHpK7RdAnOYYBPeLokxRHeJi1WYWSQA5JfRMYDbQTkSzgz0A4gKo+D/QD/i0ifmAZcF2gYinPKgXTlHk93rLqYxCDoDtwXOXrlmgJO/buILtgBSs3bGfl+l1kbtzPxiw/mzd7ydsawc7cGHK3tmHTyq6wqyOH3GLF48PTagtRcXnExBfStsNeOnYuJqGLh+SuEfRMiqZ/Shz9unWgddShVYtpegI5+mhsDct/BKpukA2QqpJCaaVgk6qZ5sIjHuJbxhPfMp5BnYChVa+rquTt3smyzG0sX1vAmvV7ydxQTHYObN0cxo6tLSjIaU/usnb8ujf20A149yOtNhARm0dMfD5xHfbSoVMxiQlCSlIEfVKiGdSzLd07dCYuKg6xudAbrZA7BYZ5nEO2SsGYA0SEdjGxjBwYy8hDLjU92O49JSxbm8+S1TtYs2E3mVn7yMouYesWL9u3tKAwuzs7lsazel/MoR9usQ1ps4iotnm0bl9Au0776JLgJ7lbGH26t2Rgz1h6duxCl1ZdaBFusxkGQ8glBREhwhtxyCypVikYUzvRLT0cPbAtRw9sW+16BQWwOnMPi1fvYMW6XaxdX8SGjcrWnHC2b+3O9vmxbCmMZWnFD7bIg9YrCY/bSqv2O2jXeS+JXf2kJHnp1yOaQT3jSYlPJLF1oiWOAAjJU2CEN8IqBWMCrHVrSE9tSXpq1XOA7NsHWVmwYu1ulqzKZ8XaPazP8pGd1YJtW/pQsKAN279vw8ryHxI/tMqGNvOJaLuF2I4FdErYT7du0KdHFIN6t6ZfYgLJscm0b9nemqoOkyUFl1UKxjS8qKjS+aSiOfOUyucC2bMHNmyAVWuLWLwqn1/X7GFdpo9NWQnk5fQmd0ksW/3hLAI+LdvwdojNxNP2R2I7badT1z2kdFf69YpiSN84+nRMJiUuxfo3KhEyp8AvvoCbb3buBRzpjayyUgjz2j8QYxqTli2d6c379o3gbDocsrykBDZvhsxM5dc1e1i0cier1u4nM7Mtm7O6kP99HNuLI1kGfOZ8AlpvgrjFhLfLol2XnSQmF9G7p5ch/VszOCWRXvE9SWydiDcEJ0MLmaQQHQ2rV8PChVYpGNOceDzQpQt06SIcd1w0cHDFoeokjTVrYOnKPfyyrIAVq5X1mT3Ysm4wOfNiyQF+BqYAROZD29V42s0mLnEbXVP20a+Pl4xBrUlLTqZ3fG8SWiU02wojZE6BqanOfxcuhIjoqvsUwsKa5w9tTKgSgc6dnceIES2Bg/s49u6Fdetg5So/vywrYOHy3axa1YlNmSnkLYklT70sAN4EaLkV4lcS1uEbOiTtoEfvYgYPiGTYwI4M7NSXPu36EBXWtOcZCZmkEBvrTGG8cCFEHH/o6KOi4hLAY5WCMSGmRYvSu/B5Oe/cOCCubNn+/bB2LaxYWcLcxQXMX1zMqlXd2bRmMNnzWpENfA884ymCtquh3ZfEJuaQ3Hs3gweGMyK9HUO69qV/+/5NZqRUSJ0CBw92kkLU6EMrhaJiP+CxPgVjTJnISOdWrf36eTjv3FjgwIV7+fmwYgUsWlLE7IX5LF7WmnWrhpM3PY4F/wljAfCq+CFuLXT4krZJ2fTos4+MIRGMTk9gSMIgerTtgUca1zQiIZcUPv0UMkpas8+376Bl+4v9QDjh4ZYUjDE1i42FY46BY46JYFy5DvCiIqf/ctFiPzPn7WDewhasXjGCvK/b8vM0Lz8Dz4XthfZL8Xb5N1175zF4sDJmWFuO7TmQQR0GBbWqCLmkUFICLXccTVbJpwctcyoFG31kjDkyEREHmqMuvaRd2fv798Ovv8Lc+UX8d85OflnYmbXL+pI5L4bMN+EjgLYrkS4f07FnNqlDijlpRCzH904lrVNag/VVhFxSAAjPzSBTn0FVy0YQlCaFcOtoNsYEQGSkcw4aPDiC667pBDgjo7Kz4ZdflOk/5jPr52iWLzqFzUvi2PwhfAUQvwJJeJ8ufTYx7qLu/PniCwMaZ0glhe7dISYGirL7si92H1t2b6FTjPPjFPlKABt9ZIxpOCKQkAAJCcJZZx3o5M7Lg7lzlW9m7uS7Wa1YtvBMNi1qw+zoX+DiwMYUUknB44FBg2DbukToD+t2rDuQFIqdpGB9CsaYYIuPh1NPFU499UDndnY2iAwJ+L4bV7d3Axg8GDasiAWFdfkHbvR2oPko5L4SY0wT0KWLc61FoIXcGXDwYCgs8MLObqzbcSApFJdWCtZ8ZIwJYSGZFADa5I8iMz+z7P3SPoWI8JD7SowxpkzInQEHDXI6d1rtGH5Q81Gxz7k3s3U0G2NCWcglhZgY6NED2Jx2cJ+Cz+lTsErBGBPKQvIM2L8/7NuSzIadG/CXOMmguNipFKyj2RgTykLyDNi7N+Rnx+Pz+ckqyAKguLRPwZKCMSaEheQZsHdv8BWFQUHXss7msusULCkYY0JYSJ4Be/d2n+T1LutX8LkdzRERIfmVGGMMEKJJoVcv90len7JrFUqbj6xSMMaEspA8A3bu7NyeM6ZwyCGVQmR46N2T1RhjSgUsKYjIyyKyVUSWVLG8jYh8IiILRWSpiFwTqFgO3bfThBSeP6AsKRTZ6CNjjAlopfAKcFo1y28ElqnqYGA08HcRiQhgPAfp3Rt8uSllHc1WKRhjTACTgqrOALZXtwrQSpwbGsS46/oCFU9FvXrBrq3tydq+lf2+/RT73UrBLl4zxoSwYJ4BnwH6AdnAYuAWVS2pbEURGS8ic0Vkbm5ubr3svHdv0BIP5DsXsVmlYIwxwU0KpwILgC5AGvCMiLSubEVVfUFVM1Q1o3379vWy8/LDUjPzM/G5fQoRlhSMMSEsmEnhGuB9dawG1gF9G2rnB4al9iarIItit+EqIsySgjEmdAUzKWwATgQQkY5AH2BtQ+28bVuIj1fI68Wmwk34/AqUEBEWUjejM8aYgwRySOqbwI9AHxHJEpHrRGSCiExwV3kQOE5EFgPfAHep6rZAxVOZ3r2FsPwBbCrYhM8HeHx4PVYpGGNCV8D+LFbVsTUszwZOCdT+a6N3b5i7vPeBSsHjJ8xjlYIxJnSF9PjL3r2hOL8jG7bl4SvGqRTEKgVjTOgK6aRQ2tm8cV0kfj8gVikYY0JbSCeFIUOc/25fkuFMne3xWVIwxoS0kE4KPXtCz7TNMG8cBXv3gMdvHc3GmJAW0kkB4NzLN8P2XqyZl2KVgjEm5IV8Urj4Ig+0yGP3lk4gfutoNsaEtJBPCt07dIHBrzovrFIwxoS4kE8K8S3iCR/6ivPCrlMwxoS4kE8KIkJC90JIng6RBXgk5L8SY0wIsz+LgYRWCWT+5mI8xW0QWR3scIwxJmjsz2IgoXUCRG8jLH5jsEMxxpigsqSAUykA1p9gjAl5lhSwpGCMMaUsKeA2H4Fdo2CMCXmWFLBKwRhjSllSoFylYPMeGWNCnCUFoEurLoBVCsYYY0kBiAqLIr5FvCUFY0zIs6TgSmidYB3NxpiQZ0nBldAqwSoFY0zIs7Og6/ZjbyenMCfYYRhjTFBZUnCd1P2kYIdgjDFBZ81HxhhjylhSMMYYUyZgSUFEXhaRrSKypIrl/ysiC9zHEhHxi0jbQMVjjDGmZoGsFF4BTqtqoao+pqppqpoG/B/wnapuD2A8xhhjahCwpKCqM4DanuTHAm8GKhZjjDG1E/Q+BRFpiVNRTK1mnfEiMldE5ubm5jZccMYYE2KCnhSAs4Efqms6UtUXVDVDVTPat2/fgKEZY0xoaQxJ4VKs6cgYYxoFUdXAbVwkGfhUVQdWsbwNsA7oqqq7a7nNXGD9YYbSDth2mJ9prOxYGic7lsarOR3PkRxLkqrW2NQSsCuaReRNYDTQTkSygD8D4QCq+ry72vnAV7VNCO5nD7v9SETmqmrG4X6uMbJjaZzsWBqv5nQ8DXEsAUsKqjq2Fuu8gjN01RhjTCPQGPoUjDHGNBKhkhReCHYA9ciOpXGyY2m8mtPxBPxYAtrRbIwxpmkJlUrBGGNMLVhSMMYYU6ZZJwUROU1EVojIahG5O9jxHA4R6Soi00VkuYgsFZFb3PfbisjXIrLK/W9csGOtLRHxisgvIvKp+zpFROa4x/K2iEQEO8baEpFYEXlPRH51f6Njm+pvIyK3uf/GlojImyIS1VR+m8pmY67qdxDHJPd8sEhE0oMX+aGqOJbH3H9ji0TkAxGJLbfs/9xjWSEip9ZXHM02KYiIF/gHcDrQHxgrIv2DG9Vh8QF3qGo/YBhwoxv/3cA3qtoL+MZ93VTcAiwv9/pR4En3WHYA1wUlqrp5CvhSVfsCg3GOq8n9NiKSANwMZLgXmXpxZhloKr/NKxw6G3NVv8PpQC/3MR54roFirK1XOPRYvgYGqmoqsBJnRmncc8GlwAD3M8+657wj1myTAjAUWK2qa1W1CHgLODfIMdWaquao6nz3eSHOSScB5xhedVd7FTgvOBEeHhFJBM4EXnJfC3AC8J67SlM6ltbASOBfAKpapKr5NNHfBud6pRYiEga0BHJoIr9NFbMxV/U7nAv8Wx2zgVgR6dwwkdassmNR1a9U1ee+nA0kus/PBd5S1f2qug5YjXPOO2LNOSkkABvLvc5y32ty3OlChgBzgI6qmgNO4gA6BC+ywzIR+ANQ4r6OB/LL/YNvSr9PdyAXmOw2h70kItE0wd9GVTcBjwMbcJLBTmAeTfe3gap/h6Z+TrgW+MJ9HrBjac5JQSp5r8mNvxWRGJxpxW9V1YJgx1MXInIWsFVV55V/u5JVm8rvEwakA8+p6hBgN02gqagybnv7uUAK0AWIxmlmqaip/DbVabL/5kTk/+E0KU8pfauS1erlWJpzUsgCupZ7nQhkBymWOhGRcJyEMEVV33ff3lJa8rr/3Rqs+A7DcOAcEcnEacY7AadyiHWbLKBp/T5ZQJaqznFfv4eTJJrib3MSsE5Vc1W1GHgfOI6m+9tA1b9DkzwniMhvgbOAy/XAhWUBO5bmnBR+Bnq5oygicDplPg5yTLXmtrn/C1iuqk+UW/Qx8Fv3+W+Bjxo6tsOlqv+nqomqmozzO3yrqpcD04GL3NWaxLEAqOpmYKOI9HHfOhFYRhP8bXCajYaJSEv331zpsTTJ38ZV1e/wMXCVOwppGLCztJmpsRKR04C7gHNUdU+5RR8Dl4pIpIik4HSe/1QvO1XVZvsAzsDpsV8D/L9gx3OYsY/AKQcXAQvcxxk4bfHfAKvc/7YNdqyHeVyjcaZTB6dt/iecTrJ3gchgx3cYx5EGzHV/nw+BuKb62wD3A78CS4DXgMim8tvg3IslByjG+ev5uqp+B5wml3+454PFOCOugn4MNRzLapy+g9JzwPPl1v9/7rGsAE6vrzhsmgtjjDFlmnPzkTHGmMNkScEYY0wZSwrGGGPKWFIwxhhTxpKCMcaYMpYUjHGJiF9EFpR71NtVyiKSXH72S2Maq7CaVzEmZOxV1bRgB2FMMFmlYEwNRCRTRB4VkZ/cR0/3/SQR+cad6/4bEenmvt/Rnft+ofs4zt2UV0RedO9d8JWItHDXv1lElrnbeStIh2kMYEnBmPJaVGg+uqTcsgJVHQo8gzNvE+7zf6sz1/0UYJL7/iTgO1UdjDMn0lL3/V7AP1R1AJAPXOi+fzcwxN3OhEAdnDG1YVc0G+MSkV2qGlPJ+5nACaq61p2kcLOqxovINqCzqha77+eoajsRyQUSVXV/uW0kA1+rc+MXROQuIFxVHxKRL4FdONNlfKiquwJ8qMZUySoFY2pHq3he1TqV2V/uuZ8DfXpn4szJcxQwr9zspMY0OEsKxtTOJeX++6P7fBbOrK8AlwMz3effADdA2X2pW1e1URHxAF1VdTrOTYhigUOqFWMaiv1FYswBLURkQbnXX6pq6bDUSBGZg/OH1Fj3vZuBl0Xkf3HuxHaN+/4twAsich1ORXADzuyXlfECr4tIG5xZPJ9U59aexgSF9SkYUwO3TyFDVbcFOxZjAs2aj4wxxpSxSsEYY0wZqxSMMcaUsaRgjDGmjCUFY4wxZSwpGGOMKWNJwRhjTJn/D/RIyjHPOoLhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.clf()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "loss_values = model_val_dict['loss']\n",
    "val_loss_values = model_val_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'blue', label='Validation loss')\n",
    "\n",
    "plt.title('Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VNX5+PHPk0lCgIQ9oAKyydeyBtKIWnFB+KJUBUWsoNYFV1xb67ellZ9al9Zqa11qtVahtqWggigqolXBpRZZlB0VBNTIFiBAwpbt+f1x7kwmyUxmEjKZJPO8X695MffOvTPnzoT73POcc88RVcUYY4ypTlK8C2CMMabhs2BhjDEmIgsWxhhjIrJgYYwxJiILFsYYYyKyYGGMMSYiCxamToiIT0QKReTYuty2oRORf4rIPd7zM0RkTTTb1uJzmsx3ZhonCxYJyjvx+B9lInIwaPnSmr6fqpaqarqqflOX29aGiJwgIp+KSIGIfC4iI2LxOZWp6kJV7VcX7yUiH4nIlUHvHdPvzJhILFgkKO/Ek66q6cA3wHlB66ZX3l5Ekuu/lLX2Z2Au0Ar4IfBdfItjwhGRJBGx81AjYD+SCUlE7heRF0RkhogUAJeJyMkiskhE9ojIVhF5XERSvO2TRURFpLu3/E/v9Te9K/z/ikiPmm7rvT5KRL4Ukb0i8oSI/Cf4qjuEEuBrdTaq6roIx7peRM4OWk4Vkd0iMtA7mc0SkW3ecS8UkT5h3meEiGwOWv6+iCz3jmkG0CzotfYiMk9E8kQkX0ReE5HO3mu/A04GnvZqeo+G+M7aeN9bnohsFpFfioh4r10jIu+LyB+9Mm8UkZHVHP8Ub5sCEVkjIqMrvX69V0MrEJHVIpLlre8mIq94ZdgpIo956+8Xkb8F7X+ciGjQ8kcicp+I/BfYDxzrlXmd9xlficg1lcow1vsu94nIBhEZKSITROSTStv9QkRmhTtWU3sWLEx1LgD+BbQGXsCdhG8DOgCnAGcD11ez/yXA/wPa4Wov99V0WxHpCLwI/J/3uZuAIRHKvRj4g/+kFoUZwISg5VHAFlVd6S2/DvQGjgJWA/+I9IYi0gx4FZiKO6ZXgfODNkkC/gocC3QDioHHAFT1F8B/gRu8mt5PQnzEn4EWQE/gTOBq4PKg138ArALaA38EnqumuF/ifs/WwAPAv0Skk3ccE4ApwKW4mtpYYLdX03wD2AB0B7rifqdo/RiY6L1nLrAdOMdbvhZ4QkQGemX4Ae57/BnQBhgGfA28AhwvIr2D3vcyovh9TC2oqj0S/AFsBkZUWnc/8F6E/e4AXvKeJwMKdPeW/wk8HbTtaGB1LbadCHwY9JoAW4Erw5TpMmApLv2UCwz01o8CPgmzz/eAvUCat/wC8Ksw23bwyt4yqOz3eM9HAJu952cC3wIStO9i/7Yh3jcHyAta/ij4GIO/MyAFF7j/J+j1m4B3vOfXAJ8HvdbK27dDlH8Pq4FzvOfvAjeF2OZUYBvgC/Ha/cDfgpaPc6eaCsd2V4QyvO7/XFygezjMdn8Ffu09HwTsBFLi/X+qKT6sZmGq823wgoh8T0Te8FIy+4B7cSfPcLYFPT8ApNdi22OCy6HurJBbzfvcBjyuqvNwJ9C3vSvUHwDvhNpBVT8HvgLOEZF04FxcjcrfC+khL02zD3clDdUft7/cuV55/b72PxGRliLyrIh8473ve1G8p19HwBf8ft7zzkHLlb9PCPP9i8iVIrLCS1ntwQVPf1m64r6byrriAmNplGWurPLf1rki8omX/tsDjIyiDADP42o94C4UXlDV4lqWyVTDgoWpTuUhif+Cu+o8TlVbAXfhrvRjaSvQxb/g5eU7h9+cZNxVN6r6KvALXJC4DHi0mv38qagLgOWqutlbfzmulnImLk1znL8oNSm3J7jb68+BHsAQ77s8s9K21Q0HvQMoxaWvgt+7xg35ItITeAqYBLRX1TbA55Qf37dArxC7fgt0ExFfiNf241JkfkeF2Ca4DaM5MAv4LdDJK8PbUZQBVf3Ie49TcL+fpaBixIKFqYkMXLpmv9fIW117RV15HcgWkfO8PPltQGY1278E3CMiA8T1svkcKAKaA2nV7DcDl6q6Dq9W4ckADgO7cCfAB6Is90dAkojc7DVOXwRkV3rfA0C+iLTHBd5g23HtEVV4V86zgN+ISLq4zgA/xaXEaiodd+LOw8Xia3A1C79ngZ+LyGBxeotIV1ybyi6vDC1EpLl3wgZYDpwuIl1FpA0wOUIZmgGpXhlKReRcYHjQ688B14jIMHEdDrqIyPFBr/8DF/D2q+qiWnwHJgoWLExN/Ay4AijA1TJeiPUHqup24GLgEdzJqRfwGe4EHsrvgL/jus7uxtUmrsEFgzdEpFWYz8nFtXWcRMWG2mnAFu+xBvg4ynIfxtVSrgXycQ3DrwRt8giuprLLe883K73Fo8AELzX0SIiPuBEXBDcB7+PSMX+PpmyVyrkSeBzXnrIVFyg+CXp9Bu47fQHYB7wMtFXVEly6rg/uyv8bYJy323xgDq6BfTHut6iuDHtwwW4O7jcbh7tI8L/+Me57fBx3sbIAl5ry+zvQH6tVxJRUTKka07B5aY8twDhV/TDe5THxJyItcam5/qq6Kd7laaqsZmEaPBE5W0Rae91R/x+uTWJxnItlGo6bgP9YoIitxnRXrklcQ4HpuLz2GuB8L81jEpyI5OLuURkT77I0dZaGMsYYE5GloYwxxkTUZNJQHTp00O7du8e7GMYY06gsW7Zsp6pW1x0daELBonv37ixdujTexTDGmEZFRL6OvJWloYwxxkTBgoUxxpiILFgYY4yJqMm0WRhj4qe4uJjc3FwOHToU76KYMNLS0ujSpQspKSm12t+ChTHmiOXm5pKRkUH37t3xJuwzDYiqsmvXLnJzc+nRo0fkHUKwNJQx5ogdOnSI9u3bW6BooESE9u3bH1HNz4KFMaZOWKBo2I7097FgEcGer/cy45aoRqU2xpgmy4JFBP/8+Uou+dMPyFu3M95FMcaEsWvXLgYNGsSgQYM46qij6Ny5c2C5qKgoqve46qqr+OKLL6rd5sknn2T69Ol1UeRGxxq4I9jpxYiiwuj+4Iwx9a99+/YsX74cgHvuuYf09HTuuOOOCtuoKqpKUlLoa+Rp06ZF/JybbrrpyAvbSFnNIoL8ve4rKi2q7bz0xph42bBhA/379+eGG24gOzubrVu3ct1115GTk0O/fv249957A9sOHTqU5cuXU1JSQps2bZg8eTJZWVmcfPLJ7NixA4ApU6bw6KOPBrafPHkyQ4YM4fjjj+fjj126ev/+/Vx44YVkZWUxYcIEcnJyAoEs2N13380JJ5wQKJ9/BPAvv/ySM888k6ysLLKzs9m8eTMAv/nNbxgwYABZWVnceeedsfzaQrKaRQT5he4rKjlswcKYqPzkJxDi5HhEBg0C7yRdU2vXrmXatGk8/fTTADz44IO0a9eOkpIShg0bxrhx4+jbt2+Fffbu3cvpp5/Ogw8+yO23387UqVOZPLnqVOKqyuLFi5k7dy733nsv8+fP54knnuCoo45i9uzZrFixguzs7Cr7Adx22238+te/RlW55JJLmD9/PqNGjWLChAncc889nHfeeRw6dIiysjJee+013nzzTRYvXkzz5s3ZvXt3rb6LIxHTmoU3w9kXIrJBRKp80yJyg4isEpHlIvKRiPT11ncXkYPe+uUi8nQsy1md3YXNAKtZGNNY9erVixNOOCGwPGPGDLKzs8nOzmbdunWsXbu2yj7Nmzdn1KhRAHz/+98PXN1XNnbs2CrbfPTRR4wfPx6ArKws+vXrF3Lfd999lyFDhpCVlcX777/PmjVryM/PZ+fOnZx33nmAu5GuRYsWvPPOO0ycOJHmzZsD0K5du5p/EUcoZjULb67kJ4H/BXKBJSIyV1WDf5l/qerT3vajcZPYn+299pWqDopV+aKVfzANsGBhTNRqWQOIlZYtWwaer1+/nscee4zFixfTpk0bLrvsspD3HqSmpgae+3w+SkpKQr53s2bNqmwTzYRyBw4c4Oabb+bTTz+lc+fOTJkyJVCOUF1cVTXuXZNjWbMYAmxQ1Y2qWgTMpNLUh6q6L2ixJdDgpu3LP+QieUlRWZxLYow5Uvv27SMjI4NWrVqxdetW3nrrrTr/jKFDh/Liiy8CsGrVqpA1l4MHD5KUlESHDh0oKChg9uzZALRt25YOHTrw2muvAe5mxwMHDjBy5Eiee+45Dh48CBCXNFQs2yw6A98GLecCJ1beSERuAm7Hza98ZtBLPUTkM2AfMEVVPwyx73XAdQDHHnts3ZU8yO7idABKD4e+sjDGNB7Z2dn07duX/v3707NnT0455ZQ6/4xbbrmFyy+/nIEDB5KdnU3//v1p3bp1hW3at2/PFVdcQf/+/enWrRsnnlh+apw+fTrXX389d955J6mpqcyePZtzzz2XFStWkJOTQ0pKCueddx733XdfnZe9OjGbg1tELgLOUtVrvOUfA0NU9ZYw21/ibX+FiDQD0lV1l4h8H3gF6FepJlJBTk6O1vXkR6qQ5iuiSFNZNm0l2VcOrNP3N6apWLduHX369Il3MRqEkpISSkpKSEtLY/369YwcOZL169eTnBz//kShficRWaaqOZH2jWXpc4GuQctdgC3VbD8TeApAVQ8Dh73ny0TkK+B/gHqdCu/AAShSl7u03lDGmGgUFhYyfPhwSkpKUFX+8pe/NIhAcaRieQRLgN4i0gP4DhgPXBK8gYj0VtX13uI5wHpvfSawW1VLRaQn0BvYGMOyhpSfX/68tNjaLIwxkbVp04Zly5bFuxh1LmbBQlVLRORm4C3AB0xV1TUici+wVFXnAjeLyAigGMgHrvB2Pw24V0RKgFLgBlWt9xad/N0KuB4IFiyMMYkspnUjVZ0HzKu07q6g57eF2W82MDuWZYvG7q2HAdd11npDGWMSmQ33UY38reX9r61mYYxJZBYsqpG/7XDgud2UZ4xJZBYsqrF7e3HgudUsjGm4zjjjjCo32D366KPceOON1e6Xnu7uo9qyZQvjxo0L+96RuuU/+uijHDhwILD8wx/+kD179kRT9EbDgkU18neW1yZKihvczeXGGM+ECROYOXNmhXUzZ85kwoQJUe1/zDHHMGvWrFp/fuVgMW/ePNq0aVPr92uILFhUY/eu8gBhNQtjGq5x48bx+uuvc/iwSx1v3ryZLVu2MHTo0MB9D9nZ2QwYMIBXX321yv6bN2+mf//+gBuKY/z48QwcOJCLL744MMQGwKRJkwLDm999990APP7442zZsoVhw4YxbNgwALp3785ObzKcRx55hP79+9O/f//A8OabN2+mT58+XHvttfTr14+RI0dW+By/1157jRNPPJHBgwczYsQItm/fDrh7Oa666ioGDBjAwIEDA8OFzJ8/n+zsbLKyshg+fHidfLd+jf9OkRjK31M+cJcFC2OiE48Rytu3b8+QIUOYP38+Y8aMYebMmVx88cWICGlpacyZM4dWrVqxc+dOTjrpJEaPHh12YL6nnnqKFi1asHLlSlauXFlhiPEHHniAdu3aUVpayvDhw1m5ciW33norjzzyCAsWLKBDhw4V3mvZsmVMmzaNTz75BFXlxBNP5PTTT6dt27asX7+eGTNm8Ne//pUf/ehHzJ49m8suu6zC/kOHDmXRokWICM8++ywPPfQQf/jDH7jvvvto3bo1q1atAiA/P5+8vDyuvfZaPvjgA3r06FHn40dZzaIa+XuTSKcAsDSUMQ1dcCoqOAWlqvzqV79i4MCBjBgxgu+++y5whR7KBx98EDhpDxw4kIEDy4f5efHFF8nOzmbw4MGsWbMm5CCBwT766CMuuOACWrZsSXp6OmPHjuXDD90wdz169GDQIDewdrhh0HNzcznrrLMYMGAADz/8MGvWrAHgnXfeqTBrX9u2bVm0aBGnnXYaPXr0AOp+GHOrWVRjd0EymeRRSAalJRYsjIlGvEYoP//887n99tv59NNPOXjwYKBGMH36dPLy8li2bBkpKSl079495LDkwULVOjZt2sTvf/97lixZQtu2bbnyyisjvk91Y+/5hzcHN8R5qDTULbfcwu23387o0aNZuHAh99xzT+B9K5cx1sOYW82iGvn7U8kkD8CChTENXHp6OmeccQYTJ06s0LC9d+9eOnbsSEpKCgsWLODrr7+u9n1OO+00pk+fDsDq1atZuXIl4IY3b9myJa1bt2b79u28+eabgX0yMjIoKCgI+V6vvPIKBw4cYP/+/cyZM4dTTz016mPau3cvnTt3BuD5558PrB85ciR/+tOfAsv5+fmcfPLJvP/++2zatAmo+2HMLVhUY/eBtECwsDu4jWn4JkyYwIoVKwIz1QFceumlLF26lJycHKZPn873vve9at9j0qRJFBYWMnDgQB566CGGDBkCuFnvBg8eTL9+/Zg4cWKF4c2vu+46Ro0aFWjg9svOzubKK69kyJAhnHjiiVxzzTUMHjw46uO55557uOiiizj11FMrtIdMmTKF/Px8+vfvT1ZWFgsWLCAzM5NnnnmGsWPHkpWVxcUXXxz150QjZkOU17e6HqK8rAxSksv4cfJMni++hL+OfZNrZo+qs/c3pimxIcobhyMZotxqFmEUFECZJpHZohCwNJQxJrFZsAjDn+7LbOkancJMwWuMMQnBgkUY/rksOmS4m3ysZmFM9ZpKSrupOtLfx4JFGP5gkdnKgoUxkaSlpbFr1y4LGA2UqrJr1y7S0tJq/R52n0UYgTRUO5d/sjSUMeF16dKF3Nxc8vLy4l0UE0ZaWhpdunSp9f4WLMIIpKHauSslq1kYE15KSkrgzmHTNFkaKoxAzSLT/Vtq01kYYxKY1SzCyN9VRirFZLRLASwNZYxJbFazCCN/RzHt2E1S6wzAahbGmMRmwSKM3XmltCUfMjJIptiChTEmoVmwCCN/d1kgWPikzIKFMSahWbAIIz9faMduFywopaQ0dkP/GmNMQ2fBIozde5NczaJVK5Kl1GoWxpiEZsEijPyCZEtDGWOMx4JFCIcPw74DKW4uCy9YWBrKGJPILFiE4B+xoCM7XG8oKaXU5j4yxiQwCxYh7Njh/vUHC5eGspqFMSZxWbAIYft2928n3y5o1sylocosWBhjEpcFixACNYv0AwAkJ5VRasHCGJPALFiEEAgWrQ4BWBrKGJPwLFiEsH07NPcdJr21DwBfklJSZl+VMSZx2RkwhB07oGNKPtLKDSLoE7U0lDEmocU0WIjI2SLyhYhsEJHJIV6/QURWichyEflIRPoGvfZLb78vROSsWJazsh07oKNvF2S4YGFtFsaYRBezYCEiPuBJYBTQF5gQHAw8/1LVAao6CHgIeMTbty8wHugHnA382Xu/erF9O3SSHYFgYWkoY0yii+UZcAiwQVU3qmoRMBMYE7yBqu4LWmwJ+OcuHQPMVNXDqroJ2OC9X73YsQM6lm0PChZllKrVLIwxiSuWM+V1Br4NWs4FTqy8kYjcBNwOpAJnBu27qNK+nUPsex1wHcCxxx5bJ4VWdcGik++7oDSUUmo1C2NMAovlGTDUpbhWWaH6pKr2An4BTKnhvs+oao6q5mT6J8s+Qvn5bgrVjkXfQXo64KWh1IKFMSZxxfIMmAt0DVruAmypZvuZwPm13LfOBO6x0G3laSifUmrBwhiTwGJ5BlwC9BaRHiKSimuwnhu8gYj0Dlo8B1jvPZ8LjBeRZiLSA+gNLI5hWQP8waIT2wM1C0tDGWMSXczaLFS1RERuBt4CfMBUVV0jIvcCS1V1LnCziIwAioF84Apv3zUi8iKwFigBblLVeplRwj8uVEd2lKehrGZhjElwsWzgRlXnAfMqrbsr6Plt1ez7APBA7EoXWoURZwPBAkq03nruGmNMg2OXy5Xs2AEiSgd2lqehrGZhjElwdgasZPt26NC6GB9lQb2hoJQk16/WGGMSkAWLSnbsgI4ZbrTZCmkokqHMpsszxiQmCxaV7NgBnTL2u4XgNBQ+dwOGMcYkIAsWlWzfDh1bFLqFli0BV7OwYGGMSWQWLCrZsQM6pnlDVvnTUMleGqq4OI4lM8aY+LFgEeTQIdi3Dzql7nErWrQArGZhjDEWLIIE7rFI3u0Chc/dW5GcLBYsjDEJzYJFkECwSCq/xwKCekNZsDDGJCgLFkFCjQsFrs3CahbGmERmwSJIYFyo0q0VgoWloYwxic6CRZBAGqpkS5WahaWhjDGJzIJFkF27IC0NWh6s3Gbh1Sys66wxJkFZsAhSUODNd1RYWDENlWJpKGNMYrNgEaSwMHSw8KWIpaGMMQnNgkWQggIvRhQWBob6APAlC2X40GILFsaYxGTBIkigQhEiDQVQVmTBwhiTmCxYBCkshIz0MjfuR4XeUO5rKi2ql5ldjTGmwbFgEaSgANLTvIBQIVi4mkXJYQsWxpjEZMEiSGEhZKR53WMrNXCD1SyMMYnLgkWQggJITz3sFiq0WXhpqMPWZmGMSUwWLIIUFkJ6ctVg4fOCRUmRTatqjElMFiw8RUXuBu2M5INuRYhgYWkoY0yismDhKShw/6b7DnhPgtJQqV6wKLaahTEmMVmw8BR6026nS9VgYWkoY0yis2Dh8dcsMvBXMSwNZYwxfhYsPIGahXrBImi4D0tDGWMSnQULjz9YZJTtdU9CpaHspjxjTIKyYOEJNHCX7oXkZEhNDbzmS/UBVrMwxiQuCxaeQBqqON/VKkQCr1kayhiT6CxYeAIN3MW7K6SgoLxmUVKs9V0sY4xpECxYeAI1i8O7wgYLq1kYYxKVBQtPYaHLPLU4WDVYWBrKGJPoYhosRORsEflCRDaIyOQQr98uImtFZKWIvCsi3YJeKxWR5d5jbizLCeWz5MmB/VVrFv7eUJaGMsYkqORYvbGI+IAngf8FcoElIjJXVdcGbfYZkKOqB0RkEvAQcLH32kFVHRSr8lVWYZa8Y46p8JrPZaEoLbFgYYxJTLGsWQwBNqjqRlUtAmYCY4I3UNUFquqNr8EioEsMy1OtggLIyKDKlKoQFCwsDWWMSVBRBQsR6SUizbznZ4jIrSLSJsJunYFvg5ZzvXXhXA28GbScJiJLRWSRiJwfplzXedsszcvLi+JIwgs3/za42y7AgoUxJnFFW7OYDZSKyHHAc0AP4F8R9pEQ60LmcUTkMiAHeDho9bGqmgNcAjwqIr2qvJnqM6qao6o5mZmZURxGeBVqFkFDfUB5zaLE5j4yxiSoaINFmaqWABcAj6rqT4GjI+yTC3QNWu4CbKm8kYiMAO4ERqvqYf96Vd3i/bsRWAgMjrKsteIqFFp9GsraLIwxCSraYFEsIhOAK4DXvXUpEfZZAvQWkR4ikgqMByr0ahKRwcBfcIFiR9D6tkFprw7AKUBww3idKyyE9OalUFYWPg1lwcIYk6CiDRZXAScDD6jqJhHpAfyzuh28msjNwFvAOuBFVV0jIveKyGhvs4eBdOClSl1k+wBLRWQFsAB4sFIvqjpXUAAZacVuIUzNwtJQxphEFVXXWe9EfSu4q34gQ1UfjGK/ecC8SuvuCno+Isx+HwMDoilbXSkshPSUIrdgaShjjKkg2t5QC0WklYi0A1YA00TkkdgWrf6o11SRkXrIrQibhrLeUMaYxBRtGqq1qu4DxgLTVPX7QMhaQWN04IALGOm+0MGiPA0VqoOXMcY0fdEGi2QRORr4EeUN3E1GYBDBpKrzb4OloYwxJtpgcS+uoforVV0iIj2B9bErVv0KDE+etN89CZeGsonyjDEJKtoG7peAl4KWNwIXxqpQ9S1Qs5DQwcJ6QxljEl20DdxdRGSOiOwQke0iMltE4jaOU10LTKmq/idh0lBWszDGJKho01DTcDfUHYMb3+k1b12T4K9ZZJTtdU8qDfdhaShjTKKLNlhkquo0VS3xHn8DjmwwpgYkkIYq9YJFixYVXg+koUqtN5QxJjFFGyx2ishlIuLzHpcBu2JZsPpUYf7tFi3Ko4PHekMZYxJdtMFiIq7b7DZgKzAONwRIk1Bh/u2MjCqvB4KF3ZNnjElQUQULVf1GVUeraqaqdlTV83E36DUJgQbuQztDBgt/m0VJqU1ZboxJTEdy9ru9zkoRZ4WFkJICzQ7kV1+zsAZuY0yCOpJg0WRaeyvMkhciWCR531JpWZM5ZGOMqZEjCRZNprU3MEte4ElFIuCTUqtZGGMSVrV3cItIAaGDggDNY1KiOAjULAoK4H/+J+Q2PimjpMzaLIwxianaYKGqVS+zm6CCAi9YfFNQ5e5tP5+opaGMMQnLLpUJaqoIk4YCSE6yNJQxpmHSemgUsGCBl4ZqqbB/f9hg4UtSS0MZYxqU/fvhpz+FSZNi/1l29sOrUDT35t8OFyxEKVVLQxljGoYFC2DgQHj0Ude9vyzGNw1HNUR5U1dYCOmp3vzb4dJQvjJKiy1YGGPi58svYdYs9/jsMzjuOFi4EE4/PfafbcECr4E7pfpg4ROlpMwX8jVjjKlL+/bB22/Dzp1ueetWmDMHVq1yyyedBH/4A9xwQ5VxT2Mm4YNFSQkcOgQZyQfdirBtFmUuDaXqbrwwxpg6tGcPzJ3rag1vvw2HD5e/JgJDh8Jjj8HYsdAlDrMJJXyw2O+fHM8XKVgopXiJQZ/VMIwxR27XLnj1VRcg3nkHiouha1fXYH3hhS7NBNC8ObRuHd+yJnywKClxEbt763y3ImybhVJCsvs1LViY6tx+O6xfDw884Fogq1Faan9OTc3hw/Dvf8Ps2a49obg4/Lbbtrm/ge7d4bbb4KKL4IQTGmbyIuGDRfv28OGHwPQv3YpwN+X5axY2Ebepzrvvwh//6IYqfuMNuPpqeOghClPasmsXdOvmNvvmG7j+eli0yOWer7qqYZ4gTM288YZrR8jNdTWBkSOhVavw2x91lEsrDR7c8H//hA8WAYEZkMKlobBgYap3+DDceCP06uWuQB5+GJ54gu0L1jI86T3WrG/GoEFw6qnwt7+5jGafPi6ezJwJU6fGJxdtjtyuXe5+h3/8A/r1g6eecoEiNTXeJas7dp+FX4RgEUhDWbAw4fz+9/Dll8y7fCZ/nnM0W+54hK0vfsgZm6axaX0Jd16JVQIIAAAYV0lEQVT2NS1awBNPwIknwurV8Mkn8OST8N//unToxo3xPghTU7NnQ9++MGMG3HUXLFsG557btAIFWM2inD9YtGwZ8mWfz9JQphrffAP338/zOU9w1T05qMJNN0Hr1idRklbGvA5Xcvorc2DFCg4e3ZO0tPK0w403uq6QI0bAGWfAe++VN2ya+CkpgT/9yTU8h5OfDx9/DNnZrgdTVlb9la++Wc3Czz/0bFLor8TSUKZab7zB1EMTuGrZTQwf7m6Yuv9+11g5/60kTv/wfve3deWVNE8trZKfzs52d+QeOACnneYaSE3slJW5LvPhHitXwg9+4FJLGze6huhQj6IiePBBV0NsyoECrGZRrppBBAGSky0NZcJbMi+Pq5nKWSOVOXNcV8dBg+DOO/1bHAuPPw5XXgmPPAL/939V3iMry/WeGTfO5bsnTnQNn7NmuTTVqae67pQXXOAaRpu6776DHTuqrj/2WNcxpTJV1wnN3x0+lNxcePll1101P7/6z+/QwbUl/ehHDb/xuT5YsPCLECx8PqtZmPA+WtIMgOefF5qHm+nl8svdWWrKFBg1Cvr3r7JJ//6wfDn8+teufXzqVNdgetVVruZx440uvXXqqXD++dCxY8X9RVx7SK9edXyAMXTwoDs2/8n722/dCX3JktDb+3wuXTdmDLRr54LE6tUuqH71VeTPa90aRo927QzhNGsGl10GmZk1Ppwmy4KFX6Rg4U9DVddp2iSmfftYvT2TzJb76dQpdJsX4M7kf/kLHH88TJ4Mr78ecrO0NPjtb+Gaa9y1yfHHu/WqsGZN+dhAt98e/qMGDXJtIM2aVVzfooWLU4MGhb5aVnUptPnzXUos1tavd91NK9cGcnLcd9CnT9XyLVkCL70Et95avt7ng+HD4Y474Oijw39eq1ZwyilNrPG5rAzy8qBTp5h+jGgMB0IXkbOBxwAf8KyqPljp9duBa4ASIA+YqKpfe69dAUzxNr1fVZ+v7rNycnJ06dKltS/saae5v7gFC0K+PHzADopWf8GHK9vAgAG1/xzT9CxYwElnNqf5wN4sWBEiP1LZb37j8lOLFrlqQC3l5rqr8mCHDrkG2VmzYPHiqvMc+Odk6dnT3S8YHDBUYcUK2LTJLdfHzYKZma6GNHasuzEN3DVbpDSbqquB+IfEyMyENm1iWtSGRRU++MBFzZdfdjN8LlxYq7cSkWWqmhNpu5jVLETEBzwJ/C+QCywRkbmqujZos8+AHFU9ICKTgIeAi0WkHXA3kIOb1nWZt2+ELOMRKCiotpO7z4e1WZiQdNEnrOEmrhySEt0Ot9zi2i3uvttdwtdSuD/XAQNcw2woeXkuE/byy6FTNn36uDg2ZozL2TdUIq7tIiEtXux+4I8/do1jP/yha1iJsVimoYYAG1R1I4CIzATGAIFgoarBl/GLgMu852cB/1bV3d6+/wbOBmbErLSR0lDJ1mZhQvvm/U0UkkG/70e5Q0YG/OIX8POfw3/+4/Ii9SQz06W3rrmm3j7S1JWdO13u8R//cCmnp592DSthuvvXtVh2ne0MfBu0nOutC+dq4M1a7nvkAnOrhpZswcKEsWapywX161eDnW680bVOT5lSP3NimsaprMxdyL70kvsDmzEDfvlL19hz/fX1FiggtsEiVGezkP8rROQyXMrp4ZrsKyLXichSEVmal5dX64ICUfSGEktDmaq++47Vu1yCvUbBomVLl4ZauNC15BrjpwqvvAK9e7v8d6tWLs3Utau7Pfw3v6n2XBUrsUxD5QJdg5a7AFsqbyQiI4A7gdNV9XDQvmdU2ndh5X1V9RngGXAN3LUuaWmp6/phaShTU4sXs4Z+HN2hiHbtatjFZtIkl4a6804XacaMiU0ZTePx5Zcu1fTGG64f9d13u/PSMce4IWmT49eBNZafvAToLSI9gO+A8cAlwRuIyGDgL8DZqhp8+81bwG9EpK23PBL4ZcxKWljo/o1Qs7Cus6aKxYtZwzj6Z9Wi65AIPPusO0FceqkbsfYIekeZRmzzZrjvPnj+edd3+ve/d32DU6LsNFEPYpaGUtUS4GbciX8d8KKqrhGRe0VktLfZw0A68JKILBeRud6+u4H7cAFnCXCvv7E7JiIMIgiQnGK9oUxVZZ8sYa30o9+AWvYzbd7cpRzatoWTT3a3bW+pUgE3TdGOHW7wqTPOcH2Zp0+Hm2+GDRvgZz9rUIECYnxTnqrOA+ZVWndX0PMR1ew7FZgau9IFiSJYBGoWFiyMnyqbPs3noKaFuhk7ep07u8mVH3jAzZv5wguut9TPflavDZimnmza5GoOU6e6G2P69XPD1V5zTYMeo94GEoTyYBFm4iMAX4oFC1NJXh6r97r/3DVq3A6lTRs3vse6da7f/N13u1u3Z8068nKahmHlStfVtXdv+OtfXepx9Wr3uOeeBh0owIKFE1UaynpDmUrWrmUNLkpUN85QjfTq5bpJfvihu435ootcQ/ihQ3X0AaZeFBe77q2vvupqiSef7EaKfPVV+MlPXO3i2Wfr4Cqj/tjYUBBdA3ey1SxMJevWsYZ+HNu5hFat6vi/0tChbqjZKVPgoYfc3bq/+pXrMZWWVrefZY7MoUOwfTt88QW89ZZ7fP55+dgqKSlurPoHHnCBv23b6t+vgbJgAdG1WViwMJWtXcuqpOvpNzBGgyilpMDvfufGLbvxRhg/3qWrxo+HK65wPads7OzYOHjQjVj4n/+Uj3teUOAapbdtgz173HaqFUdcTE2F009348gfd5xLOQ0eTPihiBsPCxYQZRoqydJQpoLdK3NZXdaXcSfF+IR9zjkubbFgAUyb5rpXPv20a9M46yxXC8nKcn+/GRnVtr01KCUl7uo7NTV00CsqKv//VlrqTtj795d3Xxdxw+i2bOkmlvK/XlbmXi8udlmDggI3VEblmYv8qT3/fVaFheWP/fvL76w/5hh3Y1x6urvrfuBAVzvwl7ltW5cyPPZYN2NSE+2UYMECalazsPssjOeDVW1Rkhg2rB4+LCnJjcE9fDjs2+cavv/1L9dQ+vjjFbc96ig3Bvn3vudOci1buhEE1693V8bdurmr3m7d3BhDnTqVnwxFyk+w/qvovXvL37t5c7ddaqo7oRYWuhvF0tPdeOj+k67//0lRkbuHYMMGl6rxn4wLCspP1v79/TeclZRUDAp1qVkz9/106lR+Uk9JcaMmtmzpHhkZbtKL7Gx38g8101ICsmAB7g83KcldpYThS0miFLGahXH27GFBfhbNU4oZEu1os3WlVSt3P8bEie6E+umn5amSvXtdj6rly10juX+iiGbNXIDIzHSjlr74YvkVeKy1aePSMb16uROx/4TsDxD+AOLP8ft87rWWLcvvNRApX+efjKKszKWL/PtmZLj/w/6x1X2+8s/LzHRBonVrS93VkgULcMHCf1UVhusNZW0WxrNuHQsYxil999CsWRynU0tJcW0X4e789p9QmzevOL98UZG70t+2reIVf1lZ+Ym8Y8eKJ1hVVxsoLHQTSfhP3qWlbt3Bg27ZX/OA8hO/afQsWEDEQQQBfKlJ1sBtAvIWb2IVlzB++K54F6V6SUmhc+ipqW5guq5dq75WGzGepc3En91nAe6qKMLVjy85iVJr4Daehe+6lMmwCxJpejaTyCxYQFQ1i+RU91WVFVmwMLBgRTvSk/aTc2I9zD1qTANgwQKiS0OluPaMkqJ6ahQ0DdqCrcdzaqcvG9pYb8bEjAULiC5YJLuvqrSotD5KZBqwrV8d4PPi4xjWf2e8i2JMvbFgAdEFCy/bUFpsNYtE9/5L2wEYdqZ1wTSJw4IFRNdm4b9fyNJQCW/d4gKSKGXg2cfEuyjG1BsLFmA1C1MjGz8vpiu5pPY9Lt5FMabeWLAoKXE3GlmwMFHa+F0qPVvlld94ZkwCsGARxfDkEJSGKtYYF8g0aKWlbCzIpGeXoniXxJh6ZcFCFX70I+jTp9rNrGZhAA4s/5JtehQ9+9icEiax2HAfbdu6OY8jCASLEqtZJLJNb30J9KHnSR3jXRRj6pXVLKIUSEMdtvssEtnGj7cB0POUo+NcEmPqlwWLKAVqFrv3Vr+hadI2rnZDfvfsbcN8mMRiwSJKgWCxLS++BTHxU1TExtxUMlIP2Xw4JuFYsIhSIA21vYEPSW1iZ80aNpZ2o+fRB23+HJNwLFhEKVCz2H+wvLutSSxLlrCRnvQ83kYPNInHgkWUAsECH3z3XXwLY+JClyx1waJ/iMmEjGniLFhEyR8sSki2YJGgtv13E4doTs9eloMyiceCRZT8bRZWs0hQu3ezcd1hAHr2jHNZjIkDCxZRsjRUgnv9dTaWdQMsWJjEZMEiSoFg0bK1BYtE9PLLbGw1CBGlW7d4F8aY+mfBIkqBrrPtO1mwSDT798Nbb7HxmKF06SI0axbvAhlT/yxYRClQs2jf0YJFopk/Hw4dYmPK8ZaCMgnLgkWUAsGiXSbk5sa3MKZ+vfwydOjAxl2tLViYhBXTYCEiZ4vIFyKyQUQmh3j9NBH5VERKRGRcpddKRWS595gby3JGI5CGapsJ27a5SZNM01dUBK+/zp6zLmbLFqF373gXyJj4iNkQ5SLiA54E/hfIBZaIyFxVXRu02TfAlcAdId7ioKoOilX5aipQs2jbAcrKYPt26Nw5voUysffee7BvH8v7XQrA4MFxLo8xcRLLmsUQYIOqblTVImAmMCZ4A1XdrKorgQY/o1CFYAHWbpEopk+HVq1YnpwDWLAwiSuWwaIz8G3Qcq63LlppIrJURBaJyPmhNhCR67xtlublxXY02EAaqrU33KgFi6Zv50548UX48Y/5bHUKRx8NnTrFu1DGxEcsg0WoMRFqMs3csaqaA1wCPCoivaq8meozqpqjqjmZmZm1LWdUAjWL1u3cEwsWTd+0aa7NYtIkPvvMahUmscUyWOQCXYOWuwBbot1ZVbd4/24EFgJx/a8aCBYtMiAlxYJFU1dWBk8/DaedxqFe/Vi7FgY1mBY0Y+pfLIPFEqC3iPQQkVRgPBBVryYRaSsizbznHYBTgLXV7xVbgTRUWRIcfbQFi6bu7bdh40aYNInVq6G01GoWJrHFLFioaglwM/AWsA54UVXXiMi9IjIaQEROEJFc4CLgLyKyxtu9D7BURFYAC4AHK/WiqneBmkUprheUBYum7amnoGNHGDuWzz5zqyxYmEQWs66zAKo6D5hXad1dQc+X4NJTlff7GBgQy7LVVJVgsWpVXMtjYugf/4DXX4fJkyE1lc8+g1atoEePeBfMmPixO7ijFJjPogQXLHJzQWvSXm8aPFX47W/h8sth2DAXLIDPPnPtFUn2v8UksJjWLJqSwHwW/prF/v2wbx+0bh3XcpkjUFIC33wDn38OH38MCxfCf/4Dl14KU6dCaiqlpbByJVx7bbwLa0x8WbCIUpU0FMBpp2FDkDYypaVw4AAUFMCOHVBc7Nb7fK5R4ne/gzvuCFQj1q93m1t7hUl0FiyiVCENdeaZcOGF7ixiGhcRSE93j44doXdvOO44yM526yqxxm1jHAsWUaqQhjrqKJg1K67lMfVj4UJIS4M+feJdEmPiy5rsolQhDWUSwu7d8M9/wiWXuPswjUlkFiyiZMEi8Tz7rMs03nZbvEtiTPxZsIiSiGvztGksEkNxMTzxhOtBO3BgvEtjTPxZm0UN+HxWs0gUc+a4W2mefDLeJTGmYbCaRQ1YsEgcjz0GvXrBOefEuyTGNAxWs6iB5GRLQyWCv/3N3aP3xBPlbVXGJDqrWdSA1SyavlWr4MYbXVvFpEnxLo0xDYcFixqwYNG07dsH48ZBmzbwr39ZrcKYYJaGqgFLQzVdhw7B+PHw1Vfw3nvuvktjTDkLFjVgNYum6eBBuOACeOsteOYZN+SXMaYiS0PVgAWLpic/H0aPdhPjPfecjS5rTDgWLGrA57M0VFMyZw707QsLFsC0aTBxYrxLZEzDZWmoGkhOhldfhX794l0Sc6SKi93w44MGwbx5NqqsMZFYsKiBO+6Ad9+NdylMXbnuOjfukw0SaExkFixq4IYb3MMYYxKNtVkYY4yJyIKFMcaYiCxYGGOMiciChTHGmIgsWBhjjInIgoUxxpiILFgYY4yJyIKFMcaYiERV412GOiEiecDXNdytA7AzBsWJBzuWhqspHY8dS8N0JMfSTVUzI23UZIJFbYjIUlXNiXc56oIdS8PVlI7HjqVhqo9jsTSUMcaYiCxYGGOMiSjRg8Uz8S5AHbJjabia0vHYsTRMMT+WhG6zMMYYE51Er1kYY4yJggULY4wxESVssBCRs0XkCxHZICKT412emhCRriKyQETWicgaEbnNW99ORP4tIuu9f9vGu6zREhGfiHwmIq97yz1E5BPvWF4QkdR4lzEaItJGRGaJyOfe73NyY/1dROSn3t/XahGZISJpjel3EZGpIrJDRFYHrQv5W4jzuHc+WCki2fEreVVhjuVh7+9spYjMEZE2Qa/90juWL0TkrLooQ0IGCxHxAU8Co4C+wAQR6RvfUtVICfAzVe0DnATc5JV/MvCuqvYG3vWWG4vbgHVBy78D/ugdSz5wdVxKVXOPAfNV9XtAFu6YGt3vIiKdgVuBHFXtD/iA8TSu3+VvwNmV1oX7LUYBvb3HdcBT9VTGaP2Nqsfyb6C/qg4EvgR+CeCdC8YD/bx9/uyd845IQgYLYAiwQVU3qmoRMBMYE+cyRU1Vt6rqp97zAtwJqTPuGJ73NnseOD8+JawZEekCnAM86y0LcCYwy9ukURyLiLQCTgOeA1DVIlXdQyP9XXDTLjcXkWSgBbCVRvS7qOoHwO5Kq8P9FmOAv6uzCGgjIkfXT0kjC3Usqvq2qpZ4i4uALt7zMcBMVT2sqpuADbhz3hFJ1GDRGfg2aDnXW9foiEh3YDDwCdBJVbeCCyhAx/iVrEYeBX4OlHnL7YE9Qf8RGsvv0xPIA6Z5KbVnRaQljfB3UdXvgN8D3+CCxF5gGY3zdwkW7rdo7OeEicCb3vOYHEuiBgsJsa7R9SEWkXRgNvATVd0X7/LUhoicC+xQ1WXBq0Ns2hh+n2QgG3hKVQcD+2kEKadQvFz+GKAHcAzQEpeqqawx/C7RaKx/c4jInbjU9HT/qhCbHfGxJGqwyAW6Bi13AbbEqSy1IiIpuEAxXVVf9lZv91edvX93xKt8NXAKMFpENuPSgWfiahptvPQHNJ7fJxfIVdVPvOVZuODRGH+XEcAmVc1T1WLgZeAHNM7fJVi436JRnhNE5ArgXOBSLb9pLibHkqjBYgnQ2+vZkYprDJob5zJFzcvpPwesU9VHgl6aC1zhPb8CeLW+y1ZTqvpLVe2iqt1xv8N7qnopsAAY523WWI5lG/CtiBzvrRoOrKUR/i649NNJItLC+3vzH0uj+10qCfdbzAUu93pFnQTs9aerGioRORv4BTBaVQ8EvTQXGC8izUSkB67RfvERf6CqJuQD+CGuB8FXwJ3xLk8Nyz4UV61cCSz3Hj/E5frfBdZ7/7aLd1lreFxnAK97z3t6f+AbgJeAZvEuX5THMAhY6v02rwBtG+vvAvwa+BxYDfwDaNaYfhdgBq69pRh3tX11uN8Cl7p50jsfrML1Aov7MUQ4lg24tgn/OeDpoO3v9I7lC2BUXZTBhvswxhgTUaKmoYwxxtSABQtjjDERWbAwxhgTkQULY4wxEVmwMMYYE5EFC2MiEJFSEVke9Kizu7JFpHvwSKLGNFTJkTcxJuEdVNVB8S6EMfFkNQtjaklENovI70Rksfc4zlvfTUTe9eYZeFdEjvXWd/LmHVjhPX7gvZVPRP7qzR3xtog097a/VUTWeu8zM06HaQxgwcKYaDSvlIa6OOi1fao6BPgTbkwrvOd/VzfPwHTgcW/948D7qpqFGzNqjbe+N/CkqvYD9gAXeusnA4O997khVgdnTDTsDm5jIhCRQlVND7F+M3Cmqm70BnbcpqrtRWQncLSqFnvrt6pqBxHJA7qo6uGg9+gO/FvdZDyIyC+AFFW9X0TmA4W4YUNeUdXCGB+qMWFZzcKYI6NhnofbJpTDQc9LKW9LPAc3XtH3gWVBo70aU+8sWBhzZC4O+ve/3vOPcSPoAlwKfOQ9fxeYBIE5x1uFe1MRSQK6quoC3MRQbYAqtRtj6otdqRgTWXMRWR60PF9V/d1nm4nIJ7gLrwneuluBqSLyf7iZ867y1t8GPCMiV+NqEJNwI4mG4gP+KSKtcSOi/lHdFK3GxIW1WRhTS16bRY6q7ox3WYyJNUtDGWOMichqFsYYYyKymoUxxpiILFgYY4yJyIKFMcaYiCxYGGOMiciChTHGmIj+P0tqqJkyfJ5OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc_values = model_val_dict['acc'] \n",
    "val_acc_values = model_val_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'blue', label='Validation acc')\n",
    "plt.title('Training & validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice an interesting pattern here: although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss seem to be reaching a limit around the 60th epoch. This means that you're probably **overfitting** the model to the training data when you train for many epochs past this dropoff point of around 40 epochs. Luckily, you learned how to tackle overfitting in the previous lecture! Since it seems clear that you are training too long, include early stopping at the 60th epoch first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Below, observe how to update the model to include an earlier cutoff point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/60\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 1.9643 - acc: 0.1583 - val_loss: 1.9249 - val_acc: 0.2010\n",
      "Epoch 2/60\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.9347 - acc: 0.1833 - val_loss: 1.9114 - val_acc: 0.2230\n",
      "Epoch 3/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.9180 - acc: 0.2067 - val_loss: 1.8989 - val_acc: 0.2460\n",
      "Epoch 4/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.9028 - acc: 0.2247 - val_loss: 1.8846 - val_acc: 0.2620\n",
      "Epoch 5/60\n",
      "7000/7000 [==============================] - 0s 30us/step - loss: 1.8870 - acc: 0.2421 - val_loss: 1.8680 - val_acc: 0.2710\n",
      "Epoch 6/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.8697 - acc: 0.2550 - val_loss: 1.8503 - val_acc: 0.2870\n",
      "Epoch 7/60\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.8508 - acc: 0.2690 - val_loss: 1.8307 - val_acc: 0.2880\n",
      "Epoch 8/60\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.8302 - acc: 0.2850 - val_loss: 1.8101 - val_acc: 0.3090\n",
      "Epoch 9/60\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.8075 - acc: 0.3010 - val_loss: 1.7888 - val_acc: 0.3330\n",
      "Epoch 10/60\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.7830 - acc: 0.3220 - val_loss: 1.7660 - val_acc: 0.3590\n",
      "Epoch 11/60\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.7558 - acc: 0.3466 - val_loss: 1.7371 - val_acc: 0.3720\n",
      "Epoch 12/60\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.7263 - acc: 0.3587 - val_loss: 1.7105 - val_acc: 0.3960\n",
      "Epoch 13/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.6940 - acc: 0.3880 - val_loss: 1.6771 - val_acc: 0.4080\n",
      "Epoch 14/60\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.6586 - acc: 0.4074 - val_loss: 1.6440 - val_acc: 0.4250\n",
      "Epoch 15/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.6207 - acc: 0.4349 - val_loss: 1.6066 - val_acc: 0.4480\n",
      "Epoch 16/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.5797 - acc: 0.4573 - val_loss: 1.5688 - val_acc: 0.4750\n",
      "Epoch 17/60\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.5365 - acc: 0.4981 - val_loss: 1.5275 - val_acc: 0.4920\n",
      "Epoch 18/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.4914 - acc: 0.5221 - val_loss: 1.4839 - val_acc: 0.5180\n",
      "Epoch 19/60\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.4448 - acc: 0.5471 - val_loss: 1.4400 - val_acc: 0.5460\n",
      "Epoch 20/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.3968 - acc: 0.5681 - val_loss: 1.3975 - val_acc: 0.5700\n",
      "Epoch 21/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 1.3486 - acc: 0.5859 - val_loss: 1.3582 - val_acc: 0.5900\n",
      "Epoch 22/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 1.3006 - acc: 0.6106 - val_loss: 1.3103 - val_acc: 0.6140\n",
      "Epoch 23/60\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.2536 - acc: 0.6293 - val_loss: 1.2651 - val_acc: 0.6170\n",
      "Epoch 24/60\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 1.2084 - acc: 0.6401 - val_loss: 1.2280 - val_acc: 0.6300\n",
      "Epoch 25/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.1647 - acc: 0.6556 - val_loss: 1.1899 - val_acc: 0.6350\n",
      "Epoch 26/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 1.1230 - acc: 0.6706 - val_loss: 1.1520 - val_acc: 0.6470\n",
      "Epoch 27/60\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 1.0843 - acc: 0.6800 - val_loss: 1.1183 - val_acc: 0.6450\n",
      "Epoch 28/60\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 1.0478 - acc: 0.6890 - val_loss: 1.0852 - val_acc: 0.6490\n",
      "Epoch 29/60\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.0147 - acc: 0.6974 - val_loss: 1.0550 - val_acc: 0.6600\n",
      "Epoch 30/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 0.9829 - acc: 0.7037 - val_loss: 1.0318 - val_acc: 0.6590\n",
      "Epoch 31/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 0.9537 - acc: 0.7107 - val_loss: 1.0089 - val_acc: 0.6710\n",
      "Epoch 32/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 0.9268 - acc: 0.7153 - val_loss: 0.9819 - val_acc: 0.6820\n",
      "Epoch 33/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 0.9023 - acc: 0.7196 - val_loss: 0.9620 - val_acc: 0.6860\n",
      "Epoch 34/60\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 0.8789 - acc: 0.7226 - val_loss: 0.9438 - val_acc: 0.6860\n",
      "Epoch 35/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 0.8579 - acc: 0.7277 - val_loss: 0.9239 - val_acc: 0.6890\n",
      "Epoch 36/60\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 0.8383 - acc: 0.7321 - val_loss: 0.9106 - val_acc: 0.6970\n",
      "Epoch 37/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 0.8194 - acc: 0.7351 - val_loss: 0.8977 - val_acc: 0.6930\n",
      "Epoch 38/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 0.8027 - acc: 0.7383 - val_loss: 0.8822 - val_acc: 0.6900\n",
      "Epoch 39/60\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 0.7869 - acc: 0.7431 - val_loss: 0.8715 - val_acc: 0.6980\n",
      "Epoch 40/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 0.7719 - acc: 0.7459 - val_loss: 0.8587 - val_acc: 0.6990\n",
      "Epoch 41/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 0.7582 - acc: 0.7476 - val_loss: 0.8472 - val_acc: 0.6950\n",
      "Epoch 42/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 0.7453 - acc: 0.7521 - val_loss: 0.8379 - val_acc: 0.7000\n",
      "Epoch 43/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 0.7329 - acc: 0.7519 - val_loss: 0.8336 - val_acc: 0.7010\n",
      "Epoch 44/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 0.7212 - acc: 0.7573 - val_loss: 0.8221 - val_acc: 0.7010\n",
      "Epoch 45/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 0.7106 - acc: 0.7604 - val_loss: 0.8142 - val_acc: 0.7020\n",
      "Epoch 46/60\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 0.7002 - acc: 0.7644 - val_loss: 0.8086 - val_acc: 0.7040\n",
      "Epoch 47/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 0.6902 - acc: 0.7659 - val_loss: 0.7989 - val_acc: 0.7040\n",
      "Epoch 48/60\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 0.6809 - acc: 0.7697 - val_loss: 0.7954 - val_acc: 0.7060\n",
      "Epoch 49/60\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 0.6719 - acc: 0.7703 - val_loss: 0.7897 - val_acc: 0.7080\n",
      "Epoch 50/60\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.6634 - acc: 0.7741 - val_loss: 0.7856 - val_acc: 0.7100\n",
      "Epoch 51/60\n",
      "7000/7000 [==============================] - 0s 31us/step - loss: 0.6554 - acc: 0.7800 - val_loss: 0.7803 - val_acc: 0.7130\n",
      "Epoch 52/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 0.6474 - acc: 0.7773 - val_loss: 0.7744 - val_acc: 0.7140\n",
      "Epoch 53/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 0.6398 - acc: 0.7804 - val_loss: 0.7710 - val_acc: 0.7120\n",
      "Epoch 54/60\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 0.6328 - acc: 0.7843 - val_loss: 0.7705 - val_acc: 0.7150\n",
      "Epoch 55/60\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 0.6256 - acc: 0.7870 - val_loss: 0.7704 - val_acc: 0.7150\n",
      "Epoch 56/60\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 0.6187 - acc: 0.7897 - val_loss: 0.7595 - val_acc: 0.7140\n",
      "Epoch 57/60\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 0.6124 - acc: 0.7899 - val_loss: 0.7634 - val_acc: 0.7200\n",
      "Epoch 58/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 0.6055 - acc: 0.7943 - val_loss: 0.7593 - val_acc: 0.7220\n",
      "Epoch 59/60\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 0.5997 - acc: 0.7957 - val_loss: 0.7504 - val_acc: 0.7210\n",
      "Epoch 60/60\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 0.5935 - acc: 0.7989 - val_loss: 0.7526 - val_acc: 0.7190\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=60,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the test set to make label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 55us/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 112us/step\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5888252187797002, 0.7981428570747375]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7261311588287354, 0.727]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've significantly reduced the variance, so this is already pretty good! your test set accuracy is slightly worse, but this model will definitely be more robust than the 120 epochs model you originally fit.\n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=kernel_regulizers.l2(lamda_coeff)` parameter to any model layer. The lambda_coeff parameter determines the strength of the regularization you wish to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7000/7000 [==============================] - 0s 68us/step - loss: 2.6191 - acc: 0.1583 - val_loss: 2.5778 - val_acc: 0.2010\n",
      "Epoch 2/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 2.5857 - acc: 0.1834 - val_loss: 2.5607 - val_acc: 0.2230\n",
      "Epoch 3/120\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 2.5656 - acc: 0.2069 - val_loss: 2.5449 - val_acc: 0.2450\n",
      "Epoch 4/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 2.5471 - acc: 0.2250 - val_loss: 2.5275 - val_acc: 0.2620\n",
      "Epoch 5/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 2.5283 - acc: 0.2417 - val_loss: 2.5080 - val_acc: 0.2730\n",
      "Epoch 6/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 2.5082 - acc: 0.2559 - val_loss: 2.4874 - val_acc: 0.2870\n",
      "Epoch 7/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 2.4865 - acc: 0.2693 - val_loss: 2.4652 - val_acc: 0.2900\n",
      "Epoch 8/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 2.4634 - acc: 0.2837 - val_loss: 2.4423 - val_acc: 0.3090\n",
      "Epoch 9/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 2.4385 - acc: 0.3003 - val_loss: 2.4189 - val_acc: 0.3320\n",
      "Epoch 10/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 2.4122 - acc: 0.3179 - val_loss: 2.3942 - val_acc: 0.3610\n",
      "Epoch 11/120\n",
      "7000/7000 [==============================] - 0s 69us/step - loss: 2.3835 - acc: 0.3440 - val_loss: 2.3640 - val_acc: 0.3720\n",
      "Epoch 12/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 2.3528 - acc: 0.3563 - val_loss: 2.3358 - val_acc: 0.3920\n",
      "Epoch 13/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 2.3197 - acc: 0.3836 - val_loss: 2.3019 - val_acc: 0.4060\n",
      "Epoch 14/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 2.2839 - acc: 0.4036 - val_loss: 2.2682 - val_acc: 0.4250\n",
      "Epoch 15/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 2.2460 - acc: 0.4291 - val_loss: 2.2309 - val_acc: 0.4440\n",
      "Epoch 16/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 2.2054 - acc: 0.4537 - val_loss: 2.1934 - val_acc: 0.4650\n",
      "Epoch 17/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 2.1631 - acc: 0.4897 - val_loss: 2.1528 - val_acc: 0.4880\n",
      "Epoch 18/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 2.1190 - acc: 0.5151 - val_loss: 2.1099 - val_acc: 0.5200\n",
      "Epoch 19/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 2.0737 - acc: 0.5419 - val_loss: 2.0671 - val_acc: 0.5450\n",
      "Epoch 20/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 2.0270 - acc: 0.5616 - val_loss: 2.0254 - val_acc: 0.5710\n",
      "Epoch 21/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.9798 - acc: 0.5801 - val_loss: 1.9863 - val_acc: 0.5890\n",
      "Epoch 22/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.9328 - acc: 0.6047 - val_loss: 1.9394 - val_acc: 0.6100\n",
      "Epoch 23/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.8864 - acc: 0.6229 - val_loss: 1.8946 - val_acc: 0.6150\n",
      "Epoch 24/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.8417 - acc: 0.6323 - val_loss: 1.8572 - val_acc: 0.6270\n",
      "Epoch 25/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.7981 - acc: 0.6503 - val_loss: 1.8189 - val_acc: 0.6340\n",
      "Epoch 26/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.7562 - acc: 0.6657 - val_loss: 1.7803 - val_acc: 0.6420\n",
      "Epoch 27/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.7169 - acc: 0.6756 - val_loss: 1.7457 - val_acc: 0.6490\n",
      "Epoch 28/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.6797 - acc: 0.6843 - val_loss: 1.7111 - val_acc: 0.6530\n",
      "Epoch 29/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.6455 - acc: 0.6923 - val_loss: 1.6794 - val_acc: 0.6510\n",
      "Epoch 30/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.6124 - acc: 0.6993 - val_loss: 1.6541 - val_acc: 0.6620\n",
      "Epoch 31/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.5816 - acc: 0.7041 - val_loss: 1.6295 - val_acc: 0.6670\n",
      "Epoch 32/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.5530 - acc: 0.7120 - val_loss: 1.6003 - val_acc: 0.6770\n",
      "Epoch 33/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.5268 - acc: 0.7174 - val_loss: 1.5783 - val_acc: 0.6850\n",
      "Epoch 34/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.5017 - acc: 0.7199 - val_loss: 1.5578 - val_acc: 0.6810\n",
      "Epoch 35/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.4789 - acc: 0.7250 - val_loss: 1.5355 - val_acc: 0.6900\n",
      "Epoch 36/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.4576 - acc: 0.7299 - val_loss: 1.5201 - val_acc: 0.6930\n",
      "Epoch 37/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.4369 - acc: 0.7331 - val_loss: 1.5049 - val_acc: 0.6930\n",
      "Epoch 38/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.4184 - acc: 0.7359 - val_loss: 1.4869 - val_acc: 0.6960\n",
      "Epoch 39/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.4008 - acc: 0.7420 - val_loss: 1.4740 - val_acc: 0.6970\n",
      "Epoch 40/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.3841 - acc: 0.7439 - val_loss: 1.4594 - val_acc: 0.7050\n",
      "Epoch 41/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.3685 - acc: 0.7453 - val_loss: 1.4458 - val_acc: 0.7020\n",
      "Epoch 42/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.3539 - acc: 0.7483 - val_loss: 1.4344 - val_acc: 0.7020\n",
      "Epoch 43/120\n",
      "7000/7000 [==============================] - 0s 58us/step - loss: 1.3399 - acc: 0.7503 - val_loss: 1.4279 - val_acc: 0.7030\n",
      "Epoch 44/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.3264 - acc: 0.7534 - val_loss: 1.4138 - val_acc: 0.7020\n",
      "Epoch 45/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.3141 - acc: 0.7547 - val_loss: 1.4038 - val_acc: 0.7040\n",
      "Epoch 46/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.3020 - acc: 0.7596 - val_loss: 1.3964 - val_acc: 0.7020\n",
      "Epoch 47/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.2903 - acc: 0.7596 - val_loss: 1.3848 - val_acc: 0.7020\n",
      "Epoch 48/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.2793 - acc: 0.7653 - val_loss: 1.3791 - val_acc: 0.7070\n",
      "Epoch 49/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.2687 - acc: 0.7651 - val_loss: 1.3708 - val_acc: 0.7000\n",
      "Epoch 50/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.2586 - acc: 0.7701 - val_loss: 1.3647 - val_acc: 0.7090\n",
      "Epoch 51/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.2489 - acc: 0.7710 - val_loss: 1.3576 - val_acc: 0.7120\n",
      "Epoch 52/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.2393 - acc: 0.7730 - val_loss: 1.3500 - val_acc: 0.7120\n",
      "Epoch 53/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.2301 - acc: 0.7756 - val_loss: 1.3439 - val_acc: 0.7170\n",
      "Epoch 54/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 1.2215 - acc: 0.7786 - val_loss: 1.3407 - val_acc: 0.7150\n",
      "Epoch 55/120\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.2127 - acc: 0.7813 - val_loss: 1.3395 - val_acc: 0.7150\n",
      "Epoch 56/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.2042 - acc: 0.7841 - val_loss: 1.3263 - val_acc: 0.7140\n",
      "Epoch 57/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.1964 - acc: 0.7831 - val_loss: 1.3277 - val_acc: 0.7210\n",
      "Epoch 58/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 1.1880 - acc: 0.7874 - val_loss: 1.3214 - val_acc: 0.7220\n",
      "Epoch 59/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.1807 - acc: 0.7880 - val_loss: 1.3105 - val_acc: 0.7190\n",
      "Epoch 60/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.1730 - acc: 0.7901 - val_loss: 1.3101 - val_acc: 0.7200\n",
      "Epoch 61/120\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.1659 - acc: 0.7939 - val_loss: 1.3034 - val_acc: 0.7210\n",
      "Epoch 62/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.1591 - acc: 0.7949 - val_loss: 1.2974 - val_acc: 0.7230\n",
      "Epoch 63/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.1516 - acc: 0.7959 - val_loss: 1.2956 - val_acc: 0.7240\n",
      "Epoch 64/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.1450 - acc: 0.7959 - val_loss: 1.2869 - val_acc: 0.7240\n",
      "Epoch 65/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.1383 - acc: 0.7994 - val_loss: 1.2834 - val_acc: 0.7210\n",
      "Epoch 66/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 1.1314 - acc: 0.8040 - val_loss: 1.2773 - val_acc: 0.7240\n",
      "Epoch 67/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.1251 - acc: 0.8050 - val_loss: 1.2751 - val_acc: 0.7290\n",
      "Epoch 68/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.1186 - acc: 0.8043 - val_loss: 1.2774 - val_acc: 0.7290\n",
      "Epoch 69/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 1.1125 - acc: 0.8086 - val_loss: 1.2701 - val_acc: 0.7310\n",
      "Epoch 70/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.1063 - acc: 0.8096 - val_loss: 1.2680 - val_acc: 0.7260\n",
      "Epoch 71/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.1004 - acc: 0.8119 - val_loss: 1.2576 - val_acc: 0.7290\n",
      "Epoch 72/120\n",
      "7000/7000 [==============================] - 1s 75us/step - loss: 1.0943 - acc: 0.8111 - val_loss: 1.2593 - val_acc: 0.7310\n",
      "Epoch 73/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.0884 - acc: 0.8141 - val_loss: 1.2519 - val_acc: 0.7320\n",
      "Epoch 74/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.0828 - acc: 0.8147 - val_loss: 1.2517 - val_acc: 0.7350\n",
      "Epoch 75/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.0770 - acc: 0.8193 - val_loss: 1.2471 - val_acc: 0.7320\n",
      "Epoch 76/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.0715 - acc: 0.8213 - val_loss: 1.2429 - val_acc: 0.7310\n",
      "Epoch 77/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.0658 - acc: 0.8216 - val_loss: 1.2423 - val_acc: 0.7360\n",
      "Epoch 78/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.0604 - acc: 0.8226 - val_loss: 1.2367 - val_acc: 0.7360\n",
      "Epoch 79/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.0550 - acc: 0.8233 - val_loss: 1.2379 - val_acc: 0.7370\n",
      "Epoch 80/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.0498 - acc: 0.8260 - val_loss: 1.2328 - val_acc: 0.7390\n",
      "Epoch 81/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.0447 - acc: 0.8249 - val_loss: 1.2275 - val_acc: 0.7350\n",
      "Epoch 82/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.0391 - acc: 0.8284 - val_loss: 1.2239 - val_acc: 0.7370\n",
      "Epoch 83/120\n",
      "7000/7000 [==============================] - 0s 60us/step - loss: 1.0344 - acc: 0.8303 - val_loss: 1.2213 - val_acc: 0.7320\n",
      "Epoch 84/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.0293 - acc: 0.8303 - val_loss: 1.2186 - val_acc: 0.7400\n",
      "Epoch 85/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.0240 - acc: 0.8321 - val_loss: 1.2211 - val_acc: 0.7400\n",
      "Epoch 86/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.0192 - acc: 0.8323 - val_loss: 1.2129 - val_acc: 0.7390\n",
      "Epoch 87/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.0144 - acc: 0.8374 - val_loss: 1.2182 - val_acc: 0.7380\n",
      "Epoch 88/120\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.0098 - acc: 0.8350 - val_loss: 1.2095 - val_acc: 0.7360\n",
      "Epoch 89/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.0051 - acc: 0.8384 - val_loss: 1.2121 - val_acc: 0.7410\n",
      "Epoch 90/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 1.0000 - acc: 0.8391 - val_loss: 1.2014 - val_acc: 0.7390\n",
      "Epoch 91/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 0.9953 - acc: 0.8399 - val_loss: 1.2019 - val_acc: 0.7450\n",
      "Epoch 92/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 0.9902 - acc: 0.8434 - val_loss: 1.1957 - val_acc: 0.7400\n",
      "Epoch 93/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 0.9857 - acc: 0.8434 - val_loss: 1.1933 - val_acc: 0.7310\n",
      "Epoch 94/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 0.9816 - acc: 0.8426 - val_loss: 1.1982 - val_acc: 0.7430\n",
      "Epoch 95/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.9770 - acc: 0.8464 - val_loss: 1.1920 - val_acc: 0.7400\n",
      "Epoch 96/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 0.9721 - acc: 0.8457 - val_loss: 1.1923 - val_acc: 0.7370\n",
      "Epoch 97/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.9683 - acc: 0.8480 - val_loss: 1.1862 - val_acc: 0.7380\n",
      "Epoch 98/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.9636 - acc: 0.8477 - val_loss: 1.1832 - val_acc: 0.7410\n",
      "Epoch 99/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 0.9596 - acc: 0.8491 - val_loss: 1.1803 - val_acc: 0.7370\n",
      "Epoch 100/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.9549 - acc: 0.8504 - val_loss: 1.1841 - val_acc: 0.7300\n",
      "Epoch 101/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.9510 - acc: 0.8523 - val_loss: 1.1846 - val_acc: 0.7380\n",
      "Epoch 102/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 0.9471 - acc: 0.8530 - val_loss: 1.1742 - val_acc: 0.7410\n",
      "Epoch 103/120\n",
      "7000/7000 [==============================] - 0s 56us/step - loss: 0.9423 - acc: 0.8547 - val_loss: 1.1758 - val_acc: 0.7460\n",
      "Epoch 104/120\n",
      "7000/7000 [==============================] - 0s 63us/step - loss: 0.9382 - acc: 0.8540 - val_loss: 1.1744 - val_acc: 0.7360\n",
      "Epoch 105/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 0.9346 - acc: 0.8556 - val_loss: 1.1717 - val_acc: 0.7410\n",
      "Epoch 106/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 0.9300 - acc: 0.8569 - val_loss: 1.1768 - val_acc: 0.7410\n",
      "Epoch 107/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 0.9264 - acc: 0.8561 - val_loss: 1.1633 - val_acc: 0.7400\n",
      "Epoch 108/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 0.9226 - acc: 0.8597 - val_loss: 1.1680 - val_acc: 0.7310\n",
      "Epoch 109/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.9184 - acc: 0.8606 - val_loss: 1.1639 - val_acc: 0.7360\n",
      "Epoch 110/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 0.9147 - acc: 0.8601 - val_loss: 1.1608 - val_acc: 0.7340\n",
      "Epoch 111/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 0.9102 - acc: 0.8614 - val_loss: 1.1621 - val_acc: 0.7380\n",
      "Epoch 112/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 0.9070 - acc: 0.8640 - val_loss: 1.1535 - val_acc: 0.7440\n",
      "Epoch 113/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.9030 - acc: 0.8620 - val_loss: 1.1539 - val_acc: 0.7350\n",
      "Epoch 114/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 0.8988 - acc: 0.8643 - val_loss: 1.1549 - val_acc: 0.7480\n",
      "Epoch 115/120\n",
      "7000/7000 [==============================] - 0s 57us/step - loss: 0.8954 - acc: 0.8649 - val_loss: 1.1518 - val_acc: 0.7360\n",
      "Epoch 116/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 0.8914 - acc: 0.8666 - val_loss: 1.1482 - val_acc: 0.7390\n",
      "Epoch 117/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 0.8878 - acc: 0.8674 - val_loss: 1.1478 - val_acc: 0.7400\n",
      "Epoch 118/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 0.8840 - acc: 0.8666 - val_loss: 1.1429 - val_acc: 0.7450\n",
      "Epoch 119/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 0.8804 - acc: 0.8681 - val_loss: 1.1458 - val_acc: 0.7440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 0.8768 - acc: 0.8701 - val_loss: 1.1406 - val_acc: 0.7470\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L2_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model_dict = L2_model.history\n",
    "L2_model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training accuracy as well as the validation accuracy for both the L2 and the model without regularization (for 120 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc_values = L2_model_dict['acc'] \n",
    "val_acc_values = L2_model_dict['val_acc']\n",
    "model_acc = model_val_dict['acc']\n",
    "model_val_acc = model_val_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, acc_values, 'g', label='Training acc L2')\n",
    "plt.plot(epochs, val_acc_values, 'g', label='Validation acc L2')\n",
    "plt.plot(epochs, model_acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, model_val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training & validation accuracy L2 vs regular')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at L1 regularization. Will this work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7000/7000 [==============================] - 1s 85us/step - loss: 16.0684 - acc: 0.1584 - val_loss: 15.6604 - val_acc: 0.1980\n",
      "Epoch 2/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 15.3470 - acc: 0.1844 - val_loss: 14.9664 - val_acc: 0.2260\n",
      "Epoch 3/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 14.6584 - acc: 0.2073 - val_loss: 14.2921 - val_acc: 0.2470\n",
      "Epoch 4/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 13.9905 - acc: 0.2246 - val_loss: 13.6356 - val_acc: 0.2640\n",
      "Epoch 5/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 13.3415 - acc: 0.2453 - val_loss: 12.9955 - val_acc: 0.2710\n",
      "Epoch 6/120\n",
      "7000/7000 [==============================] - 0s 38us/step - loss: 12.7098 - acc: 0.2553 - val_loss: 12.3733 - val_acc: 0.2820\n",
      "Epoch 7/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 12.0954 - acc: 0.2679 - val_loss: 11.7683 - val_acc: 0.2880\n",
      "Epoch 8/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 11.4990 - acc: 0.2790 - val_loss: 11.1820 - val_acc: 0.3070\n",
      "Epoch 9/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 10.9202 - acc: 0.2909 - val_loss: 10.6146 - val_acc: 0.3260\n",
      "Epoch 10/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 10.3596 - acc: 0.3054 - val_loss: 10.0653 - val_acc: 0.3520\n",
      "Epoch 11/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 9.8158 - acc: 0.3314 - val_loss: 9.5296 - val_acc: 0.3520\n",
      "Epoch 12/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 9.2895 - acc: 0.3353 - val_loss: 9.0160 - val_acc: 0.3830\n",
      "Epoch 13/120\n",
      "7000/7000 [==============================] - 0s 51us/step - loss: 8.7817 - acc: 0.3650 - val_loss: 8.5186 - val_acc: 0.3870\n",
      "Epoch 14/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 8.2926 - acc: 0.3801 - val_loss: 8.0405 - val_acc: 0.4160\n",
      "Epoch 15/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 7.8220 - acc: 0.4129 - val_loss: 7.5804 - val_acc: 0.4350\n",
      "Epoch 16/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 7.3696 - acc: 0.4307 - val_loss: 7.1401 - val_acc: 0.4660\n",
      "Epoch 17/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 6.9361 - acc: 0.4601 - val_loss: 6.7171 - val_acc: 0.4850\n",
      "Epoch 18/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 6.5211 - acc: 0.4859 - val_loss: 6.3129 - val_acc: 0.4950\n",
      "Epoch 19/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 6.1250 - acc: 0.5049 - val_loss: 5.9277 - val_acc: 0.5130\n",
      "Epoch 20/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 5.7467 - acc: 0.5210 - val_loss: 5.5608 - val_acc: 0.5450\n",
      "Epoch 21/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 5.3867 - acc: 0.5413 - val_loss: 5.2167 - val_acc: 0.5660\n",
      "Epoch 22/120\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 5.0462 - acc: 0.5633 - val_loss: 4.8846 - val_acc: 0.5750\n",
      "Epoch 23/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 4.7252 - acc: 0.5774 - val_loss: 4.5730 - val_acc: 0.5740\n",
      "Epoch 24/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 4.4238 - acc: 0.5820 - val_loss: 4.2837 - val_acc: 0.5860\n",
      "Epoch 25/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 4.1411 - acc: 0.5973 - val_loss: 4.0135 - val_acc: 0.5960\n",
      "Epoch 26/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 3.8776 - acc: 0.6071 - val_loss: 3.7595 - val_acc: 0.5940\n",
      "Epoch 27/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 3.6340 - acc: 0.6106 - val_loss: 3.5274 - val_acc: 0.6040\n",
      "Epoch 28/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 3.4090 - acc: 0.6211 - val_loss: 3.3111 - val_acc: 0.6030\n",
      "Epoch 29/120\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 3.2031 - acc: 0.6219 - val_loss: 3.1142 - val_acc: 0.6060\n",
      "Epoch 30/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 3.0152 - acc: 0.6311 - val_loss: 2.9392 - val_acc: 0.6180\n",
      "Epoch 31/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 2.8466 - acc: 0.6366 - val_loss: 2.7820 - val_acc: 0.6280\n",
      "Epoch 32/120\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 2.6967 - acc: 0.6397 - val_loss: 2.6390 - val_acc: 0.6340\n",
      "Epoch 33/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 2.5657 - acc: 0.6451 - val_loss: 2.5192 - val_acc: 0.6300\n",
      "Epoch 34/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 2.4517 - acc: 0.6481 - val_loss: 2.4148 - val_acc: 0.6290\n",
      "Epoch 35/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 2.3554 - acc: 0.6499 - val_loss: 2.3255 - val_acc: 0.6340\n",
      "Epoch 36/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 2.2759 - acc: 0.6546 - val_loss: 2.2561 - val_acc: 0.6450\n",
      "Epoch 37/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 2.2107 - acc: 0.6560 - val_loss: 2.1981 - val_acc: 0.6410\n",
      "Epoch 38/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 2.1607 - acc: 0.6610 - val_loss: 2.1535 - val_acc: 0.6460\n",
      "Epoch 39/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 2.1234 - acc: 0.6609 - val_loss: 2.1208 - val_acc: 0.6450\n",
      "Epoch 40/120\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 2.0937 - acc: 0.6634 - val_loss: 2.0946 - val_acc: 0.6510\n",
      "Epoch 41/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 2.0678 - acc: 0.6669 - val_loss: 2.0711 - val_acc: 0.6440\n",
      "Epoch 42/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 2.0454 - acc: 0.6699 - val_loss: 2.0479 - val_acc: 0.6490\n",
      "Epoch 43/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 2.0237 - acc: 0.6687 - val_loss: 2.0315 - val_acc: 0.6540\n",
      "Epoch 44/120\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 2.0037 - acc: 0.6714 - val_loss: 2.0090 - val_acc: 0.6560\n",
      "Epoch 45/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.9849 - acc: 0.6754 - val_loss: 1.9902 - val_acc: 0.6520\n",
      "Epoch 46/120\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.9670 - acc: 0.6771 - val_loss: 1.9763 - val_acc: 0.6590\n",
      "Epoch 47/120\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.9491 - acc: 0.6797 - val_loss: 1.9554 - val_acc: 0.6600\n",
      "Epoch 48/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.9327 - acc: 0.6817 - val_loss: 1.9428 - val_acc: 0.6630\n",
      "Epoch 49/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.9169 - acc: 0.6836 - val_loss: 1.9240 - val_acc: 0.6630\n",
      "Epoch 50/120\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 1.9012 - acc: 0.6869 - val_loss: 1.9117 - val_acc: 0.6620\n",
      "Epoch 51/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.8864 - acc: 0.6859 - val_loss: 1.8962 - val_acc: 0.6630\n",
      "Epoch 52/120\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.8719 - acc: 0.6870 - val_loss: 1.8827 - val_acc: 0.6640\n",
      "Epoch 53/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.8582 - acc: 0.6873 - val_loss: 1.8698 - val_acc: 0.6630\n",
      "Epoch 54/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.8451 - acc: 0.6886 - val_loss: 1.8571 - val_acc: 0.6710\n",
      "Epoch 55/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.8320 - acc: 0.6901 - val_loss: 1.8495 - val_acc: 0.6670\n",
      "Epoch 56/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.8194 - acc: 0.6909 - val_loss: 1.8349 - val_acc: 0.6690\n",
      "Epoch 57/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.8076 - acc: 0.6909 - val_loss: 1.8303 - val_acc: 0.6710\n",
      "Epoch 58/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.7956 - acc: 0.6923 - val_loss: 1.8099 - val_acc: 0.6750\n",
      "Epoch 59/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.7842 - acc: 0.6936 - val_loss: 1.7967 - val_acc: 0.6730\n",
      "Epoch 60/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.7727 - acc: 0.6944 - val_loss: 1.7897 - val_acc: 0.6750\n",
      "Epoch 61/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.7623 - acc: 0.6940 - val_loss: 1.7816 - val_acc: 0.6760\n",
      "Epoch 62/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.7516 - acc: 0.6957 - val_loss: 1.7654 - val_acc: 0.6750\n",
      "Epoch 63/120\n",
      "7000/7000 [==============================] - 0s 59us/step - loss: 1.7407 - acc: 0.6966 - val_loss: 1.7603 - val_acc: 0.6740\n",
      "Epoch 64/120\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 1.7310 - acc: 0.6949 - val_loss: 1.7485 - val_acc: 0.6800\n",
      "Epoch 65/120\n",
      "7000/7000 [==============================] - 0s 46us/step - loss: 1.7210 - acc: 0.6960 - val_loss: 1.7384 - val_acc: 0.6780\n",
      "Epoch 66/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.7111 - acc: 0.6994 - val_loss: 1.7263 - val_acc: 0.6680\n",
      "Epoch 67/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.7021 - acc: 0.6990 - val_loss: 1.7178 - val_acc: 0.6780\n",
      "Epoch 68/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.6926 - acc: 0.7000 - val_loss: 1.7239 - val_acc: 0.6780\n",
      "Epoch 69/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.6839 - acc: 0.6994 - val_loss: 1.7009 - val_acc: 0.6770\n",
      "Epoch 70/120\n",
      "7000/7000 [==============================] - 0s 47us/step - loss: 1.6747 - acc: 0.6999 - val_loss: 1.6946 - val_acc: 0.6750\n",
      "Epoch 71/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.6657 - acc: 0.7020 - val_loss: 1.6813 - val_acc: 0.6710\n",
      "Epoch 72/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.6571 - acc: 0.7024 - val_loss: 1.6756 - val_acc: 0.6810\n",
      "Epoch 73/120\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 1.6484 - acc: 0.7014 - val_loss: 1.6674 - val_acc: 0.6800\n",
      "Epoch 74/120\n",
      "7000/7000 [==============================] - 0s 53us/step - loss: 1.6397 - acc: 0.7036 - val_loss: 1.6596 - val_acc: 0.6790\n",
      "Epoch 75/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.6317 - acc: 0.7037 - val_loss: 1.6503 - val_acc: 0.6820\n",
      "Epoch 76/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.6230 - acc: 0.7044 - val_loss: 1.6440 - val_acc: 0.6790\n",
      "Epoch 77/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.6153 - acc: 0.7044 - val_loss: 1.6363 - val_acc: 0.6810\n",
      "Epoch 78/120\n",
      "7000/7000 [==============================] - 0s 61us/step - loss: 1.6078 - acc: 0.7057 - val_loss: 1.6308 - val_acc: 0.6810\n",
      "Epoch 79/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.5997 - acc: 0.7067 - val_loss: 1.6203 - val_acc: 0.6810\n",
      "Epoch 80/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.5921 - acc: 0.7053 - val_loss: 1.6132 - val_acc: 0.6850\n",
      "Epoch 81/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.5852 - acc: 0.7070 - val_loss: 1.6047 - val_acc: 0.6830\n",
      "Epoch 82/120\n",
      "7000/7000 [==============================] - 0s 49us/step - loss: 1.5773 - acc: 0.7083 - val_loss: 1.5968 - val_acc: 0.6830\n",
      "Epoch 83/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 1.5697 - acc: 0.7096 - val_loss: 1.5897 - val_acc: 0.6810\n",
      "Epoch 84/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.5624 - acc: 0.7096 - val_loss: 1.5835 - val_acc: 0.6810\n",
      "Epoch 85/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.5551 - acc: 0.7086 - val_loss: 1.5839 - val_acc: 0.6850\n",
      "Epoch 86/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.5485 - acc: 0.7121 - val_loss: 1.5713 - val_acc: 0.6860\n",
      "Epoch 87/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.5411 - acc: 0.7109 - val_loss: 1.5718 - val_acc: 0.6850\n",
      "Epoch 88/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.5344 - acc: 0.7110 - val_loss: 1.5566 - val_acc: 0.6780\n",
      "Epoch 89/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.5278 - acc: 0.7099 - val_loss: 1.5590 - val_acc: 0.6840\n",
      "Epoch 90/120\n",
      "7000/7000 [==============================] - 0s 38us/step - loss: 1.5213 - acc: 0.7094 - val_loss: 1.5421 - val_acc: 0.6870\n",
      "Epoch 91/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.5142 - acc: 0.7119 - val_loss: 1.5438 - val_acc: 0.6830\n",
      "Epoch 92/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.5072 - acc: 0.7121 - val_loss: 1.5272 - val_acc: 0.6840\n",
      "Epoch 93/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.5009 - acc: 0.7143 - val_loss: 1.5243 - val_acc: 0.6820\n",
      "Epoch 94/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.4948 - acc: 0.7130 - val_loss: 1.5188 - val_acc: 0.6870\n",
      "Epoch 95/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.4881 - acc: 0.7136 - val_loss: 1.5117 - val_acc: 0.6850\n",
      "Epoch 96/120\n",
      "7000/7000 [==============================] - 0s 70us/step - loss: 1.4813 - acc: 0.7146 - val_loss: 1.5100 - val_acc: 0.6850\n",
      "Epoch 97/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.4757 - acc: 0.7149 - val_loss: 1.4991 - val_acc: 0.6850\n",
      "Epoch 98/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.4694 - acc: 0.7149 - val_loss: 1.4932 - val_acc: 0.6870\n",
      "Epoch 99/120\n",
      "7000/7000 [==============================] - 0s 43us/step - loss: 1.4632 - acc: 0.7154 - val_loss: 1.4868 - val_acc: 0.6900\n",
      "Epoch 100/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.4570 - acc: 0.7160 - val_loss: 1.4891 - val_acc: 0.6880\n",
      "Epoch 101/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.4515 - acc: 0.7149 - val_loss: 1.4900 - val_acc: 0.6890\n",
      "Epoch 102/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.4464 - acc: 0.7151 - val_loss: 1.4718 - val_acc: 0.6900\n",
      "Epoch 103/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.4392 - acc: 0.7160 - val_loss: 1.4696 - val_acc: 0.6940\n",
      "Epoch 104/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.4338 - acc: 0.7181 - val_loss: 1.4658 - val_acc: 0.6950\n",
      "Epoch 105/120\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 1.4286 - acc: 0.7167 - val_loss: 1.4567 - val_acc: 0.6920\n",
      "Epoch 106/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.4222 - acc: 0.7164 - val_loss: 1.4528 - val_acc: 0.6870\n",
      "Epoch 107/120\n",
      "7000/7000 [==============================] - 0s 48us/step - loss: 1.4170 - acc: 0.7177 - val_loss: 1.4445 - val_acc: 0.6950\n",
      "Epoch 108/120\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.4119 - acc: 0.7184 - val_loss: 1.4494 - val_acc: 0.6940\n",
      "Epoch 109/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.4061 - acc: 0.7187 - val_loss: 1.4374 - val_acc: 0.6910\n",
      "Epoch 110/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.4008 - acc: 0.7167 - val_loss: 1.4315 - val_acc: 0.7010\n",
      "Epoch 111/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.3953 - acc: 0.7207 - val_loss: 1.4339 - val_acc: 0.6930\n",
      "Epoch 112/120\n",
      "7000/7000 [==============================] - 0s 55us/step - loss: 1.3909 - acc: 0.7197 - val_loss: 1.4177 - val_acc: 0.6930\n",
      "Epoch 113/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.3848 - acc: 0.7207 - val_loss: 1.4181 - val_acc: 0.6950\n",
      "Epoch 114/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.3794 - acc: 0.7217 - val_loss: 1.4097 - val_acc: 0.7000\n",
      "Epoch 115/120\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 1.3744 - acc: 0.7216 - val_loss: 1.4088 - val_acc: 0.6940\n",
      "Epoch 116/120\n",
      "7000/7000 [==============================] - 0s 45us/step - loss: 1.3698 - acc: 0.7213 - val_loss: 1.3994 - val_acc: 0.6950\n",
      "Epoch 117/120\n",
      "7000/7000 [==============================] - 0s 54us/step - loss: 1.3649 - acc: 0.7210 - val_loss: 1.3984 - val_acc: 0.6970\n",
      "Epoch 118/120\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 1.3595 - acc: 0.7217 - val_loss: 1.3860 - val_acc: 0.6940\n",
      "Epoch 119/120\n",
      "7000/7000 [==============================] - 0s 41us/step - loss: 1.3547 - acc: 0.7224 - val_loss: 1.3863 - val_acc: 0.6960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/120\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 1.3493 - acc: 0.7217 - val_loss: 1.3814 - val_acc: 0.6970\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "L1_model_dict = L1_model.history\n",
    "plt.clf()\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, acc_values, 'g', label='Training acc L1')\n",
    "plt.plot(epochs, val_acc_values, 'g.', label='Validation acc L1')\n",
    "plt.title('Training & validation accuracy with L1 regularization')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy doesn't reach rates much higher than 70%. It does seem like you can still improve the model by training much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "7000/7000 [==============================] - 1s 90us/step - loss: 16.0684 - acc: 0.1584 - val_loss: 15.6604 - val_acc: 0.1980\n",
      "Epoch 2/1000\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 15.3470 - acc: 0.1844 - val_loss: 14.9664 - val_acc: 0.2260\n",
      "Epoch 3/1000\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 14.6584 - acc: 0.2073 - val_loss: 14.2921 - val_acc: 0.2470\n",
      "Epoch 4/1000\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 13.9905 - acc: 0.2246 - val_loss: 13.6356 - val_acc: 0.2640\n",
      "Epoch 5/1000\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 13.3415 - acc: 0.2451 - val_loss: 12.9956 - val_acc: 0.2710\n",
      "Epoch 6/1000\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 12.7098 - acc: 0.2551 - val_loss: 12.3733 - val_acc: 0.2820\n",
      "Epoch 7/1000\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 12.0955 - acc: 0.2681 - val_loss: 11.7683 - val_acc: 0.2890\n",
      "Epoch 8/1000\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 11.4990 - acc: 0.2793 - val_loss: 11.1820 - val_acc: 0.3070\n",
      "Epoch 9/1000\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 10.9203 - acc: 0.2909 - val_loss: 10.6146 - val_acc: 0.3270\n",
      "Epoch 10/1000\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 10.3597 - acc: 0.3053 - val_loss: 10.0654 - val_acc: 0.3520\n",
      "Epoch 11/1000\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 9.8159 - acc: 0.3313 - val_loss: 9.5296 - val_acc: 0.3520\n",
      "Epoch 12/1000\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 9.2896 - acc: 0.3347 - val_loss: 9.0160 - val_acc: 0.3830\n",
      "Epoch 13/1000\n",
      "7000/7000 [==============================] - 0s 42us/step - loss: 8.7818 - acc: 0.3651 - val_loss: 8.5186 - val_acc: 0.3860\n",
      "Epoch 14/1000\n",
      "7000/7000 [==============================] - 0s 50us/step - loss: 8.2927 - acc: 0.3800 - val_loss: 8.0405 - val_acc: 0.4150\n",
      "Epoch 15/1000\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 7.8221 - acc: 0.4124 - val_loss: 7.5805 - val_acc: 0.4360\n",
      "Epoch 16/1000\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 7.3697 - acc: 0.4304 - val_loss: 7.1401 - val_acc: 0.4660\n",
      "Epoch 17/1000\n",
      "7000/7000 [==============================] - 0s 33us/step - loss: 6.9362 - acc: 0.4600 - val_loss: 6.7172 - val_acc: 0.4850\n",
      "Epoch 18/1000\n",
      "7000/7000 [==============================] - 0s 44us/step - loss: 6.5212 - acc: 0.4854 - val_loss: 6.3130 - val_acc: 0.4940\n",
      "Epoch 19/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 6.1251 - acc: 0.5047 - val_loss: 5.9278 - val_acc: 0.5140\n",
      "Epoch 20/1000\n",
      "7000/7000 [==============================] - 0s 32us/step - loss: 5.7467 - acc: 0.5214 - val_loss: 5.5608 - val_acc: 0.5440\n",
      "Epoch 21/1000\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 5.3867 - acc: 0.5413 - val_loss: 5.2167 - val_acc: 0.5660\n",
      "Epoch 22/1000\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 5.0462 - acc: 0.5634 - val_loss: 4.8846 - val_acc: 0.5750\n",
      "Epoch 23/1000\n",
      "7000/7000 [==============================] - 0s 40us/step - loss: 4.7252 - acc: 0.5773 - val_loss: 4.5731 - val_acc: 0.5740\n",
      "Epoch 24/1000\n",
      "7000/7000 [==============================] - 0s 52us/step - loss: 4.4239 - acc: 0.5824 - val_loss: 4.2837 - val_acc: 0.5870\n",
      "Epoch 25/1000\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 4.1411 - acc: 0.5970 - val_loss: 4.0135 - val_acc: 0.5970\n",
      "Epoch 26/1000\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 3.8777 - acc: 0.6069 - val_loss: 3.7595 - val_acc: 0.5940\n",
      "Epoch 27/1000\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 3.6340 - acc: 0.6101 - val_loss: 3.5275 - val_acc: 0.6040\n",
      "Epoch 28/1000\n",
      "7000/7000 [==============================] - 0s 38us/step - loss: 3.4091 - acc: 0.6210 - val_loss: 3.3111 - val_acc: 0.6030\n",
      "Epoch 29/1000\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 3.2031 - acc: 0.6221 - val_loss: 3.1143 - val_acc: 0.6060\n",
      "Epoch 30/1000\n",
      "7000/7000 [==============================] - 0s 39us/step - loss: 3.0152 - acc: 0.6313 - val_loss: 2.9392 - val_acc: 0.6180\n",
      "Epoch 31/1000\n",
      "7000/7000 [==============================] - 0s 34us/step - loss: 2.8466 - acc: 0.6366 - val_loss: 2.7821 - val_acc: 0.6280\n",
      "Epoch 32/1000\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 2.6967 - acc: 0.6397 - val_loss: 2.6390 - val_acc: 0.6340\n",
      "Epoch 33/1000\n",
      "7000/7000 [==============================] - 0s 37us/step - loss: 2.5657 - acc: 0.6451 - val_loss: 2.5192 - val_acc: 0.6280\n",
      "Epoch 34/1000\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 2.4518 - acc: 0.6480 - val_loss: 2.4149 - val_acc: 0.6290\n",
      "Epoch 35/1000\n",
      "7000/7000 [==============================] - 0s 36us/step - loss: 2.3555 - acc: 0.6497 - val_loss: 2.3255 - val_acc: 0.6340\n",
      "Epoch 36/1000\n",
      "7000/7000 [==============================] - 0s 35us/step - loss: 2.2760 - acc: 0.6546 - val_loss: 2.2562 - val_acc: 0.6460\n",
      "Epoch 37/1000\n",
      "1792/7000 [======>.......................] - ETA: 0s - loss: 2.2418 - acc: 0.6496"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=1000,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L1_model_dict = L1_model.history\n",
    "plt.clf()\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "plt.plot(epochs, acc_values, 'g', label='Training acc L1')\n",
    "plt.plot(epochs, val_acc_values, 'g,', label='Validation acc L1')\n",
    "plt.title('Training & validation accuracy L2 vs regular')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 24us/step\n",
      "1500/1500 [==============================] - 0s 26us/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)\n",
    "\n",
    "results_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8237653533299764, 0.7967999999682108]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.966706668694814, 0.7499999998410543]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about the best result you've achieved so far, but you were training for quite a while! Next, experiment with dropout regularization to see if it offers any advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 2.0228 - acc: 0.1372 - val_loss: 1.9610 - val_acc: 0.1380\n",
      "Epoch 2/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.9760 - acc: 0.1439 - val_loss: 1.9430 - val_acc: 0.1630\n",
      "Epoch 3/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.9560 - acc: 0.1548 - val_loss: 1.9328 - val_acc: 0.1790\n",
      "Epoch 4/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.9462 - acc: 0.1639 - val_loss: 1.9249 - val_acc: 0.1890\n",
      "Epoch 5/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.9412 - acc: 0.1661 - val_loss: 1.9189 - val_acc: 0.2040\n",
      "Epoch 6/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.9261 - acc: 0.1800 - val_loss: 1.9124 - val_acc: 0.2090\n",
      "Epoch 7/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.9231 - acc: 0.1896 - val_loss: 1.9062 - val_acc: 0.2310\n",
      "Epoch 8/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.9152 - acc: 0.1916 - val_loss: 1.8993 - val_acc: 0.2430\n",
      "Epoch 9/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.9105 - acc: 0.1981 - val_loss: 1.8928 - val_acc: 0.2540\n",
      "Epoch 10/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.9032 - acc: 0.2036 - val_loss: 1.8854 - val_acc: 0.2590\n",
      "Epoch 11/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.8927 - acc: 0.2129 - val_loss: 1.8773 - val_acc: 0.2640\n",
      "Epoch 12/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.8881 - acc: 0.2221 - val_loss: 1.8688 - val_acc: 0.2660\n",
      "Epoch 13/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.8835 - acc: 0.2249 - val_loss: 1.8599 - val_acc: 0.2720\n",
      "Epoch 14/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.8740 - acc: 0.2337 - val_loss: 1.8489 - val_acc: 0.2840\n",
      "Epoch 15/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.8637 - acc: 0.2427 - val_loss: 1.8371 - val_acc: 0.2930\n",
      "Epoch 16/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.8544 - acc: 0.2432 - val_loss: 1.8235 - val_acc: 0.3030\n",
      "Epoch 17/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.8401 - acc: 0.2505 - val_loss: 1.8080 - val_acc: 0.3100\n",
      "Epoch 18/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.8334 - acc: 0.2677 - val_loss: 1.7913 - val_acc: 0.3120\n",
      "Epoch 19/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.8201 - acc: 0.2657 - val_loss: 1.7722 - val_acc: 0.3190\n",
      "Epoch 20/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.8009 - acc: 0.2712 - val_loss: 1.7512 - val_acc: 0.3240\n",
      "Epoch 21/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.7911 - acc: 0.2812 - val_loss: 1.7285 - val_acc: 0.3310\n",
      "Epoch 22/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.7735 - acc: 0.2939 - val_loss: 1.7043 - val_acc: 0.3420\n",
      "Epoch 23/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.7500 - acc: 0.3079 - val_loss: 1.6776 - val_acc: 0.3510\n",
      "Epoch 24/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.7402 - acc: 0.3083 - val_loss: 1.6486 - val_acc: 0.3800\n",
      "Epoch 25/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.7199 - acc: 0.3201 - val_loss: 1.6207 - val_acc: 0.3930\n",
      "Epoch 26/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.6974 - acc: 0.3253 - val_loss: 1.5931 - val_acc: 0.4070\n",
      "Epoch 27/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.6781 - acc: 0.3377 - val_loss: 1.5651 - val_acc: 0.4270\n",
      "Epoch 28/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.6711 - acc: 0.3471 - val_loss: 1.5406 - val_acc: 0.4440\n",
      "Epoch 29/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.6474 - acc: 0.3469 - val_loss: 1.5145 - val_acc: 0.4510\n",
      "Epoch 30/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.6281 - acc: 0.3521 - val_loss: 1.4876 - val_acc: 0.4610\n",
      "Epoch 31/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.6150 - acc: 0.3639 - val_loss: 1.4634 - val_acc: 0.4750\n",
      "Epoch 32/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.5985 - acc: 0.3748 - val_loss: 1.4395 - val_acc: 0.4940\n",
      "Epoch 33/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.5763 - acc: 0.3808 - val_loss: 1.4134 - val_acc: 0.5050\n",
      "Epoch 34/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.5539 - acc: 0.3969 - val_loss: 1.3892 - val_acc: 0.5280\n",
      "Epoch 35/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.5548 - acc: 0.3883 - val_loss: 1.3709 - val_acc: 0.5280\n",
      "Epoch 36/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.5287 - acc: 0.4059 - val_loss: 1.3478 - val_acc: 0.5470\n",
      "Epoch 37/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.5163 - acc: 0.4099 - val_loss: 1.3288 - val_acc: 0.5560\n",
      "Epoch 38/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.5083 - acc: 0.4137 - val_loss: 1.3094 - val_acc: 0.5720\n",
      "Epoch 39/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.4847 - acc: 0.4319 - val_loss: 1.2877 - val_acc: 0.5770\n",
      "Epoch 40/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.4855 - acc: 0.4204 - val_loss: 1.2714 - val_acc: 0.5920\n",
      "Epoch 41/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.4642 - acc: 0.4336 - val_loss: 1.2518 - val_acc: 0.6070\n",
      "Epoch 42/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.4565 - acc: 0.4380 - val_loss: 1.2329 - val_acc: 0.6190\n",
      "Epoch 43/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.4303 - acc: 0.4479 - val_loss: 1.2134 - val_acc: 0.6380\n",
      "Epoch 44/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.4283 - acc: 0.4561 - val_loss: 1.1985 - val_acc: 0.6450\n",
      "Epoch 45/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.3998 - acc: 0.4632 - val_loss: 1.1791 - val_acc: 0.6420\n",
      "Epoch 46/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.3886 - acc: 0.4664 - val_loss: 1.1616 - val_acc: 0.6460\n",
      "Epoch 47/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.3729 - acc: 0.4784 - val_loss: 1.1441 - val_acc: 0.6540\n",
      "Epoch 48/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.3671 - acc: 0.4807 - val_loss: 1.1300 - val_acc: 0.6640\n",
      "Epoch 49/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.3640 - acc: 0.4808 - val_loss: 1.1187 - val_acc: 0.6570\n",
      "Epoch 50/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.3373 - acc: 0.4841 - val_loss: 1.0995 - val_acc: 0.6660\n",
      "Epoch 51/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.3246 - acc: 0.4999 - val_loss: 1.0832 - val_acc: 0.6730\n",
      "Epoch 52/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.3099 - acc: 0.5103 - val_loss: 1.0693 - val_acc: 0.6760\n",
      "Epoch 53/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.3033 - acc: 0.5064 - val_loss: 1.0562 - val_acc: 0.6850\n",
      "Epoch 54/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.2944 - acc: 0.5116 - val_loss: 1.0446 - val_acc: 0.6820\n",
      "Epoch 55/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.2866 - acc: 0.5151 - val_loss: 1.0344 - val_acc: 0.6850\n",
      "Epoch 56/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.2655 - acc: 0.5233 - val_loss: 1.0180 - val_acc: 0.6880\n",
      "Epoch 57/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.2563 - acc: 0.5239 - val_loss: 1.0041 - val_acc: 0.6920\n",
      "Epoch 58/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.2481 - acc: 0.5256 - val_loss: 0.9925 - val_acc: 0.6950\n",
      "Epoch 59/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.2476 - acc: 0.5280 - val_loss: 0.9800 - val_acc: 0.6940\n",
      "Epoch 60/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.2354 - acc: 0.5300 - val_loss: 0.9684 - val_acc: 0.7050\n",
      "Epoch 61/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 1.2150 - acc: 0.5400 - val_loss: 0.9589 - val_acc: 0.7120\n",
      "Epoch 62/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.2109 - acc: 0.5513 - val_loss: 0.9459 - val_acc: 0.7030\n",
      "Epoch 63/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.2099 - acc: 0.5472 - val_loss: 0.9360 - val_acc: 0.7070\n",
      "Epoch 64/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.1975 - acc: 0.5485 - val_loss: 0.9275 - val_acc: 0.7140\n",
      "Epoch 65/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 1.1849 - acc: 0.5585 - val_loss: 0.9184 - val_acc: 0.7120\n",
      "Epoch 66/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.1837 - acc: 0.5669 - val_loss: 0.9071 - val_acc: 0.7230\n",
      "Epoch 67/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.1751 - acc: 0.5639 - val_loss: 0.8986 - val_acc: 0.7200\n",
      "Epoch 68/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.1549 - acc: 0.5747 - val_loss: 0.8873 - val_acc: 0.7260\n",
      "Epoch 69/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.1635 - acc: 0.5651 - val_loss: 0.8807 - val_acc: 0.7260\n",
      "Epoch 70/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.1557 - acc: 0.5672 - val_loss: 0.8725 - val_acc: 0.7280\n",
      "Epoch 71/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 1.1337 - acc: 0.5803 - val_loss: 0.8605 - val_acc: 0.7310\n",
      "Epoch 72/200\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.1170 - acc: 0.5859 - val_loss: 0.8531 - val_acc: 0.7290\n",
      "Epoch 73/200\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.1179 - acc: 0.5797 - val_loss: 0.8437 - val_acc: 0.7330\n",
      "Epoch 74/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.1314 - acc: 0.5715 - val_loss: 0.8400 - val_acc: 0.7340\n",
      "Epoch 75/200\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 1.0935 - acc: 0.5948 - val_loss: 0.8310 - val_acc: 0.7370\n",
      "Epoch 76/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.0940 - acc: 0.5903 - val_loss: 0.8213 - val_acc: 0.7360\n",
      "Epoch 77/200\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 1.0864 - acc: 0.5919 - val_loss: 0.8140 - val_acc: 0.7370\n",
      "Epoch 78/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.0872 - acc: 0.5936 - val_loss: 0.8073 - val_acc: 0.7370\n",
      "Epoch 79/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.0767 - acc: 0.5975 - val_loss: 0.7990 - val_acc: 0.7370\n",
      "Epoch 80/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.0606 - acc: 0.6045 - val_loss: 0.7912 - val_acc: 0.7390\n",
      "Epoch 81/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.0702 - acc: 0.6021 - val_loss: 0.7851 - val_acc: 0.7400\n",
      "Epoch 82/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.0764 - acc: 0.5968 - val_loss: 0.7811 - val_acc: 0.7430\n",
      "Epoch 83/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.0551 - acc: 0.6103 - val_loss: 0.7777 - val_acc: 0.7410\n",
      "Epoch 84/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 1.0540 - acc: 0.6044 - val_loss: 0.7700 - val_acc: 0.7450\n",
      "Epoch 85/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.0394 - acc: 0.6139 - val_loss: 0.7644 - val_acc: 0.7470\n",
      "Epoch 86/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 1.0397 - acc: 0.6067 - val_loss: 0.7589 - val_acc: 0.7470\n",
      "Epoch 87/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.0272 - acc: 0.6219 - val_loss: 0.7505 - val_acc: 0.7510\n",
      "Epoch 88/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 1.0158 - acc: 0.6245 - val_loss: 0.7446 - val_acc: 0.7460\n",
      "Epoch 89/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.0275 - acc: 0.6136 - val_loss: 0.7412 - val_acc: 0.7500\n",
      "Epoch 90/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 1.0228 - acc: 0.6173 - val_loss: 0.7377 - val_acc: 0.7490\n",
      "Epoch 91/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 1.0199 - acc: 0.6184 - val_loss: 0.7353 - val_acc: 0.7500\n",
      "Epoch 92/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 1.0134 - acc: 0.6215 - val_loss: 0.7303 - val_acc: 0.7530\n",
      "Epoch 93/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 1.0174 - acc: 0.6208 - val_loss: 0.7271 - val_acc: 0.7500\n",
      "Epoch 94/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 1.0023 - acc: 0.6265 - val_loss: 0.7241 - val_acc: 0.7500\n",
      "Epoch 95/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 1.0029 - acc: 0.6220 - val_loss: 0.7190 - val_acc: 0.7540\n",
      "Epoch 96/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.9879 - acc: 0.6327 - val_loss: 0.7127 - val_acc: 0.7560\n",
      "Epoch 97/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.9865 - acc: 0.6252 - val_loss: 0.7100 - val_acc: 0.7550\n",
      "Epoch 98/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9628 - acc: 0.6372 - val_loss: 0.7027 - val_acc: 0.7590\n",
      "Epoch 99/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9743 - acc: 0.6404 - val_loss: 0.7010 - val_acc: 0.7580\n",
      "Epoch 100/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 0.9698 - acc: 0.6383 - val_loss: 0.6961 - val_acc: 0.7580\n",
      "Epoch 101/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.9758 - acc: 0.6328 - val_loss: 0.6926 - val_acc: 0.7590\n",
      "Epoch 102/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9662 - acc: 0.6391 - val_loss: 0.6881 - val_acc: 0.7580\n",
      "Epoch 103/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.9672 - acc: 0.6409 - val_loss: 0.6854 - val_acc: 0.7550\n",
      "Epoch 104/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9480 - acc: 0.6501 - val_loss: 0.6818 - val_acc: 0.7640\n",
      "Epoch 105/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9476 - acc: 0.6475 - val_loss: 0.6776 - val_acc: 0.7610\n",
      "Epoch 106/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9526 - acc: 0.6485 - val_loss: 0.6744 - val_acc: 0.7600\n",
      "Epoch 107/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.9478 - acc: 0.6456 - val_loss: 0.6734 - val_acc: 0.7620\n",
      "Epoch 108/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.9373 - acc: 0.6532 - val_loss: 0.6690 - val_acc: 0.7600\n",
      "Epoch 109/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9404 - acc: 0.6469 - val_loss: 0.6653 - val_acc: 0.7620\n",
      "Epoch 110/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.9366 - acc: 0.6524 - val_loss: 0.6629 - val_acc: 0.7620\n",
      "Epoch 111/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.9141 - acc: 0.6569 - val_loss: 0.6577 - val_acc: 0.7650\n",
      "Epoch 112/200\n",
      "7500/7500 [==============================] - 0s 32us/step - loss: 0.9396 - acc: 0.6484 - val_loss: 0.6591 - val_acc: 0.7620\n",
      "Epoch 113/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9192 - acc: 0.6569 - val_loss: 0.6553 - val_acc: 0.7630\n",
      "Epoch 114/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.9250 - acc: 0.6605 - val_loss: 0.6542 - val_acc: 0.7620\n",
      "Epoch 115/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.9224 - acc: 0.6533 - val_loss: 0.6496 - val_acc: 0.7640\n",
      "Epoch 116/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9200 - acc: 0.6568 - val_loss: 0.6510 - val_acc: 0.7640\n",
      "Epoch 117/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9003 - acc: 0.6680 - val_loss: 0.6470 - val_acc: 0.7610\n",
      "Epoch 118/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.9010 - acc: 0.6671 - val_loss: 0.6434 - val_acc: 0.7660\n",
      "Epoch 119/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.9034 - acc: 0.6628 - val_loss: 0.6428 - val_acc: 0.7640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.9110 - acc: 0.6584 - val_loss: 0.6407 - val_acc: 0.7640\n",
      "Epoch 121/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8934 - acc: 0.6695 - val_loss: 0.6380 - val_acc: 0.7670\n",
      "Epoch 122/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.8921 - acc: 0.6660 - val_loss: 0.6374 - val_acc: 0.7640\n",
      "Epoch 123/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8894 - acc: 0.6664 - val_loss: 0.6322 - val_acc: 0.7660\n",
      "Epoch 124/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8856 - acc: 0.6701 - val_loss: 0.6285 - val_acc: 0.7670\n",
      "Epoch 125/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.8889 - acc: 0.6688 - val_loss: 0.6283 - val_acc: 0.7700\n",
      "Epoch 126/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8769 - acc: 0.6671 - val_loss: 0.6276 - val_acc: 0.7680\n",
      "Epoch 127/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.8794 - acc: 0.6720 - val_loss: 0.6248 - val_acc: 0.7670\n",
      "Epoch 128/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8593 - acc: 0.6759 - val_loss: 0.6234 - val_acc: 0.7690\n",
      "Epoch 129/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 0.8801 - acc: 0.6691 - val_loss: 0.6223 - val_acc: 0.7690\n",
      "Epoch 130/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8658 - acc: 0.6731 - val_loss: 0.6190 - val_acc: 0.7720\n",
      "Epoch 131/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8869 - acc: 0.6708 - val_loss: 0.6189 - val_acc: 0.7750\n",
      "Epoch 132/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 0.8563 - acc: 0.6824 - val_loss: 0.6160 - val_acc: 0.7750\n",
      "Epoch 133/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8640 - acc: 0.6839 - val_loss: 0.6151 - val_acc: 0.7740\n",
      "Epoch 134/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 0.8484 - acc: 0.6855 - val_loss: 0.6113 - val_acc: 0.7710\n",
      "Epoch 135/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8609 - acc: 0.6819 - val_loss: 0.6112 - val_acc: 0.7730\n",
      "Epoch 136/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.8558 - acc: 0.6849 - val_loss: 0.6074 - val_acc: 0.7730\n",
      "Epoch 137/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8475 - acc: 0.6873 - val_loss: 0.6076 - val_acc: 0.7700\n",
      "Epoch 138/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.8470 - acc: 0.6843 - val_loss: 0.6069 - val_acc: 0.7720\n",
      "Epoch 139/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.8506 - acc: 0.6827 - val_loss: 0.6039 - val_acc: 0.7750\n",
      "Epoch 140/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.8442 - acc: 0.6788 - val_loss: 0.6027 - val_acc: 0.7720\n",
      "Epoch 141/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8418 - acc: 0.6872 - val_loss: 0.6037 - val_acc: 0.7760\n",
      "Epoch 142/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8406 - acc: 0.6839 - val_loss: 0.6015 - val_acc: 0.7760\n",
      "Epoch 143/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8358 - acc: 0.6884 - val_loss: 0.5979 - val_acc: 0.7790\n",
      "Epoch 144/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8416 - acc: 0.6879 - val_loss: 0.5957 - val_acc: 0.7770\n",
      "Epoch 145/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8329 - acc: 0.6801 - val_loss: 0.5942 - val_acc: 0.7750\n",
      "Epoch 146/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8179 - acc: 0.6956 - val_loss: 0.5947 - val_acc: 0.7760\n",
      "Epoch 147/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8390 - acc: 0.6831 - val_loss: 0.5946 - val_acc: 0.7770\n",
      "Epoch 148/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8243 - acc: 0.6896 - val_loss: 0.5922 - val_acc: 0.7760\n",
      "Epoch 149/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.8181 - acc: 0.6913 - val_loss: 0.5918 - val_acc: 0.7810\n",
      "Epoch 150/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8336 - acc: 0.6841 - val_loss: 0.5914 - val_acc: 0.7810\n",
      "Epoch 151/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8093 - acc: 0.6941 - val_loss: 0.5911 - val_acc: 0.7800\n",
      "Epoch 152/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8186 - acc: 0.6928 - val_loss: 0.5864 - val_acc: 0.7850\n",
      "Epoch 153/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8137 - acc: 0.7011 - val_loss: 0.5850 - val_acc: 0.7760\n",
      "Epoch 154/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8236 - acc: 0.6940 - val_loss: 0.5852 - val_acc: 0.7820\n",
      "Epoch 155/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8231 - acc: 0.6897 - val_loss: 0.5852 - val_acc: 0.7830\n",
      "Epoch 156/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8060 - acc: 0.7013 - val_loss: 0.5845 - val_acc: 0.7790\n",
      "Epoch 157/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7927 - acc: 0.7033 - val_loss: 0.5826 - val_acc: 0.7810\n",
      "Epoch 158/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7906 - acc: 0.7007 - val_loss: 0.5800 - val_acc: 0.7840\n",
      "Epoch 159/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.8047 - acc: 0.6956 - val_loss: 0.5789 - val_acc: 0.7820\n",
      "Epoch 160/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.8041 - acc: 0.7039 - val_loss: 0.5785 - val_acc: 0.7840\n",
      "Epoch 161/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7914 - acc: 0.7107 - val_loss: 0.5778 - val_acc: 0.7770\n",
      "Epoch 162/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7874 - acc: 0.7096 - val_loss: 0.5766 - val_acc: 0.7780\n",
      "Epoch 163/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7860 - acc: 0.7115 - val_loss: 0.5753 - val_acc: 0.7880\n",
      "Epoch 164/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7962 - acc: 0.7027 - val_loss: 0.5772 - val_acc: 0.7800\n",
      "Epoch 165/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7840 - acc: 0.7115 - val_loss: 0.5736 - val_acc: 0.7850\n",
      "Epoch 166/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.7821 - acc: 0.7073 - val_loss: 0.5730 - val_acc: 0.7820\n",
      "Epoch 167/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7884 - acc: 0.7077 - val_loss: 0.5700 - val_acc: 0.7840\n",
      "Epoch 168/200\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7944 - acc: 0.7095 - val_loss: 0.5711 - val_acc: 0.7820\n",
      "Epoch 169/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7728 - acc: 0.7117 - val_loss: 0.5682 - val_acc: 0.7810\n",
      "Epoch 170/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 0.7821 - acc: 0.7048 - val_loss: 0.5666 - val_acc: 0.7840\n",
      "Epoch 171/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7830 - acc: 0.7076 - val_loss: 0.5673 - val_acc: 0.7840\n",
      "Epoch 172/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.7835 - acc: 0.7121 - val_loss: 0.5684 - val_acc: 0.7830\n",
      "Epoch 173/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7745 - acc: 0.7136 - val_loss: 0.5668 - val_acc: 0.7850\n",
      "Epoch 174/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7770 - acc: 0.7079 - val_loss: 0.5686 - val_acc: 0.7810\n",
      "Epoch 175/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.7860 - acc: 0.7053 - val_loss: 0.5658 - val_acc: 0.7860\n",
      "Epoch 176/200\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7738 - acc: 0.7079 - val_loss: 0.5644 - val_acc: 0.7880\n",
      "Epoch 177/200\n",
      "7500/7500 [==============================] - 0s 31us/step - loss: 0.7666 - acc: 0.7068 - val_loss: 0.5638 - val_acc: 0.7820\n",
      "Epoch 178/200\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7707 - acc: 0.7079 - val_loss: 0.5627 - val_acc: 0.7840\n",
      "Epoch 179/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7840 - acc: 0.7064 - val_loss: 0.5618 - val_acc: 0.7870\n",
      "Epoch 180/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7650 - acc: 0.7151 - val_loss: 0.5598 - val_acc: 0.7850\n",
      "Epoch 181/200\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.7661 - acc: 0.7088 - val_loss: 0.5599 - val_acc: 0.7860\n",
      "Epoch 182/200\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7444 - acc: 0.7239 - val_loss: 0.5568 - val_acc: 0.7870\n",
      "Epoch 183/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7523 - acc: 0.7149 - val_loss: 0.5578 - val_acc: 0.7830\n",
      "Epoch 184/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7616 - acc: 0.7185 - val_loss: 0.5593 - val_acc: 0.7850\n",
      "Epoch 185/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7566 - acc: 0.7108 - val_loss: 0.5588 - val_acc: 0.7860\n",
      "Epoch 186/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7467 - acc: 0.7197 - val_loss: 0.5590 - val_acc: 0.7830\n",
      "Epoch 187/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7537 - acc: 0.7157 - val_loss: 0.5566 - val_acc: 0.7800\n",
      "Epoch 188/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7494 - acc: 0.7199 - val_loss: 0.5566 - val_acc: 0.7830\n",
      "Epoch 189/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7526 - acc: 0.7203 - val_loss: 0.5554 - val_acc: 0.7880\n",
      "Epoch 190/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7362 - acc: 0.7256 - val_loss: 0.5528 - val_acc: 0.7860\n",
      "Epoch 191/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7464 - acc: 0.7181 - val_loss: 0.5523 - val_acc: 0.7850\n",
      "Epoch 192/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7515 - acc: 0.7141 - val_loss: 0.5511 - val_acc: 0.7850\n",
      "Epoch 193/200\n",
      "7500/7500 [==============================] - 0s 30us/step - loss: 0.7432 - acc: 0.7191 - val_loss: 0.5511 - val_acc: 0.7880\n",
      "Epoch 194/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7388 - acc: 0.7232 - val_loss: 0.5523 - val_acc: 0.7850\n",
      "Epoch 195/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 0.7412 - acc: 0.7212 - val_loss: 0.5543 - val_acc: 0.7840\n",
      "Epoch 196/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7288 - acc: 0.7279 - val_loss: 0.5510 - val_acc: 0.7830\n",
      "Epoch 197/200\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.7335 - acc: 0.7285 - val_loss: 0.5509 - val_acc: 0.7820\n",
      "Epoch 198/200\n",
      "7500/7500 [==============================] - 0s 25us/step - loss: 0.7255 - acc: 0.7292 - val_loss: 0.5480 - val_acc: 0.7840\n",
      "Epoch 199/200\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.7341 - acc: 0.7236 - val_loss: 0.5490 - val_acc: 0.7830\n",
      "Epoch 200/200\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.7398 - acc: 0.7244 - val_loss: 0.5489 - val_acc: 0.7840\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "model.add(layers.Dense(50, activation='relu')) #2 hidden layers\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dropout_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=200,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 24us/step\n",
      "1500/1500 [==============================] - 0s 26us/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)\n",
    "results_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.44953240927060445, 0.8355999999682109]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6567809325853984, 0.745333333492279]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again! the variance did become higher again compared to L1-regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, one of the solutions to high variance was just getting more data. You actually *have* more data, but took a subset of 10,000 units before. Let's now quadruple your data set, and see what happens. Note that you are really just lucky here, and getting more data isn't always possible, but this is a useful exercise in order to understand the power of big data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "random.seed(123)\n",
    "df = df.sample(40000)\n",
    "df.index = range(40000)\n",
    "product = df[\"Product\"]\n",
    "complaints = df[\"Consumer complaint narrative\"]\n",
    "\n",
    "#one-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(complaints)\n",
    "sequences = tokenizer.texts_to_sequences(complaints)\n",
    "one_hot_results= tokenizer.texts_to_matrix(complaints, mode='binary')\n",
    "word_index = tokenizer.word_index\n",
    "np.shape(one_hot_results)\n",
    "\n",
    "#one-hot encoding of products\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(product)\n",
    "list(le.classes_)\n",
    "product_cat = le.transform(product) \n",
    "product_onehot = to_categorical(product_cat)\n",
    "\n",
    "# train test split\n",
    "test_index = random.sample(range(1,40000), 4000)\n",
    "test = one_hot_results[test_index]\n",
    "train = np.delete(one_hot_results, test_index, 0)\n",
    "label_test = product_onehot[test_index]\n",
    "label_train = np.delete(product_onehot, test_index, 0)\n",
    "\n",
    "#Validation set\n",
    "random.seed(123)\n",
    "val = train[:3000]\n",
    "train_final = train[3000:]\n",
    "label_val = label_train[:3000]\n",
    "label_train_final = label_train[3000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33000 samples, validate on 3000 samples\n",
      "Epoch 1/120\n",
      "33000/33000 [==============================] - 1s 25us/step - loss: 1.9131 - acc: 0.1977 - val_loss: 1.8734 - val_acc: 0.2517\n",
      "Epoch 2/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 1.8204 - acc: 0.3034 - val_loss: 1.7551 - val_acc: 0.3397\n",
      "Epoch 3/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 1.6686 - acc: 0.4072 - val_loss: 1.5741 - val_acc: 0.4647\n",
      "Epoch 4/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 1.4662 - acc: 0.5248 - val_loss: 1.3619 - val_acc: 0.5560\n",
      "Epoch 5/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 1.2557 - acc: 0.6060 - val_loss: 1.1666 - val_acc: 0.6303\n",
      "Epoch 6/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 1.0768 - acc: 0.6660 - val_loss: 1.0120 - val_acc: 0.6777\n",
      "Epoch 7/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.9451 - acc: 0.7012 - val_loss: 0.9037 - val_acc: 0.7047\n",
      "Epoch 8/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.8536 - acc: 0.7191 - val_loss: 0.8281 - val_acc: 0.7210\n",
      "Epoch 9/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.7894 - acc: 0.7321 - val_loss: 0.7750 - val_acc: 0.7300\n",
      "Epoch 10/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.7434 - acc: 0.7419 - val_loss: 0.7363 - val_acc: 0.7397\n",
      "Epoch 11/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.7086 - acc: 0.7492 - val_loss: 0.7075 - val_acc: 0.7450\n",
      "Epoch 12/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.6815 - acc: 0.7555 - val_loss: 0.6846 - val_acc: 0.7507\n",
      "Epoch 13/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.6596 - acc: 0.7612 - val_loss: 0.6661 - val_acc: 0.7587\n",
      "Epoch 14/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.6413 - acc: 0.7678 - val_loss: 0.6501 - val_acc: 0.7623\n",
      "Epoch 15/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.6259 - acc: 0.7724 - val_loss: 0.6383 - val_acc: 0.7653\n",
      "Epoch 16/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.6119 - acc: 0.7780 - val_loss: 0.6275 - val_acc: 0.7700\n",
      "Epoch 17/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.5999 - acc: 0.7809 - val_loss: 0.6168 - val_acc: 0.7720\n",
      "Epoch 18/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.5891 - acc: 0.7845 - val_loss: 0.6079 - val_acc: 0.7757\n",
      "Epoch 19/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.5792 - acc: 0.7892 - val_loss: 0.6013 - val_acc: 0.7753\n",
      "Epoch 20/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.5700 - acc: 0.7920 - val_loss: 0.5924 - val_acc: 0.7813\n",
      "Epoch 21/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.5614 - acc: 0.7954 - val_loss: 0.5879 - val_acc: 0.7807\n",
      "Epoch 22/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.5535 - acc: 0.7989 - val_loss: 0.5832 - val_acc: 0.7817\n",
      "Epoch 23/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.5459 - acc: 0.8010 - val_loss: 0.5766 - val_acc: 0.7847\n",
      "Epoch 24/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.5391 - acc: 0.8044 - val_loss: 0.5735 - val_acc: 0.7850\n",
      "Epoch 25/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.5326 - acc: 0.8076 - val_loss: 0.5674 - val_acc: 0.7937\n",
      "Epoch 26/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.5264 - acc: 0.8092 - val_loss: 0.5622 - val_acc: 0.7920\n",
      "Epoch 27/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.5198 - acc: 0.8114 - val_loss: 0.5599 - val_acc: 0.7977\n",
      "Epoch 28/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.5144 - acc: 0.8140 - val_loss: 0.5571 - val_acc: 0.8000\n",
      "Epoch 29/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.5087 - acc: 0.8162 - val_loss: 0.5509 - val_acc: 0.8000\n",
      "Epoch 30/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.5033 - acc: 0.8180 - val_loss: 0.5483 - val_acc: 0.8020\n",
      "Epoch 31/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4982 - acc: 0.8205 - val_loss: 0.5443 - val_acc: 0.8023\n",
      "Epoch 32/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4934 - acc: 0.8222 - val_loss: 0.5435 - val_acc: 0.8027\n",
      "Epoch 33/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.4885 - acc: 0.8253 - val_loss: 0.5426 - val_acc: 0.8033\n",
      "Epoch 34/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.4840 - acc: 0.8256 - val_loss: 0.5386 - val_acc: 0.8080\n",
      "Epoch 35/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4799 - acc: 0.8278 - val_loss: 0.5341 - val_acc: 0.8093\n",
      "Epoch 36/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4755 - acc: 0.8305 - val_loss: 0.5322 - val_acc: 0.8100\n",
      "Epoch 37/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.4713 - acc: 0.8308 - val_loss: 0.5297 - val_acc: 0.8117\n",
      "Epoch 38/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4674 - acc: 0.8319 - val_loss: 0.5273 - val_acc: 0.8123\n",
      "Epoch 39/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4632 - acc: 0.8339 - val_loss: 0.5265 - val_acc: 0.8103\n",
      "Epoch 40/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4599 - acc: 0.8355 - val_loss: 0.5236 - val_acc: 0.8103\n",
      "Epoch 41/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4558 - acc: 0.8370 - val_loss: 0.5241 - val_acc: 0.8103\n",
      "Epoch 42/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4522 - acc: 0.8383 - val_loss: 0.5210 - val_acc: 0.8120\n",
      "Epoch 43/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4487 - acc: 0.8403 - val_loss: 0.5223 - val_acc: 0.8143\n",
      "Epoch 44/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.4453 - acc: 0.8405 - val_loss: 0.5187 - val_acc: 0.8180\n",
      "Epoch 45/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4420 - acc: 0.8427 - val_loss: 0.5206 - val_acc: 0.8153\n",
      "Epoch 46/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4388 - acc: 0.8437 - val_loss: 0.5186 - val_acc: 0.8120\n",
      "Epoch 47/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4358 - acc: 0.8442 - val_loss: 0.5154 - val_acc: 0.8133\n",
      "Epoch 48/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4324 - acc: 0.8458 - val_loss: 0.5156 - val_acc: 0.8130\n",
      "Epoch 49/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4296 - acc: 0.8474 - val_loss: 0.5147 - val_acc: 0.8150\n",
      "Epoch 50/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4266 - acc: 0.8484 - val_loss: 0.5136 - val_acc: 0.8117\n",
      "Epoch 51/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4235 - acc: 0.8492 - val_loss: 0.5142 - val_acc: 0.8167\n",
      "Epoch 52/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.4206 - acc: 0.8502 - val_loss: 0.5135 - val_acc: 0.8133\n",
      "Epoch 53/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4181 - acc: 0.8508 - val_loss: 0.5154 - val_acc: 0.8163\n",
      "Epoch 54/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4152 - acc: 0.8521 - val_loss: 0.5109 - val_acc: 0.8140\n",
      "Epoch 55/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4125 - acc: 0.8531 - val_loss: 0.5124 - val_acc: 0.8160\n",
      "Epoch 56/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4100 - acc: 0.8537 - val_loss: 0.5126 - val_acc: 0.8163\n",
      "Epoch 57/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4076 - acc: 0.8543 - val_loss: 0.5112 - val_acc: 0.8180\n",
      "Epoch 58/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.4052 - acc: 0.8555 - val_loss: 0.5120 - val_acc: 0.8113\n",
      "Epoch 59/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.4028 - acc: 0.8556 - val_loss: 0.5111 - val_acc: 0.8130\n",
      "Epoch 60/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.4000 - acc: 0.8580 - val_loss: 0.5105 - val_acc: 0.8183\n",
      "Epoch 61/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3977 - acc: 0.8590 - val_loss: 0.5116 - val_acc: 0.8163\n",
      "Epoch 62/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3953 - acc: 0.8602 - val_loss: 0.5123 - val_acc: 0.8180\n",
      "Epoch 63/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3931 - acc: 0.8606 - val_loss: 0.5089 - val_acc: 0.8157\n",
      "Epoch 64/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3908 - acc: 0.8617 - val_loss: 0.5120 - val_acc: 0.8113\n",
      "Epoch 65/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3888 - acc: 0.8624 - val_loss: 0.5128 - val_acc: 0.8157\n",
      "Epoch 66/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3863 - acc: 0.8633 - val_loss: 0.5122 - val_acc: 0.8167\n",
      "Epoch 67/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3844 - acc: 0.8638 - val_loss: 0.5100 - val_acc: 0.8157\n",
      "Epoch 68/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3821 - acc: 0.8646 - val_loss: 0.5113 - val_acc: 0.8160\n",
      "Epoch 69/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3801 - acc: 0.8665 - val_loss: 0.5136 - val_acc: 0.8120\n",
      "Epoch 70/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3779 - acc: 0.8661 - val_loss: 0.5121 - val_acc: 0.8163\n",
      "Epoch 71/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3760 - acc: 0.8688 - val_loss: 0.5113 - val_acc: 0.8117\n",
      "Epoch 72/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3741 - acc: 0.8685 - val_loss: 0.5115 - val_acc: 0.8163\n",
      "Epoch 73/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3720 - acc: 0.8689 - val_loss: 0.5121 - val_acc: 0.8167\n",
      "Epoch 74/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3702 - acc: 0.8699 - val_loss: 0.5157 - val_acc: 0.8160\n",
      "Epoch 75/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3681 - acc: 0.8702 - val_loss: 0.5137 - val_acc: 0.8160\n",
      "Epoch 76/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3661 - acc: 0.8725 - val_loss: 0.5126 - val_acc: 0.8143\n",
      "Epoch 77/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3641 - acc: 0.8718 - val_loss: 0.5138 - val_acc: 0.8147\n",
      "Epoch 78/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3627 - acc: 0.8725 - val_loss: 0.5194 - val_acc: 0.8160\n",
      "Epoch 79/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3610 - acc: 0.8739 - val_loss: 0.5152 - val_acc: 0.8117\n",
      "Epoch 80/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3589 - acc: 0.8742 - val_loss: 0.5166 - val_acc: 0.8170\n",
      "Epoch 81/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3571 - acc: 0.8754 - val_loss: 0.5157 - val_acc: 0.8147\n",
      "Epoch 82/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3557 - acc: 0.8765 - val_loss: 0.5159 - val_acc: 0.8150\n",
      "Epoch 83/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3536 - acc: 0.8771 - val_loss: 0.5180 - val_acc: 0.8157\n",
      "Epoch 84/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3520 - acc: 0.8768 - val_loss: 0.5189 - val_acc: 0.8140\n",
      "Epoch 85/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3501 - acc: 0.8779 - val_loss: 0.5177 - val_acc: 0.8160\n",
      "Epoch 86/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3487 - acc: 0.8785 - val_loss: 0.5218 - val_acc: 0.8167\n",
      "Epoch 87/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3468 - acc: 0.8794 - val_loss: 0.5212 - val_acc: 0.8137\n",
      "Epoch 88/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.3456 - acc: 0.8793 - val_loss: 0.5198 - val_acc: 0.8153\n",
      "Epoch 89/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.3438 - acc: 0.8801 - val_loss: 0.5210 - val_acc: 0.8143\n",
      "Epoch 90/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3421 - acc: 0.8802 - val_loss: 0.5235 - val_acc: 0.8127\n",
      "Epoch 91/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3406 - acc: 0.8813 - val_loss: 0.5213 - val_acc: 0.8143\n",
      "Epoch 92/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3386 - acc: 0.8818 - val_loss: 0.5223 - val_acc: 0.8153\n",
      "Epoch 93/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.3374 - acc: 0.8827 - val_loss: 0.5232 - val_acc: 0.8137\n",
      "Epoch 94/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3358 - acc: 0.8840 - val_loss: 0.5240 - val_acc: 0.8150\n",
      "Epoch 95/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3342 - acc: 0.8832 - val_loss: 0.5284 - val_acc: 0.8160\n",
      "Epoch 96/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3328 - acc: 0.8852 - val_loss: 0.5263 - val_acc: 0.8160\n",
      "Epoch 97/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3312 - acc: 0.8856 - val_loss: 0.5260 - val_acc: 0.8137\n",
      "Epoch 98/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3297 - acc: 0.8869 - val_loss: 0.5322 - val_acc: 0.8117\n",
      "Epoch 99/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3280 - acc: 0.8863 - val_loss: 0.5297 - val_acc: 0.8140\n",
      "Epoch 100/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3267 - acc: 0.8873 - val_loss: 0.5302 - val_acc: 0.8127\n",
      "Epoch 101/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3257 - acc: 0.8878 - val_loss: 0.5295 - val_acc: 0.8133\n",
      "Epoch 102/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3239 - acc: 0.8889 - val_loss: 0.5335 - val_acc: 0.8143\n",
      "Epoch 103/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3223 - acc: 0.8888 - val_loss: 0.5320 - val_acc: 0.8153\n",
      "Epoch 104/120\n",
      "33000/33000 [==============================] - 1s 15us/step - loss: 0.3212 - acc: 0.8890 - val_loss: 0.5335 - val_acc: 0.8130\n",
      "Epoch 105/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3196 - acc: 0.8891 - val_loss: 0.5339 - val_acc: 0.8150\n",
      "Epoch 106/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3184 - acc: 0.8903 - val_loss: 0.5370 - val_acc: 0.8143\n",
      "Epoch 107/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3171 - acc: 0.8912 - val_loss: 0.5352 - val_acc: 0.8147\n",
      "Epoch 108/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3152 - acc: 0.8909 - val_loss: 0.5379 - val_acc: 0.8127\n",
      "Epoch 109/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3144 - acc: 0.8923 - val_loss: 0.5363 - val_acc: 0.8137\n",
      "Epoch 110/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3130 - acc: 0.8931 - val_loss: 0.5379 - val_acc: 0.8133\n",
      "Epoch 111/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3114 - acc: 0.8927 - val_loss: 0.5388 - val_acc: 0.8153\n",
      "Epoch 112/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3100 - acc: 0.8924 - val_loss: 0.5392 - val_acc: 0.8147\n",
      "Epoch 113/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.3091 - acc: 0.8947 - val_loss: 0.5406 - val_acc: 0.8137\n",
      "Epoch 114/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3078 - acc: 0.8943 - val_loss: 0.5422 - val_acc: 0.8157\n",
      "Epoch 115/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3061 - acc: 0.8951 - val_loss: 0.5433 - val_acc: 0.8123\n",
      "Epoch 116/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3052 - acc: 0.8956 - val_loss: 0.5432 - val_acc: 0.8130\n",
      "Epoch 117/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3035 - acc: 0.8950 - val_loss: 0.5483 - val_acc: 0.8090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.3024 - acc: 0.8965 - val_loss: 0.5461 - val_acc: 0.8117\n",
      "Epoch 119/120\n",
      "33000/33000 [==============================] - 1s 16us/step - loss: 0.3013 - acc: 0.8966 - val_loss: 0.5459 - val_acc: 0.8127\n",
      "Epoch 120/120\n",
      "33000/33000 [==============================] - 0s 15us/step - loss: 0.2998 - acc: 0.8972 - val_loss: 0.5460 - val_acc: 0.8150\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "moredata_model = model.fit(train_final,\n",
    "                    label_train_final,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(val, label_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33000/33000 [==============================] - 1s 21us/step\n",
      "4000/4000 [==============================] - 0s 22us/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_final, label_train_final)\n",
    "results_test = model.evaluate(test, label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29492314792401864, 0.8997272727272727]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5750258494615554, 0.805]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs, you were able to get a fairly similar validation accuracy of 89.67 (compared to 88.55 in obtained in the first model in this lab). your test set accuracy went up from 75.8 to a staggering 80.225% though, without any other regularization technique. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "In this lesson, you not only built an initial deep-learning model, you then used a validation set to tune your model using various types of regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
